FANN_FLO_2.1
num_layers=4
learning_rate=0.400000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=7 9 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (7, 3, 5.00000000000000000000e-01) (7, 3, 5.00000000000000000000e-01) (7, 3, 5.00000000000000000000e-01) (7, 3, 5.00000000000000000000e-01) (7, 3, 5.00000000000000000000e-01) (7, 3, 5.00000000000000000000e-01) (7, 3, 5.00000000000000000000e-01) (7, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.92281198501586914062e+00) (1, -2.00313072204589843750e+01) (2, 2.80978565216064453125e+01) (3, -1.51671113967895507812e+01) (4, -4.67300300598144531250e+01) (5, 2.99925079345703125000e+01) (6, -1.33217656984925270081e-02) (0, -1.47977917480468750000e+03) (1, -1.50000000000000000000e+03) (2, -8.45374145507812500000e+01) (3, 3.12344482421875000000e+02) (4, -1.78233322143554687500e+02) (5, 1.25595703125000000000e+03) (6, -1.96956977844238281250e+01) (0, -1.97026214599609375000e+01) (1, 1.78875541687011718750e+01) (2, 2.67281556129455566406e+00) (3, -4.99648761749267578125e+00) (4, -1.96049690246582031250e+00) (5, -6.83294296264648437500e+00) (6, 3.28057384490966796875e+00) (0, -6.67721679687500000000e+02) (1, -6.51907424926757812500e+01) (2, 7.67518768310546875000e+01) (3, -1.43586669921875000000e+03) (4, 7.47973327636718750000e+02) (5, 1.49316552734375000000e+03) (6, 4.06179189682006835938e-01) (0, -1.22678784179687500000e+03) (1, 5.25827392578125000000e+02) (2, -1.46455041503906250000e+03) (3, 9.67346862792968750000e+02) (4, -1.29536755371093750000e+03) (5, 1.49414782714843750000e+03) (6, 7.51392889022827148438e+00) (0, 1.29566925048828125000e+02) (1, -8.59006404876708984375e+00) (2, 1.49975097656250000000e+03) (3, -1.35755224609375000000e+03) (4, -4.45918350219726562500e+01) (5, 2.96786865234375000000e+02) (6, -8.49896132946014404297e-01) (0, -1.28329992675781250000e+03) (1, -1.23150598144531250000e+03) (2, 1.29286755371093750000e+03) (3, 1.42489270019531250000e+03) (4, -1.13519220352172851562e+01) (5, 5.25269470214843750000e+02) (6, 3.15015435218811035156e+00) (0, -1.43419995117187500000e+03) (1, -1.50000000000000000000e+03) (2, 1.27983105468750000000e+03) (3, 7.66957153320312500000e+02) (4, -1.42055816650390625000e+01) (5, 1.57919128417968750000e+02) (6, -1.81589841842651367188e-01) (7, 6.74872619628906250000e+02) (8, 9.85000061035156250000e+02) (9, 1.50000000000000000000e+03) (10, 1.44001916503906250000e+03) (11, 1.50000000000000000000e+03) (12, -1.43372644042968750000e+03) (13, -9.52848022460937500000e+02) (14, 1.50000000000000000000e+03) (15, -1.73864688873291015625e+01) (7, 1.82847763061523437500e+02) (8, 9.85000061035156250000e+02) (9, 1.50000000000000000000e+03) (10, 1.39494738769531250000e+03) (11, -1.61856430053710937500e+02) (12, -1.28512060546875000000e+03) (13, -1.17619360351562500000e+03) (14, 1.50000000000000000000e+03) (15, -5.80851364135742187500e+01) (7, 2.23941223144531250000e+02) (8, 3.28162200927734375000e+02) (9, 1.05201854705810546875e+01) (10, -7.91953659057617187500e+00) (11, -6.34535179138183593750e+01) (12, 7.25174560546875000000e+02) (13, -2.51422576904296875000e+02) (14, 1.50000000000000000000e+03) (15, -5.58025074005126953125e+00) (7, -3.13633758544921875000e+02) (8, 9.85000061035156250000e+02) (9, 1.50000000000000000000e+03) (10, 1.45675512695312500000e+03) (11, -1.02961750030517578125e+01) (12, -1.19116442871093750000e+03) (13, -3.13063507080078125000e+02) (14, 1.50000000000000000000e+03) (15, 6.95715522766113281250e+00) (16, -2.32355505228042602539e-01) (17, -4.40542876720428466797e-01) (18, -1.55042743682861328125e+00) (19, -6.17792725563049316406e-01) (20, -9.01579856872558593750e-01) 
