FANN_FLO_2.1
num_layers=4
learning_rate=0.400000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=7 9 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (7, 3, 5.00000000000000000000e-01) (7, 3, 5.00000000000000000000e-01) (7, 3, 5.00000000000000000000e-01) (7, 3, 5.00000000000000000000e-01) (7, 3, 5.00000000000000000000e-01) (7, 3, 5.00000000000000000000e-01) (7, 3, 5.00000000000000000000e-01) (7, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -3.29251194000244140625e+00) (1, 1.53469538688659667969e+00) (2, -3.11788654327392578125e+00) (3, -2.85999727249145507812e+00) (4, -6.94142699241638183594e-01) (5, 3.23078483343124389648e-01) (6, 2.11617851257324218750e+00) (0, -1.50000000000000000000e+03) (1, -3.58476562500000000000e+02) (2, -1.14875329589843750000e+03) (3, 3.24148376464843750000e+02) (4, -1.37831542968750000000e+03) (5, 1.02907788085937500000e+03) (6, -5.45991063117980957031e-02) (0, -1.50000000000000000000e+03) (1, -1.49103369140625000000e+03) (2, -1.50000000000000000000e+03) (3, 1.41175915527343750000e+03) (4, -1.36427111816406250000e+03) (5, 1.48961389160156250000e+03) (6, -1.32552623748779296875e+00) (0, -1.50000000000000000000e+03) (1, -1.23292028808593750000e+03) (2, -1.43449658203125000000e+03) (3, 1.44070959472656250000e+03) (4, -1.36504614257812500000e+03) (5, 1.47777905273437500000e+03) (6, -2.12202891707420349121e-01) (0, -1.50000000000000000000e+03) (1, -6.67300537109375000000e+02) (2, -1.44068627929687500000e+03) (3, 1.45530517578125000000e+03) (4, -1.48134509277343750000e+03) (5, -1.36600303649902343750e+01) (6, 2.28816300630569458008e-01) (0, -1.50000000000000000000e+03) (1, -6.86434020996093750000e+02) (2, -1.44068627929687500000e+03) (3, 1.45530517578125000000e+03) (4, -1.19115283203125000000e+03) (5, -5.99059143066406250000e+02) (6, 3.64266782999038696289e-01) (0, -7.28069213867187500000e+02) (1, -1.23299133300781250000e+03) (2, -9.97714050292968750000e+02) (3, 9.35212890625000000000e+02) (4, -1.36320971679687500000e+03) (5, 1.37467126464843750000e+03) (6, 1.12510681152343750000e-01) (0, -1.50000000000000000000e+03) (1, 1.44136328125000000000e+03) (2, -1.49489001464843750000e+03) (3, 1.50000000000000000000e+03) (4, -1.40000000000000000000e+03) (5, 1.50000000000000000000e+03) (6, 4.34946894645690917969e-01) (7, 1.98809585571289062500e+01) (8, 8.88428527832031250000e+02) (9, 1.26953423023223876953e+00) (10, 4.12000244140625000000e+02) (11, 1.50000000000000000000e+03) (12, 1.50000000000000000000e+03) (13, -4.30747344970703125000e+02) (14, 1.81846523284912109375e+00) (15, -2.54206466674804687500e+00) (7, 1.23821315765380859375e+01) (8, 8.88428527832031250000e+02) (9, 1.50000000000000000000e+03) (10, 1.50000000000000000000e+03) (11, 1.50000000000000000000e+03) (12, 1.50000000000000000000e+03) (13, 7.48996154785156250000e+02) (14, 9.76773757934570312500e+01) (15, -2.83390045166015625000e+00) (7, 2.26726703643798828125e+01) (8, 8.88428527832031250000e+02) (9, 1.50000000000000000000e+03) (10, 1.50000000000000000000e+03) (11, 1.50000000000000000000e+03) (12, 1.50000000000000000000e+03) (13, 7.48996154785156250000e+02) (14, 7.98324763774871826172e-01) (15, -9.52060222625732421875e+00) (7, 3.34286804199218750000e+01) (8, 8.88428527832031250000e+02) (9, 1.50000000000000000000e+03) (10, 1.50000000000000000000e+03) (11, 1.50000000000000000000e+03) (12, 1.50000000000000000000e+03) (13, 7.48996154785156250000e+02) (14, -5.75521767139434814453e-01) (15, -3.43346333503723144531e+00) (16, -8.96817445755004882812e-01) (17, -5.17112851142883300781e-01) (18, -1.34481704235076904297e+00) (19, -6.40568137168884277344e-01) (20, -2.03826770186424255371e-01) 
