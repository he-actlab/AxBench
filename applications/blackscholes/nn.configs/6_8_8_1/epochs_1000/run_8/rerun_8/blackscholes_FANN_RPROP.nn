FANN_FLO_2.1
num_layers=4
learning_rate=0.400000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=7 9 9 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (7, 3, 5.00000000000000000000e-01) (7, 3, 5.00000000000000000000e-01) (7, 3, 5.00000000000000000000e-01) (7, 3, 5.00000000000000000000e-01) (7, 3, 5.00000000000000000000e-01) (7, 3, 5.00000000000000000000e-01) (7, 3, 5.00000000000000000000e-01) (7, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -7.76790714263916015625e+00) (1, -3.01385372877120971680e-01) (2, 8.70269241333007812500e+01) (3, -5.55055725097656250000e+02) (4, 1.00524810791015625000e+02) (5, 2.31469058990478515625e+01) (6, 3.13615632057189941406e+00) (0, 2.65206664800643920898e-01) (1, -3.10431265830993652344e+00) (2, 6.03077793121337890625e+00) (3, -4.61879205703735351562e+00) (4, -1.71419680118560791016e+00) (5, 3.73221325874328613281e+00) (6, -1.02257706224918365479e-01) (0, -2.55529594421386718750e+00) (1, 2.49012374877929687500e+00) (2, 3.48491249084472656250e+01) (3, -9.70214939117431640625e+00) (4, -5.83630657196044921875e+00) (5, -6.46257493644952774048e-03) (6, 2.21026921272277832031e+00) (0, -1.51419913768768310547e+00) (1, 2.30472469329833984375e+00) (2, 1.08572216796875000000e+03) (3, 9.53238647460937500000e+02) (4, 6.56956359863281250000e+02) (5, -4.61170911788940429688e+00) (6, 1.53565301895141601562e+01) (0, -3.23643040657043457031e+00) (1, 4.73938062787055969238e-02) (2, -1.52558755874633789062e+00) (3, -2.50873637199401855469e+00) (4, -7.41690874099731445312e-01) (5, 8.45330417156219482422e-01) (6, 1.06917667388916015625e+00) (0, -5.42032337188720703125e+00) (1, 3.46056890487670898438e+00) (2, -3.91115620732307434082e-02) (3, -2.30880093574523925781e+00) (4, -9.10108029842376708984e-01) (5, -4.48457098007202148438e+00) (6, 1.34778118133544921875e+00) (0, -1.04939910888671875000e+02) (1, -2.78582549095153808594e+00) (2, 5.59766662597656250000e+02) (3, -6.03681221008300781250e+01) (4, 7.59715148925781250000e+02) (5, 1.26005993652343750000e+03) (6, -5.63272142410278320312e+00) (0, -1.85793030261993408203e+00) (1, -4.61803078651428222656e-01) (2, 5.93986368179321289062e+00) (3, -4.12202167510986328125e+00) (4, -1.79210269451141357422e+00) (5, 2.72227454185485839844e+00) (6, 8.57212007045745849609e-01) (7, 7.59877920150756835938e-01) (8, 1.76849651336669921875e+01) (9, -3.56134033203125000000e+00) (10, 1.82755720615386962891e+00) (11, -1.09438171386718750000e+01) (12, 1.20557661056518554688e+01) (13, -9.65940952301025390625e-01) (14, -6.96116304397583007812e+00) (15, -2.15926003456115722656e+00) (7, 1.07042901217937469482e-02) (8, 3.06396961212158203125e+00) (9, -4.03773498535156250000e+00) (10, 7.59580945968627929688e+00) (11, -2.73160362243652343750e+01) (12, 1.25359630584716796875e+00) (13, 2.71887749433517456055e-01) (14, 1.17671310901641845703e+00) (15, -4.81176882982254028320e-01) (7, -1.03390092849731445312e+01) (8, 6.69350967407226562500e+01) (9, 1.09934597015380859375e+01) (10, -3.83964121341705322266e-01) (11, -7.00252342224121093750e+00) (12, 9.50280284881591796875e+00) (13, -1.18435823917388916016e+00) (14, 5.98062849044799804688e+00) (15, -3.24956130981445312500e+00) (7, -2.04712814331054687500e+02) (8, 6.20045900344848632812e+00) (9, 4.57686004638671875000e+01) (10, 1.50000000000000000000e+03) (11, 1.47692004394531250000e+03) (12, 5.81579101562500000000e+02) (13, -1.31518322753906250000e+03) (14, 8.95989704132080078125e+00) (15, -1.18463039398193359375e+00) (7, -9.60175228118896484375e+00) (8, 1.11634263992309570312e+01) (9, 1.39250164031982421875e+01) (10, -1.37993011474609375000e+01) (11, -2.58872203826904296875e+01) (12, 1.10141429901123046875e+01) (13, 2.48552322387695312500e+01) (14, 9.90082168579101562500e+00) (15, -2.69477224349975585938e+00) (7, -4.22217315673828125000e+02) (8, 2.13229408264160156250e+01) (9, 6.06502380371093750000e+02) (10, 2.71413731575012207031e+00) (11, -4.94101667404174804688e+00) (12, 4.05445365905761718750e+01) (13, -3.26288604736328125000e+02) (14, 7.69740390777587890625e+00) (15, -2.48429012298583984375e+00) (7, -3.68671936035156250000e+02) (8, -7.48189392089843750000e+01) (9, 1.46916351318359375000e+01) (10, -8.90290260314941406250e-01) (11, -1.96306953430175781250e+01) (12, 4.48905677795410156250e+01) (13, 2.02996719360351562500e+02) (14, -2.62786312103271484375e+01) (15, -1.30130062103271484375e+01) (7, 2.04462468624114990234e-01) (8, 1.33242158889770507812e+01) (9, -2.15902614593505859375e+00) (10, 7.25120604038238525391e-01) (11, -3.84575676918029785156e+00) (12, 1.34796257019042968750e+01) (13, -4.58437442779541015625e-01) (14, -6.38547897338867187500e+00) (15, -2.48235869407653808594e+00) (16, -2.17926740646362304688e+00) (17, -5.19614100456237792969e-01) (18, -1.18145942687988281250e+00) (19, 4.55100685358047485352e-01) (20, -4.67165082693099975586e-01) (21, -2.98488348722457885742e-01) (22, -1.52522727847099304199e-01) (23, -1.96889281272888183594e+00) (24, 3.91138851642608642578e-01) 
