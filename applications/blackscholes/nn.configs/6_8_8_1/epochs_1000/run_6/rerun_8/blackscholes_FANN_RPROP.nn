FANN_FLO_2.1
num_layers=4
learning_rate=0.400000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=7 9 9 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (7, 3, 5.00000000000000000000e-01) (7, 3, 5.00000000000000000000e-01) (7, 3, 5.00000000000000000000e-01) (7, 3, 5.00000000000000000000e-01) (7, 3, 5.00000000000000000000e-01) (7, 3, 5.00000000000000000000e-01) (7, 3, 5.00000000000000000000e-01) (7, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.88905522227287292480e-01) (1, -8.17950248718261718750e+00) (2, -2.08817458152770996094e+00) (3, -1.44491660594940185547e+00) (4, -7.87498950958251953125e-01) (5, 1.99052679538726806641e+00) (6, 1.30957913398742675781e+00) (0, 2.37701940536499023438e+00) (1, -4.02887105941772460938e+00) (2, -3.58210635185241699219e+00) (3, -6.68949365615844726562e+00) (4, -1.22804844379425048828e+00) (5, 2.96575784683227539062e+00) (6, -1.04050040245056152344e-01) (0, -5.48725097656250000000e+02) (1, 4.85974140465259552002e-02) (2, -1.50000000000000000000e+03) (3, -2.72361111640930175781e+00) (4, -1.50000000000000000000e+03) (5, -3.50267028808593750000e+02) (6, 3.72563391923904418945e-01) (0, 1.65654003620147705078e+00) (1, -1.95860162377357482910e-01) (2, 1.38824005126953125000e+01) (3, -4.30048799514770507812e+00) (4, -1.80993080139160156250e+00) (5, 1.56045532226562500000e+00) (6, -6.62295997142791748047e-01) (0, -1.57951664924621582031e+00) (1, 4.22602742910385131836e-01) (2, -1.16154539585113525391e+00) (3, -4.05379390716552734375e+00) (4, -1.25902926921844482422e+00) (5, 6.87982559204101562500e-01) (6, 2.28977799415588378906e-01) (0, -4.09621704101562500000e+02) (1, 3.07556271553039550781e-01) (2, -1.50000000000000000000e+03) (3, -8.21374607086181640625e+00) (4, -1.50000000000000000000e+03) (5, -1.22182205200195312500e+02) (6, 2.16666483879089355469e+00) (0, -8.28590106964111328125e+00) (1, 7.48657417297363281250e+00) (2, -5.15082597732543945312e+00) (3, -2.04303121566772460938e+00) (4, -1.39839768409729003906e+00) (5, -4.68188619613647460938e+00) (6, 9.25133585929870605469e-01) (0, 3.88152933120727539062e+00) (1, -1.92395532131195068359e+00) (2, -1.50000000000000000000e+03) (3, -2.33192712068557739258e-01) (4, -1.50000000000000000000e+03) (5, -2.68797308206558227539e-01) (6, 5.85701465606689453125e-01) (7, 7.27954149246215820312e+00) (8, 2.83184814453125000000e+00) (9, 1.50000000000000000000e+03) (10, 1.81484127044677734375e+00) (11, -8.60223102569580078125e+00) (12, 1.50000000000000000000e+03) (13, -3.47175407409667968750e+00) (14, 1.50000000000000000000e+03) (15, -2.24292731285095214844e+00) (7, 7.79692077636718750000e+01) (8, 1.36213668823242187500e+02) (9, 1.50000000000000000000e+03) (10, 1.33252563476562500000e+01) (11, 6.41185836791992187500e+01) (12, 1.50000000000000000000e+03) (13, -3.44381141662597656250e+01) (14, 1.50000000000000000000e+03) (15, 1.95507109165191650391e+00) (7, -2.57000904083251953125e+01) (8, 6.42973089218139648438e+00) (9, 1.50000000000000000000e+03) (10, 1.13187062740325927734e+00) (11, -8.38855457305908203125e+00) (12, 1.50000000000000000000e+03) (13, 9.99708271026611328125e+00) (14, 1.50000000000000000000e+03) (15, -1.23833334445953369141e+00) (7, 5.17693614959716796875e+00) (8, 2.41764855384826660156e+00) (9, 1.50000000000000000000e+03) (10, 1.60102438926696777344e+00) (11, -7.92357158660888671875e+00) (12, 1.50000000000000000000e+03) (13, 6.15137958526611328125e+00) (14, 1.50000000000000000000e+03) (15, -2.40036129951477050781e+00) (7, -1.12205543518066406250e+01) (8, 6.02351188659667968750e+00) (9, 1.50000000000000000000e+03) (10, 1.72001028060913085938e+00) (11, -1.00780839920043945312e+01) (12, 1.50000000000000000000e+03) (13, -2.01623558998107910156e+00) (14, 1.50000000000000000000e+03) (15, -1.74529659748077392578e+00) (7, 3.00154457092285156250e+01) (8, 5.31365509033203125000e+01) (9, 1.50000000000000000000e+03) (10, -5.97350263595581054688e+00) (11, 4.31713104248046875000e+01) (12, 1.50000000000000000000e+03) (13, 4.14187335968017578125e+00) (14, 1.50000000000000000000e+03) (15, -2.97313761711120605469e+00) (7, 5.13016296386718750000e+02) (8, -6.95176744461059570312e+00) (9, 1.50000000000000000000e+03) (10, 3.13573050498962402344e+00) (11, -4.73818826675415039062e+00) (12, 1.50000000000000000000e+03) (13, -6.23717021942138671875e+00) (14, 1.50000000000000000000e+03) (15, -5.10335302352905273438e+00) (7, -4.20130310058593750000e+01) (8, 1.54666275024414062500e+02) (9, 1.50000000000000000000e+03) (10, -3.25826454162597656250e+01) (11, 9.99369506835937500000e+01) (12, 1.50000000000000000000e+03) (13, -6.42276430130004882812e+00) (14, 1.50000000000000000000e+03) (15, -4.24175746738910675049e-02) (16, -3.76815104484558105469e+00) (17, -3.44241112470626831055e-01) (18, -2.21945762634277343750e+00) (19, -3.70275688171386718750e+00) (20, -1.56956326961517333984e+00) (21, -1.59737735986709594727e-01) (22, -9.38965618610382080078e-01) (23, -1.72189265489578247070e-01) (24, 6.93386673927307128906e-01) 
