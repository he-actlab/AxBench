FANN_FLO_2.1
num_layers=4
learning_rate=0.400000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=7 9 9 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (7, 3, 5.00000000000000000000e-01) (7, 3, 5.00000000000000000000e-01) (7, 3, 5.00000000000000000000e-01) (7, 3, 5.00000000000000000000e-01) (7, 3, 5.00000000000000000000e-01) (7, 3, 5.00000000000000000000e-01) (7, 3, 5.00000000000000000000e-01) (7, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.05355761945247650146e-01) (1, -6.86298418045043945312e+00) (2, -2.23448165893554687500e+02) (3, -1.30335164070129394531e+00) (4, -2.17268714904785156250e+01) (5, 1.50740346908569335938e+01) (6, 3.62501645088195800781e+00) (0, -1.29410156250000000000e+03) (1, -1.47888854980468750000e+03) (2, -1.48709179687500000000e+03) (3, 1.48666857910156250000e+03) (4, -1.49302502441406250000e+03) (5, 1.50000000000000000000e+03) (6, -2.18098526000976562500e+01) (0, -5.58533191680908203125e+00) (1, -6.76120328903198242188e+00) (2, -9.19914474487304687500e+01) (3, 8.58041763305664062500e+00) (4, -4.57217842340469360352e-02) (5, 7.01410055160522460938e+00) (6, -1.32023429870605468750e+00) (0, -7.04302825927734375000e+01) (1, -1.77415893554687500000e+02) (2, -8.01084960937500000000e+02) (3, 1.49676525878906250000e+03) (4, 1.17249108886718750000e+03) (5, -1.27641210937500000000e+03) (6, -2.52522258758544921875e+01) (0, 9.43587036132812500000e+02) (1, 1.76654708862304687500e+02) (2, 1.62497039794921875000e+02) (3, 1.49064477539062500000e+03) (4, 1.17716369628906250000e+03) (5, -1.33455944824218750000e+03) (6, -2.42193279266357421875e+01) (0, 1.49563586425781250000e+03) (1, 1.48633337402343750000e+03) (2, 1.49160229492187500000e+03) (3, 1.88287334442138671875e+01) (4, 1.49989123535156250000e+03) (5, 5.18233398437500000000e+02) (6, 7.61856126785278320312e+00) (0, -4.34901611328125000000e+02) (1, -1.40782958984375000000e+03) (2, -1.47679199218750000000e+03) (3, -1.79812374114990234375e+01) (4, -1.47764831542968750000e+03) (5, 1.50368362426757812500e+02) (6, 1.24936647713184356689e-01) (0, -7.88306379318237304688e+00) (1, 6.60547113418579101562e+00) (2, 6.64487075805664062500e+00) (3, -3.86693096160888671875e+00) (4, -1.51072549819946289062e+00) (5, 1.28817200660705566406e+00) (6, 2.67754602432250976562e+00) (7, 1.14333007812500000000e+02) (8, 1.34080004882812500000e+03) (9, 2.73925342559814453125e+01) (10, -4.47279052734375000000e+02) (11, 4.55910308837890625000e+02) (12, -8.76127481460571289062e-01) (13, 1.50000000000000000000e+03) (14, 7.87938354492187500000e+02) (15, -1.78408420085906982422e+00) (7, -1.21567321777343750000e+03) (8, 9.66747741699218750000e+02) (9, -6.13519515991210937500e+01) (10, 1.49676525878906250000e+03) (11, 1.49675292968750000000e+03) (12, -4.38295013427734375000e+02) (13, 1.50000000000000000000e+03) (14, -1.21896032714843750000e+03) (15, -5.18494558334350585938e+00) (7, 1.50000000000000000000e+03) (8, 1.34080004882812500000e+03) (9, 1.10600757598876953125e+01) (10, -4.47279052734375000000e+02) (11, 4.55910308837890625000e+02) (12, 3.00894770771265029907e-02) (13, 1.50000000000000000000e+03) (14, 7.21145009994506835938e+00) (15, -1.84679329395294189453e+00) (7, -1.10727575683593750000e+03) (8, 9.66747741699218750000e+02) (9, -7.17370300292968750000e+01) (10, 1.49676525878906250000e+03) (11, 1.49675292968750000000e+03) (12, -2.15633392333984375000e+02) (13, 1.50000000000000000000e+03) (14, 5.02065490722656250000e+02) (15, -8.86304855346679687500e-01) (7, 1.44540002441406250000e+03) (8, 1.34080004882812500000e+03) (9, 8.90781478881835937500e+01) (10, -4.47279052734375000000e+02) (11, 4.55910308837890625000e+02) (12, 2.71265289306640625000e+02) (13, 1.50000000000000000000e+03) (14, 1.50000000000000000000e+03) (15, -9.22494173049926757812e-01) (7, -2.43668670654296875000e+02) (8, 1.22147314453125000000e+03) (9, -2.45729923248291015625e+01) (10, 1.49676525878906250000e+03) (11, 1.49675292968750000000e+03) (12, -1.71715576171875000000e+02) (13, 1.50000000000000000000e+03) (14, -1.50000000000000000000e+03) (15, -1.57761991024017333984e+00) (7, 1.44540002441406250000e+03) (8, 1.34080004882812500000e+03) (9, 8.45415344238281250000e+01) (10, -4.47279052734375000000e+02) (11, 4.55910308837890625000e+02) (12, 1.93404464721679687500e+02) (13, 1.50000000000000000000e+03) (14, 1.50000000000000000000e+03) (15, -4.60609626770019531250e+00) (7, 1.31936853027343750000e+03) (8, 1.34080004882812500000e+03) (9, 8.45389099121093750000e+01) (10, -1.94568969726562500000e+02) (11, 4.12793487548828125000e+02) (12, -3.97461486816406250000e+02) (13, 1.50000000000000000000e+03) (14, 1.50000000000000000000e+03) (15, -3.91371488571166992188e+00) (16, -9.24605429172515869141e-01) (17, 7.50368103027343750000e+02) (18, -2.72855687141418457031e+00) (19, 1.60207107663154602051e-01) (20, -3.48882883787155151367e-01) (21, 7.47645446777343750000e+02) (22, -3.58680754899978637695e-01) (23, -1.49633020019531250000e+03) (24, -8.92013236880302429199e-02) 
