FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 3 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (3, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.18532174825668334961e-01) (1, -1.32149839401245117188e+01) (2, -6.56711816787719726562e+00) (3, -1.55835139751434326172e+00) (4, -4.27047014236450195312e+00) (5, -5.76237253844738006592e-02) (6, 3.62854361534118652344e+00) (7, 6.02865457534790039062e+00) (8, 1.63623199462890625000e+01) (9, 2.43401122093200683594e+00) (0, 1.56513595581054687500e+00) (1, -1.17505512237548828125e+01) (2, -2.55313658714294433594e+00) (3, -7.72691488265991210938e+00) (4, -4.94885492324829101562e+00) (5, -1.44209535792469978333e-02) (6, 4.12028837203979492188e+00) (7, 1.21311931610107421875e+01) (8, 1.29056520462036132812e+01) (9, 2.64367729425430297852e-01) (0, -2.30261659622192382812e+00) (1, -7.78827857971191406250e+00) (2, 4.14761686325073242188e+00) (3, -1.40791893005371093750e+00) (4, -2.23991060256958007812e+00) (5, -5.17672538757324218750e-01) (6, 9.29347801208496093750e+00) (7, 3.55791282653808593750e+00) (8, 5.70575952529907226562e+00) (9, -6.66162788867950439453e-01) (0, -7.89772391319274902344e-01) (1, -1.39344825744628906250e+01) (2, -2.90835571289062500000e+00) (3, -1.64198303222656250000e+00) (4, -4.22837924957275390625e+00) (5, -3.73668707907199859619e-02) (6, 3.08232021331787109375e+00) (7, 7.57497549057006835938e+00) (8, 1.36776952743530273438e+01) (9, 1.93627882003784179688e+00) (0, -3.48186254501342773438e-01) (1, -1.39763660430908203125e+01) (2, -3.63760828971862792969e+00) (3, -4.57300758361816406250e+00) (4, -3.72038030624389648438e+00) (5, -6.65307492017745971680e-02) (6, 3.73278975486755371094e+00) (7, 9.51372051239013671875e+00) (8, 1.93762130737304687500e+01) (9, 2.78150200843811035156e-01) (0, -3.81008195877075195312e+00) (1, -1.02830305099487304688e+01) (2, -5.98648500442504882812e+00) (3, -2.95454263687133789062e+00) (4, -2.95915627479553222656e+00) (5, -8.47745597362518310547e-01) (6, 7.68513822555541992188e+00) (7, 3.23562002182006835938e+00) (8, 1.75676021575927734375e+01) (9, -1.10941842198371887207e-01) (0, -2.30633068084716796875e+00) (1, -9.56080055236816406250e+00) (2, -1.56809866428375244141e+00) (3, -3.64254140853881835938e+00) (4, -4.26215696334838867188e+00) (5, -1.45473456382751464844e+00) (6, 6.92985153198242187500e+00) (7, 3.40736031532287597656e+00) (8, 8.31012535095214843750e+00) (9, -7.59969472885131835938e-01) (0, -1.21965856933593750000e+03) (1, -9.94340324401855468750e+00) (2, 3.57254719734191894531e+00) (3, 5.63642233610153198242e-02) (4, -4.54289531707763671875e+00) (5, -3.34008131176233291626e-03) (6, 4.88518238067626953125e-01) (7, 2.80010104179382324219e+00) (8, 4.50584220886230468750e+00) (9, -3.00005227327346801758e-01) (10, -2.05127668380737304688e+00) (11, -1.44439899921417236328e+00) (12, 1.15964877605438232422e+00) (13, -2.04784464836120605469e+00) (14, -2.04800295829772949219e+00) (15, 6.74836492538452148438e+00) (16, 8.52158367633819580078e-01) (17, -6.88935399055480957031e-01) (18, 1.07583200931549072266e+00) (10, -4.36001396179199218750e+00) (11, -8.33599686622619628906e-01) (12, 1.67470932006835937500e+00) (13, -3.69276404380798339844e+00) (14, -9.95784997940063476562e-01) (15, 5.10402870178222656250e+00) (16, 3.29524040222167968750e+00) (17, -9.60997343063354492188e-01) (18, 1.66491782665252685547e+00) (19, 2.11932516098022460938e+00) (20, 1.94998717308044433594e+00) (21, -2.35187768936157226562e+00) 
