FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 3 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (3, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 4.13242608308792114258e-01) (1, 2.16364169120788574219e+00) (2, 3.23513150215148925781e+00) (3, -5.26923322677612304688e+00) (4, 6.39645457267761230469e-01) (5, 2.63969349861145019531e+00) (6, -5.89666891098022460938e+00) (7, -5.38589954376220703125e+00) (8, 3.41257905960083007812e+00) (9, -2.06458926200866699219e+00) (0, -1.44080746173858642578e+00) (1, 8.34591507911682128906e-01) (2, 8.81784379482269287109e-01) (3, -4.27592229843139648438e+00) (4, 5.21343231201171875000e-01) (5, 6.72053909301757812500e+00) (6, -2.20992207527160644531e+00) (7, -5.11888265609741210938e+00) (8, 3.31737089157104492188e+00) (9, -1.91797792911529541016e+00) (0, -8.09303741455078125000e+01) (1, 2.23904061317443847656e+00) (2, 3.19542026519775390625e+00) (3, -4.02162265777587890625e+00) (4, 1.18785727024078369141e+00) (5, 2.55845546722412109375e+00) (6, -8.49990940093994140625e+00) (7, 7.50060729980468750000e+01) (8, 4.66589736938476562500e+00) (9, -2.52635216712951660156e+00) (0, 1.07375551015138626099e-02) (1, 2.39313745498657226562e+00) (2, 9.25167143344879150391e-01) (3, -3.70941686630249023438e+00) (4, 6.77958667278289794922e-01) (5, 9.34251499176025390625e+00) (6, -9.00105357170104980469e-01) (7, -1.12365922927856445312e+01) (8, 3.33311223983764648438e+00) (9, -2.48146605491638183594e+00) (0, -1.25059723854064941406e-01) (1, 2.51172232627868652344e+00) (2, 1.33194875717163085938e+00) (3, -4.47932481765747070312e+00) (4, 5.33784985542297363281e-01) (5, 9.82895946502685546875e+00) (6, -2.57137107849121093750e+00) (7, -8.52472877502441406250e+00) (8, 3.01186156272888183594e+00) (9, -2.40345454216003417969e+00) (0, -1.02136969566345214844e+00) (1, 2.50797319412231445312e+00) (2, 2.66409707069396972656e+00) (3, -8.42583084106445312500e+00) (4, 2.16699862480163574219e+00) (5, 2.69461822509765625000e+00) (6, -7.53315258026123046875e+00) (7, -2.71107125282287597656e+00) (8, 4.68143558502197265625e+00) (9, -2.73287415504455566406e+00) (0, -1.22072570800781250000e+03) (1, 8.82758677005767822266e-01) (2, 6.22496843338012695312e+00) (3, -5.50719070434570312500e+00) (4, 8.20297360420227050781e-01) (5, 4.71510028839111328125e+00) (6, -4.70740890502929687500e+00) (7, -1.38202321529388427734e+00) (8, 2.70294022560119628906e+00) (9, -1.22430300712585449219e+00) (0, -2.39767861366271972656e+00) (1, 2.22167897224426269531e+00) (2, 2.80060243606567382812e+00) (3, 4.64176237583160400391e-01) (4, 1.06693410873413085938e+00) (5, 5.31972885131835937500e+00) (6, -1.41684665679931640625e+01) (7, 8.29968261718750000000e+00) (8, 2.76683330535888671875e+00) (9, -2.79363203048706054688e+00) (10, -4.61434221267700195312e+00) (11, 2.96563768386840820312e+00) (12, 1.50000000000000000000e+03) (13, 1.13977041244506835938e+01) (14, 5.20093011856079101562e+00) (15, 1.14669513702392578125e+00) (16, 1.50000000000000000000e+03) (17, 8.10993671417236328125e+00) (18, -7.31014299392700195312e+00) (10, 1.96963214874267578125e+01) (11, 1.42864048480987548828e+00) (12, 1.50000000000000000000e+03) (13, 1.61712722778320312500e+01) (14, 2.86744475364685058594e+00) (15, 3.52512025833129882812e+00) (16, 1.50000000000000000000e+03) (17, 1.17091178894042968750e+00) (18, -9.97907352447509765625e+00) (19, 9.99245345592498779297e-01) (20, 1.10831880569458007812e+00) (21, -1.24030315876007080078e+00) 
