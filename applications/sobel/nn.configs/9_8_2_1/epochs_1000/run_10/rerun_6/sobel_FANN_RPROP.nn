FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 3 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (3, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.11162376403808593750e+00) (1, 3.14483261108398437500e+00) (2, -1.82177429199218750000e+01) (3, -7.92943775653839111328e-01) (4, 2.46248111128807067871e-01) (5, 3.66024933755397796631e-02) (6, 5.94778299331665039062e+00) (7, 2.50655341148376464844e+00) (8, -2.88423299789428710938e+00) (9, 3.81964683532714843750e+00) (0, -2.96233916282653808594e+00) (1, 5.90815842151641845703e-01) (2, -1.48253412246704101562e+01) (3, -3.41088443994522094727e-01) (4, 9.54515993595123291016e-01) (5, -1.04959201812744140625e+00) (6, 1.60064205527305603027e-01) (7, -6.83857202529907226562e-02) (8, 2.43628644943237304688e+00) (9, -2.04695001244544982910e-01) (0, -5.02579498291015625000e+00) (1, 1.12192983627319335938e+01) (2, -1.26090419292449951172e+00) (3, -1.80719852447509765625e+00) (4, 1.77329492568969726562e+00) (5, 2.27812558412551879883e-01) (6, 1.50329983234405517578e+00) (7, -4.40669345855712890625e+00) (8, -8.78591537475585937500e-01) (9, -5.62383532524108886719e-01) (0, 5.73681783676147460938e+00) (1, -1.14319591522216796875e+01) (2, 3.75649482011795043945e-01) (3, 7.48034060001373291016e-01) (4, -1.67103195190429687500e+00) (5, -8.62096786499023437500e-01) (6, 3.75623941421508789062e-01) (7, 1.17508840560913085938e+00) (8, 1.92320287227630615234e+00) (9, 3.17537516355514526367e-01) (0, -1.09984836578369140625e+01) (1, 9.22382450103759765625e+00) (2, -5.08465290069580078125e+00) (3, -1.00891029834747314453e+00) (4, 2.44915103912353515625e+00) (5, 4.24263191223144531250e+00) (6, 4.32760906219482421875e+00) (7, -6.94446420669555664062e+00) (8, 3.06552380323410034180e-01) (9, 4.89570975303649902344e-01) (0, 1.16003303527832031250e+01) (1, 2.62400054931640625000e+00) (2, -1.06726288795471191406e+00) (3, -2.64653778076171875000e+00) (4, 1.36349570751190185547e+00) (5, 1.35333108901977539062e+00) (6, -3.49732351303100585938e+00) (7, -5.18757677078247070312e+00) (8, -6.24802350997924804688e+00) (9, -3.07301729917526245117e-02) (0, 3.97560930252075195312e+00) (1, 2.00060820579528808594e+00) (2, -1.20289433002471923828e+00) (3, -9.23874855041503906250e+00) (4, 9.76718366146087646484e-01) (5, 5.69760274887084960938e+00) (6, -5.41015243530273437500e+00) (7, -1.91229140758514404297e+00) (8, -5.32323265075683593750e+00) (9, 1.90210044384002685547e+00) (0, 3.28987550735473632812e+00) (1, -5.16779565811157226562e+00) (2, 8.35230350494384765625e+00) (3, 1.56582963466644287109e+00) (4, -8.43024075031280517578e-01) (5, 1.56029605865478515625e+00) (6, 4.21400461345911026001e-03) (7, 4.39120960235595703125e+00) (8, 9.63927745819091796875e+00) (9, 2.31530213356018066406e+00) (10, -3.50250053405761718750e+01) (11, 1.26574546813964843750e+02) (12, 6.23762178421020507812e+00) (13, -1.56354017257690429688e+01) (14, 4.14369106292724609375e+00) (15, 7.79828977584838867188e+00) (16, 6.28112268447875976562e+00) (17, -7.02389812469482421875e+00) (18, -2.64469116926193237305e-01) (10, -1.81189079284667968750e+01) (11, 2.80027236938476562500e+01) (12, 6.58821725845336914062e+00) (13, -7.19548320770263671875e+00) (14, 1.28704137802124023438e+01) (15, 1.52910976409912109375e+01) (16, -1.11765604019165039062e+01) (17, -4.20916891098022460938e+00) (18, 1.27799764275550842285e-01) (19, 1.52391600608825683594e+00) (20, 1.35036623477935791016e+00) (21, -1.99734008312225341797e+00) 
