FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 3 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (3, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.09472763061523437500e+02) (1, 1.50000000000000000000e+03) (2, 1.50000000000000000000e+03) (3, 4.66305434703826904297e-01) (4, 5.65092638134956359863e-02) (5, -9.63835620880126953125e+00) (6, 3.25832033157348632812e+00) (7, 4.01344537734985351562e+00) (8, 7.00613856315612792969e-02) (9, -6.44011795520782470703e-01) (0, -2.44319510459899902344e+00) (1, 2.12294965982437133789e-01) (2, 3.02302837371826171875e-01) (3, 4.79398679733276367188e+00) (4, 9.30085122585296630859e-01) (5, 5.97460889816284179688e+00) (6, -2.59941530227661132812e+00) (7, -5.33542454242706298828e-01) (8, 1.63758802413940429688e+00) (9, -7.74367213249206542969e-01) (0, -7.88992214202880859375e+00) (1, -7.40902709960937500000e+00) (2, -7.92325544357299804688e+00) (3, 1.81440699100494384766e+00) (4, 1.08032476902008056641e+00) (5, 5.33135700225830078125e+00) (6, 4.79369688034057617188e+00) (7, 8.93686294555664062500e+00) (8, 2.42349123954772949219e+00) (9, 1.36886084079742431641e+00) (0, 3.39895749092102050781e+00) (1, 1.57127976417541503906e+00) (2, 2.98723769187927246094e+00) (3, 8.34621071815490722656e-01) (4, 3.78680199384689331055e-01) (5, -1.08588190078735351562e+01) (6, -8.19596827030181884766e-01) (7, 4.55349540710449218750e+00) (8, -5.09730696678161621094e-01) (9, 3.96971285343170166016e-01) (0, 2.65566658973693847656e+00) (1, -2.18082666397094726562e+00) (2, 1.24472880363464355469e+00) (3, 3.96793574094772338867e-01) (4, -2.77411192655563354492e-01) (5, -4.66063117980957031250e+00) (6, 8.81354093551635742188e-01) (7, 9.25030171871185302734e-01) (8, 2.21137642860412597656e+00) (9, -6.87009513378143310547e-01) (0, 2.62555670738220214844e+00) (1, -1.66344296932220458984e+00) (2, 1.13572418689727783203e+00) (3, 3.47335278987884521484e-01) (4, -2.47626543045043945312e-01) (5, -3.39975738525390625000e+00) (6, 1.78087913990020751953e+00) (7, 1.76210492849349975586e-01) (8, 8.59543144702911376953e-01) (9, -6.13508641719818115234e-01) (0, 3.99501204490661621094e-01) (1, -4.12165117263793945312e+00) (2, -3.59560585021972656250e+00) (3, -5.94624698162078857422e-01) (4, 7.14707002043724060059e-02) (5, 1.59111753106117248535e-01) (6, -5.37903904914855957031e-01) (7, -2.35133910179138183594e+00) (8, 1.31405744552612304688e+01) (9, 7.59764492511749267578e-01) (0, 1.42832660675048828125e+00) (1, 2.14905166625976562500e+00) (2, -4.03798007965087890625e+00) (3, 1.51719883084297180176e-01) (4, 9.80165526270866394043e-02) (5, -8.30740165710449218750e+00) (6, -3.82315605878829956055e-01) (7, 5.30351877212524414062e+00) (8, 2.05381121486425399780e-02) (9, 5.48450723290443420410e-02) (10, -4.97811164855957031250e+01) (11, 2.88182473182678222656e+00) (12, 7.59428405761718750000e+00) (13, 4.44813842773437500000e+01) (14, -1.08780479058623313904e-02) (15, -4.99120426177978515625e+00) (16, 2.08895969390869140625e+00) (17, 2.04664478302001953125e+01) (18, 3.38092893362045288086e-01) (10, -1.48695445060729980469e+00) (11, 1.00524072647094726562e+01) (12, -7.46103239059448242188e+00) (13, -3.76511502265930175781e+00) (14, -6.41827404499053955078e-01) (15, -8.03812742233276367188e-01) (16, -3.07131862640380859375e+00) (17, 5.59080839157104492188e+00) (18, 1.31040525436401367188e+00) (19, 8.48699033260345458984e-01) (20, 3.11562395095825195312e+00) (21, -2.15521287918090820312e+00) 
