FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 3 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (3, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.17112016677856445312e+01) (1, -1.07322463989257812500e+01) (2, 1.84544220566749572754e-01) (3, -4.27041864395141601562e+00) (4, -5.12263774871826171875e+00) (5, 2.17651176452636718750e+00) (6, 1.90595877170562744141e+00) (7, 8.50640106201171875000e+00) (8, 3.13020491600036621094e+00) (9, -5.01941442489624023438e+00) (0, 1.21421823501586914062e+01) (1, -1.00131063461303710938e+01) (2, 2.04881763458251953125e+00) (3, -7.73138046264648437500e+00) (4, -5.58712339401245117188e+00) (5, 5.21850347518920898438e+00) (6, 3.77269387245178222656e+00) (7, 5.30768585205078125000e+00) (8, 4.29879522323608398438e+00) (9, -3.09520745277404785156e+00) (0, 1.05505275726318359375e+01) (1, 1.62472763061523437500e+01) (2, -1.09069833755493164062e+01) (3, -4.37155455350875854492e-01) (4, -7.19045162200927734375e-01) (5, -3.86857771873474121094e+00) (6, 2.81968498229980468750e+01) (7, -3.28617668151855468750e+00) (8, -2.77839050292968750000e+01) (9, 4.22061271965503692627e-02) (0, 1.11356506347656250000e+01) (1, -1.29628953933715820312e+01) (2, 5.33406555652618408203e-01) (3, -4.34449195861816406250e+00) (4, -7.42472267150878906250e+00) (5, 6.35722875595092773438e-01) (6, 2.09770512580871582031e+00) (7, 1.18852396011352539062e+01) (8, 1.07473163604736328125e+01) (9, -4.45911359786987304688e+00) (0, 1.10574693679809570312e+01) (1, 1.48484802246093750000e+01) (2, -9.95965862274169921875e+00) (3, 1.99164927005767822266e-01) (4, -6.03250801563262939453e-01) (5, -3.55220437049865722656e+00) (6, 2.71497383117675781250e+01) (7, -3.53146457672119140625e+00) (8, -2.75351295471191406250e+01) (9, 3.32123227417469024658e-02) (0, 1.19713640213012695312e+01) (1, 4.57961883544921875000e+01) (2, -2.49769840240478515625e+01) (3, -3.48015129566192626953e-01) (4, 1.67935962677001953125e+01) (5, -2.96423840522766113281e+00) (6, 1.93690586090087890625e+01) (7, -4.62225437164306640625e+00) (8, -2.60746765136718750000e+01) (9, -1.66132462024688720703e+00) (0, -2.84405589103698730469e-01) (1, 2.58093118667602539062e+00) (2, -3.64297056198120117188e+00) (3, 7.64926910400390625000e+00) (4, 1.66343843936920166016e+00) (5, -4.19156217575073242188e+00) (6, -3.37932705879211425781e+00) (7, -1.84435534477233886719e+00) (8, -1.31464198231697082520e-01) (9, 3.63844990730285644531e-01) (0, 1.17094516754150390625e+01) (1, -2.89228141307830810547e-01) (2, 1.49982861328125000000e+03) (3, 3.22030883789062500000e+02) (4, -6.65877151489257812500e+01) (5, -3.73025822639465332031e+00) (6, 8.16177291870117187500e+01) (7, 2.75896739959716796875e+00) (8, 1.49731616210937500000e+03) (9, -4.34418869018554687500e+00) (10, -7.69507646560668945312e-01) (11, -5.95018529891967773438e+00) (12, -3.13070058822631835938e-01) (13, -2.73971891403198242188e+00) (14, -4.62675839662551879883e-01) (15, -9.41646099090576171875e+00) (16, 1.14342079162597656250e+01) (17, 9.71537303924560546875e+00) (18, 7.86396741867065429688e-01) (10, 2.97875595092773437500e+00) (11, -6.04894590377807617188e+00) (12, -2.65668720006942749023e-01) (13, -9.53172028064727783203e-01) (14, -2.04651772975921630859e-01) (15, -2.11592578887939453125e+00) (16, 1.12344799041748046875e+01) (17, 1.99653232097625732422e+00) (18, 8.33236753940582275391e-01) (19, 1.51929187774658203125e+00) (20, 9.62100565433502197266e-01) (21, -1.58688735961914062500e+00) 
