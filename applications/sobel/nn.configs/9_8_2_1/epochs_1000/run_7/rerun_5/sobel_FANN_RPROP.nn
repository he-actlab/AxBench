FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 3 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (3, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 5.24704039096832275391e-01) (1, -2.29215502738952636719e+00) (2, 3.52950811386108398438e+00) (3, 1.66101619601249694824e-01) (4, -1.82021274566650390625e+01) (5, -1.99608564376831054688e+00) (6, 1.06247625350952148438e+01) (7, 6.54307842254638671875e-01) (8, 3.46070146560668945312e+00) (9, 1.66924074292182922363e-01) (0, 5.39035201072692871094e-02) (1, -9.16876316070556640625e+00) (2, -3.94826102256774902344e+00) (3, 4.25112199783325195312e+00) (4, -6.66384887695312500000e+00) (5, 5.48476982116699218750e+00) (6, 9.10471057891845703125e+00) (7, 3.55911374092102050781e-01) (8, 1.51305937767028808594e+00) (9, 1.01999974250793457031e+00) (0, -3.95732879638671875000e-01) (1, -4.43441182374954223633e-01) (2, 9.74322855472564697266e-01) (3, -8.62846523523330688477e-03) (4, -8.40414237976074218750e+00) (5, -5.71348011493682861328e-01) (6, 8.92624282836914062500e+00) (7, -1.69063270092010498047e+00) (8, 4.34616518020629882812e+00) (9, 1.87754318118095397949e-01) (0, 1.08373261988162994385e-01) (1, 2.33639836311340332031e+00) (2, -8.33058834075927734375e-01) (3, 5.88126003742218017578e-01) (4, 3.98968935012817382812e+00) (5, 1.82998335361480712891e+00) (6, -6.55097007751464843750e-01) (7, -1.73816990852355957031e+00) (8, -2.86687850952148437500e-01) (9, -1.41865789890289306641e+00) (0, 5.87043106555938720703e-01) (1, -2.26583266258239746094e+00) (2, 3.41571378707885742188e+00) (3, -3.02525162696838378906e-02) (4, -1.82651805877685546875e+01) (5, -1.22166705131530761719e+00) (6, 1.04673957824707031250e+01) (7, 2.99920499324798583984e-01) (8, 4.00859832763671875000e+00) (9, 1.31779700517654418945e-01) (0, 3.58890104293823242188e+00) (1, -5.02726125717163085938e+00) (2, -1.16292059421539306641e+00) (3, -1.26354828476905822754e-01) (4, -9.69842433929443359375e+00) (5, -2.02098703384399414062e+00) (6, 7.26903581619262695312e+00) (7, 1.84051966667175292969e+00) (8, 5.33758020401000976562e+00) (9, 4.09231424331665039062e+00) (0, 5.27649223804473876953e-01) (1, -2.02197265625000000000e+00) (2, 4.03728389739990234375e+00) (3, 1.36312559247016906738e-01) (4, -2.04685096740722656250e+01) (5, -1.06693732738494873047e+00) (6, 1.09893121719360351562e+01) (7, 6.34109675884246826172e-01) (8, 4.67197418212890625000e+00) (9, 4.55685675144195556641e-01) (0, -2.43409085273742675781e+00) (1, -6.59690761566162109375e+00) (2, 2.78880357742309570312e+00) (3, -3.86117672920227050781e+00) (4, -8.17491817474365234375e+00) (5, 7.89837360382080078125e+00) (6, 1.04187984466552734375e+01) (7, 6.29164993762969970703e-01) (8, -6.74206161499023437500e+00) (9, 7.11084902286529541016e-01) (10, -1.00021467208862304688e+01) (11, -5.32004892826080322266e-01) (12, 1.80260109901428222656e+00) (13, 6.32774972915649414062e+00) (14, -5.53465127944946289062e+00) (15, 1.25470131635665893555e-01) (16, -1.44294719696044921875e+01) (17, -1.87231624126434326172e+00) (18, 3.38324934244155883789e-01) (10, -6.78339338302612304688e+00) (11, -2.17751789093017578125e+00) (12, 1.73584604263305664062e+00) (13, -7.25990384817123413086e-02) (14, -3.87957882881164550781e+00) (15, 7.74685800075531005859e-01) (16, -1.13820142745971679688e+01) (17, 5.59039974212646484375e+00) (18, 1.95305973291397094727e-01) (19, 1.99663245677947998047e+00) (20, 7.45005428791046142578e-01) (21, -1.56967794895172119141e+00) 
