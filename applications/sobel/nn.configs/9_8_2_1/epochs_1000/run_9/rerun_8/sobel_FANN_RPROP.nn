FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 3 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (3, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 4.55476701259613037109e-01) (1, 3.83112621307373046875e+00) (2, 3.92876195907592773438e+00) (3, -7.40396082401275634766e-01) (4, -1.84323847293853759766e+00) (5, -4.80287981033325195312e+00) (6, -5.75817704200744628906e-01) (7, 1.56539261341094970703e+00) (8, -8.73846912384033203125e+00) (9, 1.29764318466186523438e+00) (0, -1.20866084098815917969e+00) (1, 6.44612503051757812500e+00) (2, 6.05767905712127685547e-01) (3, -3.39345955848693847656e+00) (4, -4.90646219253540039062e+00) (5, -5.47046124935150146484e-01) (6, 4.68386125564575195312e+00) (7, -9.79012310504913330078e-01) (8, -1.53148818016052246094e+00) (9, 1.12342274188995361328e+00) (0, 1.97065782546997070312e+00) (1, 7.05176496505737304688e+00) (2, 1.64333999156951904297e+00) (3, -1.72819004058837890625e+01) (4, 2.48295798897743225098e-01) (5, -3.91150027513504028320e-01) (6, -2.93606781959533691406e+00) (7, 2.36424255371093750000e+00) (8, -6.02154731750488281250e-01) (9, 9.98848915100097656250e-01) (0, 2.70767271518707275391e-01) (1, 2.53282260894775390625e+00) (2, 4.72476482391357421875e+00) (3, -2.06477437168359756470e-02) (4, 2.50347703695297241211e-01) (5, -4.76151275634765625000e+00) (6, -5.97797214984893798828e-01) (7, 1.55076301097869873047e+00) (8, -9.40963459014892578125e+00) (9, 3.42002302408218383789e-01) (0, 4.87105703353881835938e+00) (1, 4.12689113616943359375e+00) (2, 1.17230772972106933594e+00) (3, -1.57714354991912841797e+00) (4, -2.52056193351745605469e+00) (5, -1.46974778175354003906e+00) (6, -5.77036285400390625000e+00) (7, -5.24668574333190917969e-01) (8, -1.97909295558929443359e+00) (9, 1.52606701850891113281e+00) (0, -1.49941650390625000000e+03) (1, -1.49402087402343750000e+03) (2, -1.49430773925781250000e+03) (3, -1.00007522106170654297e+00) (4, 5.71458935737609863281e-01) (5, -1.49280126953125000000e+03) (6, -1.49770849609375000000e+03) (7, 6.24491786956787109375e+00) (8, -1.47945446777343750000e+03) (9, -2.18872570991516113281e+00) (0, 1.46864205598831176758e-01) (1, 6.03510522842407226562e+00) (2, 2.52088513225317001343e-02) (3, -1.94627714157104492188e+00) (4, -4.37204694747924804688e+00) (5, -7.10761010646820068359e-01) (6, -2.71479320526123046875e+00) (7, -9.30652260780334472656e-01) (8, -1.55508494377136230469e+00) (9, 1.36131489276885986328e+00) (0, 9.83375728130340576172e-01) (1, 9.39586353302001953125e+00) (2, 6.01019096374511718750e+00) (3, -4.70305490493774414062e+00) (4, 6.33211553096771240234e-01) (5, -1.12902565002441406250e+01) (6, 4.39483314752578735352e-01) (7, -5.86870193481445312500e+00) (8, -8.45878791809082031250e+00) (9, 1.00215864181518554688e+00) (10, 2.32554984092712402344e+00) (11, 1.02622532844543457031e+00) (12, 5.93742084503173828125e+00) (13, 1.85930976867675781250e+01) (14, 6.20048642158508300781e-01) (15, 1.50000000000000000000e+03) (16, 1.17767453193664550781e+00) (17, -1.30922670364379882812e+01) (18, -6.36914253234863281250e+00) (10, 1.97748422622680664062e+00) (11, -5.18992948532104492188e+00) (12, 4.79198360443115234375e+00) (13, 9.27373027801513671875e+00) (14, 8.40707874298095703125e+00) (15, 1.50000000000000000000e+03) (16, 6.92738115787506103516e-01) (17, -4.96887922286987304688e+00) (18, -3.44947052001953125000e+00) (19, 1.20430302619934082031e+00) (20, 1.53274083137512207031e+00) (21, -1.81807112693786621094e+00) 
