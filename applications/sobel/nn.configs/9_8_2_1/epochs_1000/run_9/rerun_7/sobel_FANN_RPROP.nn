FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 3 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (3, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.73796200752258300781e+00) (1, -2.59078407287597656250e+00) (2, -1.46553754806518554688e+00) (3, 6.67942285537719726562e-01) (4, -1.09335172176361083984e+00) (5, 2.80672836303710937500e+00) (6, 2.12561130523681640625e+00) (7, -3.83598059415817260742e-01) (8, 4.53339624404907226562e+00) (9, -1.38473176956176757812e+00) (0, 9.42622601985931396484e-01) (1, -2.80141758918762207031e+00) (2, -1.91788226366043090820e-01) (3, 3.85544598102569580078e-01) (4, -9.74176228046417236328e-01) (5, 3.75055289268493652344e+00) (6, 1.24509096145629882812e+00) (7, -6.40286684036254882812e-01) (8, 3.90003037452697753906e+00) (9, -7.92362868785858154297e-01) (0, 2.17586636543273925781e+00) (1, -1.20785212516784667969e+00) (2, 4.21833902597427368164e-01) (3, -2.17565560340881347656e+00) (4, -1.02435576915740966797e+00) (5, 3.18517732620239257812e+00) (6, -9.85585117340087890625e+00) (7, 1.61974084377288818359e+00) (8, 6.33072566986083984375e+00) (9, -1.12605094909667968750e+00) (0, 1.48440253734588623047e+00) (1, -2.59372973442077636719e+00) (2, -1.38214147090911865234e+00) (3, 6.48607254028320312500e-01) (4, 4.79682050645351409912e-02) (5, 2.74314475059509277344e+00) (6, 1.81491017341613769531e+00) (7, -1.50339365005493164062e+00) (8, 4.34888124465942382812e+00) (9, -1.38666558265686035156e+00) (0, 2.99269461631774902344e+00) (1, -2.33433461189270019531e+00) (2, 4.75361436605453491211e-01) (3, 1.47987091541290283203e+00) (4, -7.17876791954040527344e-01) (5, 2.53094983100891113281e+00) (6, 1.42696726322174072266e+00) (7, 8.65473747253417968750e-01) (8, 1.80261003971099853516e+00) (9, -1.90251302719116210938e+00) (0, 2.41243720054626464844e+00) (1, -3.15951943397521972656e+00) (2, 9.12234008312225341797e-01) (3, 1.62735736370086669922e+00) (4, -6.60202741622924804688e-01) (5, 2.48112416267395019531e+00) (6, 2.25056385993957519531e+00) (7, 2.32513642311096191406e+00) (8, 2.41771960258483886719e+00) (9, -1.94037997722625732422e+00) (0, -1.74373149871826171875e-01) (1, -4.76341152191162109375e+00) (2, 2.18185596168041229248e-03) (3, 3.60005468130111694336e-01) (4, -7.99727588891983032227e-02) (5, 3.29877781867980957031e+00) (6, 1.11410784721374511719e+00) (7, 8.39847475290298461914e-02) (8, 5.95894718170166015625e+00) (9, -1.07879853248596191406e+00) (0, 1.80740761756896972656e+00) (1, -2.48209404945373535156e+00) (2, 1.33979451656341552734e+00) (3, 1.74036657810211181641e+00) (4, -5.07989883422851562500e-01) (5, 2.15279936790466308594e+00) (6, 1.96128201484680175781e+00) (7, 1.87185955047607421875e+00) (8, 3.02133226394653320312e+00) (9, -1.39658570289611816406e+00) (10, 7.14061927795410156250e+00) (11, 4.45037460327148437500e+00) (12, -2.57193684577941894531e+00) (13, 7.30360507965087890625e+00) (14, -6.07087659835815429688e+00) (15, -6.11087036132812500000e+00) (16, 2.12001848220825195312e+00) (17, -4.05944347381591796875e+00) (18, -1.14090585708618164062e+00) (10, 2.90402531623840332031e+00) (11, 1.08536505699157714844e+00) (12, -5.31466484069824218750e-01) (13, 1.56045579910278320312e+00) (14, 2.01789617538452148438e+00) (15, -4.69055223464965820312e+00) (16, -3.00342086702585220337e-02) (17, -1.29647099971771240234e+00) (18, 2.71676015853881835938e+00) (19, -4.42517471313476562500e+00) (20, 1.95386397838592529297e+00) (21, -4.67547863721847534180e-01) 
