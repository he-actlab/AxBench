FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 3 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (3, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.12147693634033203125e+01) (1, 8.88453769683837890625e+00) (2, 2.93351483345031738281e+00) (3, 1.49400782585144042969e+00) (4, 3.91342592239379882812e+00) (5, 3.73266398906707763672e-01) (6, -3.77469849586486816406e+00) (7, 1.18787813186645507812e+00) (8, -1.26547451019287109375e+01) (9, -8.81955251097679138184e-02) (0, -4.46797996759414672852e-01) (1, 9.75208663940429687500e+00) (2, -1.93479254841804504395e-01) (3, 4.31154578924179077148e-01) (4, 9.22491073608398437500e+00) (5, 2.01619356870651245117e-01) (6, -6.12968318164348602295e-02) (7, 1.62722599506378173828e+00) (8, -4.33141422271728515625e+00) (9, -4.30171775817871093750e+00) (0, 5.74063420295715332031e-01) (1, 8.74044322967529296875e+00) (2, -3.53854675292968750000e+01) (3, 8.70689213275909423828e-01) (4, 8.55996894836425781250e+00) (5, 7.90509939193725585938e-01) (6, 1.82292473316192626953e+00) (7, 1.30828323364257812500e+01) (8, -9.08316850662231445312e-01) (9, -2.75801205635070800781e+00) (0, 6.02425992488861083984e-01) (1, -8.13256740570068359375e+00) (2, 7.29813650250434875488e-02) (3, -2.16305200010538101196e-02) (4, -3.67613577842712402344e+00) (5, -1.48367241024971008301e-01) (6, 1.75558865070343017578e+00) (7, -1.16744863986968994141e+00) (8, 2.82070350646972656250e+00) (9, 1.19420158863067626953e+00) (0, -5.34699279785156250000e+02) (1, -1.15572900772094726562e+01) (2, -4.44201517105102539062e+00) (3, 6.59672319889068603516e-01) (4, -5.87801790237426757812e+00) (5, 4.67475473880767822266e-01) (6, 6.70157194137573242188e+00) (7, 5.09243631362915039062e+00) (8, 1.03998422622680664062e+01) (9, -1.27802419662475585938e+00) (0, 6.51125478744506835938e+00) (1, -8.54023933410644531250e+00) (2, 1.77870333194732666016e+00) (3, -1.91780424211174249649e-03) (4, -2.78333997726440429688e+00) (5, 2.51197719573974609375e+00) (6, 1.23611378669738769531e+00) (7, -1.33560597896575927734e+00) (8, 2.36547231674194335938e+00) (9, 1.08110213279724121094e+00) (0, -3.38865709304809570312e+00) (1, 8.09367656707763671875e+00) (2, 1.43505764007568359375e+00) (3, 1.22970700263977050781e+00) (4, 5.88213825225830078125e+00) (5, 1.03366005420684814453e+00) (6, 5.00062584877014160156e-01) (7, 1.93051624298095703125e+00) (8, -4.59059190750122070312e+00) (9, -1.87704354524612426758e-01) (0, 8.36872196197509765625e+00) (1, -5.65076971054077148438e+00) (2, 4.49861764907836914062e+00) (3, -8.88931572437286376953e-01) (4, -8.14493465423583984375e+00) (5, -8.45460593700408935547e-01) (6, 3.04523944854736328125e+00) (7, -1.24032235145568847656e+00) (8, 4.28334760665893554688e+00) (9, -1.20954252779483795166e-01) (10, 1.50000000000000000000e+03) (11, 1.41580410003662109375e+01) (12, 1.50000000000000000000e+03) (13, -4.37802246093750000000e+02) (14, 1.50000000000000000000e+03) (15, -2.65632939338684082031e+00) (16, -8.31148207187652587891e-01) (17, -1.73777179718017578125e+01) (18, -1.16629505157470703125e+00) (10, 2.44060592651367187500e+01) (11, 2.36101188659667968750e+01) (12, 1.50000000000000000000e+03) (13, -1.38636688232421875000e+02) (14, 1.50000000000000000000e+03) (15, -1.18426237106323242188e+01) (16, 1.05369782447814941406e+00) (17, -2.78817319869995117188e+00) (18, 5.59165000915527343750e-01) (19, 8.38065087795257568359e-01) (20, 1.61692667007446289062e+00) (21, -1.62308275699615478516e+00) 
