FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 3 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (3, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.00015821456909179688e+01) (1, 3.93715620040893554688e+00) (2, 1.48304593563079833984e+00) (3, 8.48353385925292968750e-01) (4, -1.07593405246734619141e+00) (5, -1.83255434036254882812e+00) (6, -1.89814150333404541016e+00) (7, 9.71355020999908447266e-01) (8, 1.58223891258239746094e+00) (9, -1.35851395130157470703e+00) (0, -1.90944051742553710938e+00) (1, -5.31422793865203857422e-01) (2, 2.58749651908874511719e+00) (3, -6.59572267532348632812e+00) (4, 4.64877545833587646484e-01) (5, 4.11203241348266601562e+00) (6, -4.03522223234176635742e-01) (7, 5.77899754047393798828e-01) (8, 1.62562727928161621094e+00) (9, 6.20627515017986297607e-02) (0, -9.95518875122070312500e+00) (1, 3.68472838401794433594e+00) (2, -6.58157634735107421875e+00) (3, 8.67467164993286132812e-01) (4, 1.71687602996826171875e+00) (5, 1.35112452507019042969e+00) (6, -3.12441587448120117188e+00) (7, 5.51037371158599853516e-01) (8, 6.15140008926391601562e+00) (9, -1.22414767742156982422e+00) (0, -1.35933799743652343750e+01) (1, -4.48839759826660156250e+00) (2, -5.31261539459228515625e+00) (3, 1.31695833206176757812e+01) (4, 1.73913514614105224609e+00) (5, 1.53511643409729003906e+00) (6, 5.29890298843383789062e-01) (7, -1.02338120341300964355e-01) (8, 1.14697480201721191406e+00) (9, -1.16910770535469055176e-01) (0, -1.12256669998168945312e+01) (1, 4.69303035736083984375e+00) (2, 5.06782007217407226562e+00) (3, 1.33795976638793945312e+00) (4, -2.32594490051269531250e+00) (5, -4.27149152755737304688e+00) (6, 4.42702382802963256836e-01) (7, -1.20498023927211761475e-01) (8, 3.46271514892578125000e+00) (9, -1.48182880878448486328e+00) (0, 1.49635974121093750000e+03) (1, 9.30202102661132812500e+00) (2, 1.48820568847656250000e+03) (3, 1.49434912109375000000e+03) (4, 1.05836057662963867188e+00) (5, 1.64287900924682617188e+00) (6, 1.30990254878997802734e+00) (7, 2.64962524175643920898e-01) (8, 3.35780501365661621094e-01) (9, -1.18642544746398925781e+00) (0, -1.43171167373657226562e+01) (1, -9.86840128898620605469e-01) (2, -5.09729909896850585938e+00) (3, 1.41797294616699218750e+01) (4, 1.64473581314086914062e+00) (5, 1.13183403015136718750e+00) (6, 6.52946352958679199219e-01) (7, -2.34403896331787109375e+00) (8, 4.23385977745056152344e-01) (9, -9.40001368522644042969e-01) (0, -7.68918097019195556641e-01) (1, -8.95740318298339843750e+00) (2, -1.56954181194305419922e+00) (3, -1.55431532859802246094e+00) (4, -7.13943690061569213867e-02) (5, -1.70338779687881469727e-01) (6, -2.98263520002365112305e-01) (7, 6.28562831878662109375e+00) (8, 6.27098608016967773438e+00) (9, 1.74437832832336425781e+00) (10, 3.12028288841247558594e+00) (11, -3.46690201759338378906e+00) (12, 2.70035386085510253906e+00) (13, 6.22934722900390625000e+00) (14, 4.35439538955688476562e+00) (15, 6.90375423431396484375e+00) (16, 1.29318313598632812500e+01) (17, -1.56340980529785156250e+01) (18, 1.96415948867797851562e+00) (10, 2.09043359756469726562e+00) (11, -2.35257673263549804688e+00) (12, 3.11325454711914062500e+00) (13, 5.33655834197998046875e+00) (14, 3.48696112632751464844e+00) (15, 4.19773578643798828125e+00) (16, 2.77939176559448242188e+00) (17, -1.41601390838623046875e+01) (18, 3.96554303169250488281e+00) (19, 6.53895497322082519531e-01) (20, 2.37676858901977539062e+00) (21, -2.13646006584167480469e+00) 
