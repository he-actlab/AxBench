FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 9 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 3.88706386089324951172e-01) (1, 1.10456228256225585938e-01) (2, -1.31422305107116699219e+00) (3, -1.93692016601562500000e+00) (4, -2.04701113700866699219e+00) (5, -1.86935305595397949219e+00) (6, 2.73820757865905761719e+00) (7, -2.04266595840454101562e+00) (8, 1.38796317577362060547e+00) (9, -8.31514239311218261719e-01) (0, 3.34383696317672729492e-01) (1, 8.64471054077148437500e+00) (2, -3.40299201011657714844e+00) (3, -2.93060612678527832031e+00) (4, -2.85986828804016113281e+00) (5, -1.63136601448059082031e+00) (6, 4.60444688796997070312e+00) (7, -3.90750193595886230469e+00) (8, 2.56955802440643310547e-01) (9, -1.57120752334594726562e+00) (0, 8.94244313240051269531e-02) (1, -6.80587887763977050781e-02) (2, -4.52910304069519042969e-01) (3, -1.22966253757476806641e+00) (4, -1.31346714496612548828e+00) (5, -4.46883153915405273438e+00) (6, 4.43556690216064453125e+00) (7, -9.18693125247955322266e-01) (8, 3.17057776451110839844e+00) (9, -2.07089591026306152344e+00) (0, -7.17336773872375488281e-01) (1, 2.86016285419464111328e-01) (2, -1.44079387187957763672e+00) (3, -2.04292654991149902344e+00) (4, -1.74950718879699707031e+00) (5, -2.74084258079528808594e+00) (6, 1.61224114894866943359e+00) (7, -1.45361828804016113281e+00) (8, 2.14169168472290039062e+00) (9, -7.35908925533294677734e-01) (0, -1.25569931030273437500e+02) (1, 3.61624062061309814453e-02) (2, -4.45276069641113281250e+00) (3, 1.82361740112304687500e+02) (4, -2.05483770370483398438e+00) (5, -2.26349182128906250000e+01) (6, -1.94313125610351562500e+01) (7, -2.39427185058593750000e+01) (8, 2.15433812141418457031e+00) (9, -3.92168021202087402344e+00) (0, 1.73164343833923339844e+00) (1, -1.61453276872634887695e-01) (2, -1.29076743125915527344e+00) (3, -1.49736185073852539062e+01) (4, -3.56851506233215332031e+00) (5, -4.45947980880737304688e+00) (6, -9.98901307582855224609e-01) (7, 2.53945648670196533203e-01) (8, 6.51210641860961914062e+00) (9, 7.80754745006561279297e-01) (0, 1.42634260654449462891e+00) (1, 7.80447661876678466797e-01) (2, 2.75798821449279785156e+00) (3, 2.24281743168830871582e-01) (4, -7.64964163303375244141e-01) (5, -1.04551589488983154297e+00) (6, 5.19544601440429687500e+00) (7, 5.56445121765136718750e-01) (8, 3.88850903511047363281e+00) (9, -7.81150865554809570312e+00) (0, -3.05440759658813476562e+00) (1, 6.67054593563079833984e-01) (2, -8.81481170654296875000e+00) (3, -1.18533868789672851562e+01) (4, -1.09129695892333984375e+01) (5, -1.69931209087371826172e+00) (6, 1.71323084831237792969e+00) (7, -5.87899863719940185547e-01) (8, 7.08771848678588867188e+00) (9, 8.31359195709228515625e+00) (10, -1.29224328994750976562e+01) (11, -2.73068606853485107422e-01) (12, -6.88878774642944335938e-01) (13, -7.07605540752410888672e-01) (14, -4.31499338150024414062e+00) (15, 4.14574003219604492188e+00) (16, -8.33894348144531250000e+00) (17, -1.39758825302124023438e+00) (18, 6.55428469181060791016e-01) (10, -7.10098743438720703125e+00) (11, -2.75814592838287353516e-01) (12, -3.42942595481872558594e-01) (13, -6.66440784931182861328e-01) (14, 5.77133893966674804688e+00) (15, 7.21466064453125000000e-01) (16, -8.82988262176513671875e+00) (17, -2.46181130409240722656e+00) (18, 8.10830414295196533203e-01) (10, -1.29035472869873046875e+01) (11, -3.22611004114151000977e-01) (12, -7.47741222381591796875e-01) (13, -6.18057429790496826172e-01) (14, -5.02698945999145507812e+00) (15, 4.15701675415039062500e+00) (16, -8.33405971527099609375e+00) (17, -1.32755303382873535156e+00) (18, 6.60569965839385986328e-01) (10, -1.18297157287597656250e+01) (11, 3.80004346370697021484e-02) (12, -6.14192962646484375000e-01) (13, -5.37971377372741699219e-01) (14, 9.96986484527587890625e+00) (15, 1.13762211799621582031e+00) (16, -8.59715270996093750000e+00) (17, -1.53370416164398193359e+00) (18, 7.78812825679779052734e-01) (10, 9.19345092773437500000e+00) (11, -2.67745912075042724609e-01) (12, 1.20035705566406250000e+01) (13, -2.34816551208496093750e+00) (14, 2.67143188476562500000e+02) (15, 9.17596530914306640625e+00) (16, -9.16908359527587890625e+00) (17, -4.82809019088745117188e+00) (18, 2.76042610406875610352e-01) (10, 3.45354766845703125000e+01) (11, 1.44631311297416687012e-01) (12, 1.31080413818359375000e+02) (13, 3.86983603239059448242e-01) (14, 2.67143188476562500000e+02) (15, -3.30177276611328125000e+02) (16, -2.95604019165039062500e+01) (17, -1.76878738403320312500e+01) (18, 3.27693164348602294922e-01) (10, -4.58274459838867187500e+00) (11, -1.81036293506622314453e+00) (12, 1.06543064117431640625e+01) (13, 1.16960358619689941406e+00) (14, -7.83309097290039062500e+01) (15, 3.82586932182312011719e+00) (16, -8.21637058258056640625e+00) (17, -3.58488631248474121094e+00) (18, 4.63609606027603149414e-01) (10, -1.15927810668945312500e+01) (11, -3.96800041198730468750e-01) (12, 9.49705004692077636719e-01) (13, -8.52755904197692871094e-01) (14, -3.60586881637573242188e+00) (15, 7.36720621585845947266e-01) (16, -7.44415092468261718750e+00) (17, -1.14717316627502441406e+00) (18, 3.27807396650314331055e-01) (19, 1.38529741764068603516e+00) (20, 9.79454040527343750000e-01) (21, 1.35857677459716796875e+00) (22, 9.20884728431701660156e-01) (23, 7.42374598979949951172e-01) (24, 7.05242156982421875000e-01) (25, 5.57491064071655273438e-01) (26, 9.68802034854888916016e-01) (27, -2.49655771255493164062e+00) 
