FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 9 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.49856579589843750000e+03) (1, 1.04260021972656250000e+03) (2, 1.49937768554687500000e+03) (3, 1.49330163574218750000e+03) (4, 1.49254602050781250000e+03) (5, 1.49198791503906250000e+03) (6, 1.49016369628906250000e+03) (7, 1.49934436035156250000e+03) (8, 1.49966162109375000000e+03) (9, 7.60628795623779296875e+00) (0, 7.67300486564636230469e-01) (1, 7.93363094329833984375e-01) (2, -6.27864181995391845703e-01) (3, 3.05697441101074218750e-01) (4, 2.85340285301208496094e+00) (5, -6.30516719818115234375e+00) (6, 1.53202223777770996094e+00) (7, 1.93692321777343750000e+01) (8, 1.06050481796264648438e+01) (9, -1.31817781925201416016e+00) (0, 5.15423834323883056641e-01) (1, 1.95634257793426513672e+00) (2, 1.98460960388183593750e+01) (3, -5.11975526809692382812e+00) (4, -3.41000723838806152344e+00) (5, -2.50756549835205078125e+01) (6, 5.57690334320068359375e+00) (7, -3.45390844345092773438e+00) (8, 1.46712837219238281250e+01) (9, -3.70547026395797729492e-01) (0, 2.91012859344482421875e+00) (1, 7.46760129928588867188e-01) (2, 9.52386617660522460938e-01) (3, 1.44294719696044921875e+01) (4, 2.27499079704284667969e+00) (5, 2.55471527576446533203e-01) (6, 3.68033409118652343750e+01) (7, 2.08409100770950317383e-01) (8, 1.12014257907867431641e+00) (9, 4.73785829544067382812e+00) (0, -3.99304318428039550781e+00) (1, -4.51871037483215332031e-01) (2, 1.57892017364501953125e+01) (3, 3.48998618125915527344e+00) (4, 8.61792373657226562500e+00) (5, 1.02082967758178710938e+01) (6, 1.49945507812500000000e+03) (7, 1.50000000000000000000e+03) (8, 1.50000000000000000000e+03) (9, -1.35250606536865234375e+01) (0, -1.19628405570983886719e+00) (1, -3.21365833282470703125e-01) (2, -1.15883004665374755859e+00) (3, 2.77543723583221435547e-01) (4, 3.59650945663452148438e+00) (5, 8.45120549201965332031e-01) (6, -4.66899251937866210938e+00) (7, 5.33942222595214843750e-01) (8, -1.02961683273315429688e+00) (9, 7.35539078712463378906e-01) (0, 6.72730386257171630859e-01) (1, 8.31035017967224121094e-01) (2, 8.76903343200683593750e+00) (3, -4.14226949214935302734e-01) (4, -5.35801351070404052734e-01) (5, 6.33941841125488281250e+00) (6, 1.00742411613464355469e+00) (7, -1.80889594554901123047e+00) (8, 9.51787889003753662109e-01) (9, -5.28646183013916015625e+00) (0, 3.37342917919158935547e-01) (1, 3.89910638332366943359e-01) (2, 3.42063379287719726562e+00) (3, 3.80720794200897216797e-01) (4, 1.05751290917396545410e-01) (5, 1.42262160778045654297e+00) (6, -4.94050645828247070312e+00) (7, -3.62928450107574462891e-01) (8, -1.82052123546600341797e+00) (9, -2.86008138209581375122e-02) (10, 4.47409510612487792969e-01) (11, 6.45661711692810058594e-01) (12, 6.17192932128906250000e+02) (13, 1.27407085895538330078e+00) (14, -1.06284843444824218750e+02) (15, 3.14036926269531250000e+02) (16, -6.70741424560546875000e+01) (17, -1.08151865005493164062e+00) (18, -1.21393609046936035156e+00) (10, -3.40040147304534912109e-01) (11, 1.60758003592491149902e-01) (12, 1.44437444210052490234e+00) (13, 2.77990877628326416016e-01) (14, 1.13181381225585937500e+01) (15, 1.90728485584259033203e+00) (16, -3.59190082550048828125e+00) (17, -1.71687030792236328125e+01) (18, -1.54693448543548583984e+00) (10, -5.79646492004394531250e+00) (11, -1.10249011230468750000e+03) (12, 1.49864624023437500000e+03) (13, -4.58239078521728515625e+00) (14, -1.07200813293457031250e+01) (15, -1.10205798339843750000e+03) (16, 4.28414016962051391602e-01) (17, -1.44417438507080078125e+01) (18, -1.36654806137084960938e+00) (10, 1.93628281354904174805e-01) (11, 6.32557928562164306641e-01) (12, 2.15010955810546875000e+02) (13, 1.51162552833557128906e+00) (14, -1.01306999206542968750e+02) (15, -2.53381881713867187500e+02) (16, 2.03594088554382324219e+00) (17, -3.65603899955749511719e+00) (18, -1.56112039089202880859e+00) (10, -6.67205154895782470703e-01) (11, -1.06066381931304931641e+00) (12, -2.31981325149536132812e+00) (13, -6.95816040039062500000e-01) (14, -2.24622535705566406250e+00) (15, 3.24077720642089843750e+01) (16, -1.44978511333465576172e+00) (17, -3.96465897560119628906e-01) (18, -4.82019126415252685547e-01) (10, -4.81781810522079467773e-01) (11, -2.62156039476394653320e-01) (12, -1.25265955924987792969e+00) (13, -3.99994552135467529297e-01) (14, -1.98726868629455566406e+00) (15, 2.53871345520019531250e+01) (16, -1.02657103538513183594e+00) (17, -2.24275410175323486328e-01) (18, -6.27672299742698669434e-02) (10, -3.22118014097213745117e-01) (11, -1.56387344360351562500e+02) (12, 1.46781042480468750000e+03) (13, -9.75374519824981689453e-01) (14, -2.23673721313476562500e+02) (15, 6.18897094726562500000e+02) (16, 4.62853997945785522461e-01) (17, 1.36845855712890625000e+01) (18, 4.84012931585311889648e-01) (10, -1.13546586036682128906e+00) (11, 1.50000000000000000000e+03) (12, -1.44346276855468750000e+03) (13, 6.63124918937683105469e-01) (14, 1.50000000000000000000e+03) (15, 1.28830773925781250000e+03) (16, 1.50000000000000000000e+03) (17, 3.52568054199218750000e+01) (18, -1.00716844201087951660e-01) (19, -3.71203124523162841797e-01) (20, -2.19071865081787109375e+00) (21, 7.15550661087036132812e-01) (22, 1.79319277405738830566e-01) (23, 2.01502966880798339844e+00) (24, 1.29844951629638671875e+00) (25, -2.18720793724060058594e+00) (26, 3.32502186298370361328e-01) (27, -2.12112292647361755371e-01) 
