FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 9 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 2.06868286132812500000e+01) (1, -1.17863070964813232422e+00) (2, -8.58381390571594238281e-01) (3, -1.29059290885925292969e+00) (4, -2.20900201797485351562e+00) (5, -4.60993558168411254883e-01) (6, -1.98154985904693603516e+00) (7, -5.79366683959960937500e+00) (8, -1.54958546161651611328e+00) (9, -9.97061669826507568359e-01) (0, 2.02728843688964843750e+01) (1, -1.84721672534942626953e+00) (2, -1.18942773342132568359e+00) (3, -9.62359666824340820312e-01) (4, -1.34289562702178955078e+00) (5, -3.61515074968338012695e-01) (6, -8.50592422485351562500e+00) (7, -1.81737446784973144531e+00) (8, -4.31467533111572265625e+00) (9, -8.68512272834777832031e-01) (0, 2.20389251708984375000e+01) (1, 8.35412293672561645508e-02) (2, -4.20692205429077148438e+00) (3, -8.91633212566375732422e-01) (4, -1.09786033630371093750e+00) (5, -1.67225256562232971191e-01) (6, -2.11518073081970214844e+00) (7, -1.63415825366973876953e+00) (8, -1.90878897905349731445e-01) (9, -8.11011731624603271484e-01) (0, 8.78643321990966796875e+00) (1, -4.65449428558349609375e+00) (2, 5.30225467681884765625e+00) (3, 9.32661771774291992188e-01) (4, -8.41108894348144531250e+00) (5, -4.09460276365280151367e-01) (6, -1.47523963451385498047e+00) (7, -1.68447569012641906738e-01) (8, -4.00711536407470703125e-01) (9, -3.25252264738082885742e-01) (0, 1.97167434692382812500e+01) (1, -3.84604543447494506836e-01) (2, -2.95062541961669921875e-01) (3, -1.17227964103221893311e-01) (4, -2.71881628036499023438e+00) (5, -4.23641800880432128906e-01) (6, -2.40620255470275878906e+00) (7, -7.58846616744995117188e+00) (8, -4.93577361106872558594e-01) (9, -7.54974365234375000000e-01) (0, 6.06417131423950195312e+00) (1, -6.13450860977172851562e+00) (2, 7.58219528198242187500e+00) (3, 1.65466964244842529297e+00) (4, -7.46313381195068359375e+00) (5, -1.87293577194213867188e+00) (6, 4.98114061355590820312e+00) (7, -2.77079135179519653320e-01) (8, -8.37814867496490478516e-01) (9, -1.69140183925628662109e+00) (0, -4.08424797058105468750e+01) (1, -2.50649547576904296875e+00) (2, 4.00562591552734375000e+01) (3, -1.46604537963867187500e-01) (4, -3.56021493673324584961e-01) (5, 7.57530868053436279297e-01) (6, -5.72870433330535888672e-01) (7, 5.08427047729492187500e+00) (8, 1.04716527462005615234e+00) (9, -4.64125245809555053711e-01) (0, 1.62343406677246093750e+01) (1, -5.26068735122680664062e+00) (2, 5.99554061889648437500e-01) (3, -2.90599197149276733398e-01) (4, -3.91035348176956176758e-01) (5, 1.60410356521606445312e+00) (6, -4.22740316390991210938e+00) (7, -2.05894619226455688477e-01) (8, 1.81189012527465820312e+00) (9, -2.73828536272048950195e-01) (10, -6.62214532494544982910e-02) (11, -2.12671399116516113281e-01) (12, 6.08148872852325439453e-01) (13, -5.21737909317016601562e+00) (14, -8.36365371942520141602e-02) (15, -7.33597373962402343750e+00) (16, -9.54651355743408203125e-01) (17, 1.18586421012878417969e-01) (18, 1.77347576618194580078e+00) (10, -3.52546609938144683838e-02) (11, -1.27900570631027221680e-01) (12, -1.48376077413558959961e-02) (13, 2.24684521555900573730e-01) (14, -1.52420371770858764648e-01) (15, -9.27753067016601562500e+00) (16, 1.07911806106567382812e+01) (17, -1.62558495998382568359e-01) (18, 5.05508563946932554245e-04) (10, 2.01429635286331176758e-01) (11, 7.65859723091125488281e-01) (12, -1.05212259292602539062e+00) (13, 9.06127071380615234375e+00) (14, -4.82907034456729888916e-02) (15, 2.06817936897277832031e+00) (16, 4.18588876724243164062e-01) (17, -5.40755212306976318359e-01) (18, 2.68448386341333389282e-02) (10, -2.03400835394859313965e-01) (11, -1.13799378275871276855e-01) (12, 1.95112302899360656738e-01) (13, -3.00531363487243652344e+00) (14, -1.13901861011981964111e-01) (15, -7.48059797286987304688e+00) (16, -9.89930748939514160156e-01) (17, 3.37116159498691558838e-02) (18, 1.77458333969116210938e+00) (10, -3.60314212739467620850e-02) (11, -1.12796910107135772705e-01) (12, 1.25045657157897949219e+00) (13, -1.12721872329711914062e+01) (14, 1.04858562350273132324e-01) (15, -5.60538387298583984375e+00) (16, -9.08593356609344482422e-01) (17, 4.71260786056518554688e-01) (18, 1.68713736534118652344e+00) (10, -9.80832576751708984375e-02) (11, -8.58889371156692504883e-02) (12, 4.50362861156463623047e-01) (13, -3.65130281448364257812e+00) (14, -1.13775223493576049805e-01) (15, -8.37132072448730468750e+00) (16, -9.30731594562530517578e-01) (17, 1.63742616772651672363e-01) (18, 1.78541862964630126953e+00) (10, 3.50874572992324829102e-01) (11, 3.23437571525573730469e+00) (12, 2.90644824504852294922e-01) (13, 5.47212362289428710938e+00) (14, 3.19404065608978271484e-01) (15, -7.31214618682861328125e+00) (16, 2.33784511685371398926e-01) (17, 2.66797959804534912109e-01) (18, 1.17128595709800720215e-01) (10, -2.25539517402648925781e+00) (11, -2.94026327133178710938e+00) (12, -2.13398575782775878906e+00) (13, 1.50437631607055664062e+01) (14, -2.28158879280090332031e+00) (15, 8.26676940917968750000e+00) (16, -1.57880872488021850586e-01) (17, -1.64857172966003417969e+00) (18, -1.39557874202728271484e+00) (19, 1.21607255935668945312e+00) (20, -1.74582302570343017578e+00) (21, -9.34600055217742919922e-01) (22, 1.19965577125549316406e+00) (23, 1.58968830108642578125e+00) (24, 1.20363295078277587891e+00) (25, -1.02753496170043945312e+00) (26, 3.09974193572998046875e+00) (27, -2.54438906908035278320e-01) 
