FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 9 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.50000000000000000000e+03) (1, 1.50000000000000000000e+03) (2, 5.21481201171875000000e+02) (3, 5.63234436035156250000e+02) (4, 8.38285766601562500000e+02) (5, 6.84668395996093750000e+02) (6, -1.45998254394531250000e+03) (7, 1.52795553207397460938e+00) (8, -6.73873107910156250000e+02) (9, 4.78779411315917968750e+01) (0, 6.69340229034423828125e+00) (1, -4.25950145721435546875e+00) (2, 3.66985559463500976562e+00) (3, -9.75444167852401733398e-02) (4, -9.46129417419433593750e+00) (5, -8.28107595443725585938e-01) (6, 6.92107439041137695312e+00) (7, -8.79608631134033203125e-01) (8, -1.05476868152618408203e+00) (9, -6.40547096729278564453e-01) (0, 3.02227001190185546875e+01) (1, -3.02163219451904296875e+00) (2, 1.21213960647583007812e+00) (3, -1.85811843872070312500e+01) (4, -4.34104502201080322266e-01) (5, 1.52032762765884399414e-01) (6, -4.45992040634155273438e+00) (7, 2.54583072662353515625e+00) (8, 1.37459194660186767578e+00) (9, 4.07739542424678802490e-03) (0, 3.12428331375122070312e+00) (1, -8.77932643890380859375e+00) (2, 4.82030153274536132812e+00) (3, 9.62408959865570068359e-01) (4, -7.08493947982788085938e+00) (5, -1.37345027923583984375e+00) (6, 8.94477462768554687500e+00) (7, 4.10120069980621337891e-01) (8, -3.90473276376724243164e-01) (9, -3.27394276857376098633e-01) (0, 3.32372322082519531250e+01) (1, -2.58911228179931640625e+00) (2, 1.86487960815429687500e+00) (3, -1.85225620269775390625e+01) (4, -5.82580327987670898438e-01) (5, -2.18925520777702331543e-01) (6, -6.84558486938476562500e+00) (7, -4.68825995922088623047e-01) (8, 2.77710366249084472656e+00) (9, 6.54353201389312744141e-02) (0, 4.95608043670654296875e+00) (1, -4.56312990188598632812e+00) (2, 4.22333288192749023438e+00) (3, 3.98836880922317504883e-01) (4, -5.00304651260375976562e+00) (5, -1.04282751083374023438e+01) (6, 1.96296501159667968750e+01) (7, -8.29373836517333984375e-01) (8, -1.21839845180511474609e+00) (9, -9.44623947143554687500e-01) (0, 3.09158725738525390625e+01) (1, -3.76315742731094360352e-01) (2, 2.36561131477355957031e+00) (3, -1.22151041030883789062e+01) (4, -3.05234849452972412109e-01) (5, 3.85832458734512329102e-01) (6, -1.09704313278198242188e+01) (7, 1.75755888223648071289e-01) (8, 4.44924533367156982422e-01) (9, 4.53806459903717041016e-01) (0, 1.50909833908081054688e+01) (1, 3.82966661453247070312e+00) (2, 3.10513858795166015625e+01) (3, -2.04955482482910156250e+00) (4, -7.83799934387207031250e+00) (5, 4.48320627212524414062e+00) (6, -3.85484733581542968750e+01) (7, 1.87551617622375488281e+00) (8, 2.73988461494445800781e+00) (9, -5.25202274322509765625e-01) (10, -1.41257977485656738281e+00) (11, 6.76794886589050292969e-01) (12, -2.33971506357192993164e-01) (13, 1.52627401351928710938e+01) (14, -9.75642502307891845703e-01) (15, 8.41708183288574218750e+00) (16, -2.14104324579238891602e-01) (17, -1.02647495269775390625e+00) (18, -1.73372864723205566406e-01) (10, -6.77681446075439453125e-01) (11, -4.78704528808593750000e+01) (12, 2.23443340510129928589e-02) (13, 4.54636306762695312500e+01) (14, -2.63754814863204956055e-01) (15, 1.36794960498809814453e+00) (16, 1.09045588970184326172e+00) (17, -8.11025977134704589844e-01) (18, -1.14338123798370361328e+00) (10, -9.16176617145538330078e-01) (11, 1.82998907566070556641e+00) (12, -8.20500731468200683594e-01) (13, -7.97853410243988037109e-01) (14, -7.45163142681121826172e-01) (15, -5.18808424472808837891e-01) (16, -4.79824095964431762695e-01) (17, -9.73729193210601806641e-01) (18, 9.24692809581756591797e-01) (10, 8.85264039039611816406e-01) (11, -5.21712303161621093750e+00) (12, 3.90120148658752441406e-01) (13, -1.58047218322753906250e+01) (14, 5.26469290256500244141e-01) (15, -6.91025972366333007812e+00) (16, 4.22278493642807006836e-01) (17, 7.78925001621246337891e-01) (18, 1.45457494258880615234e+00) (10, -1.55513703823089599609e+00) (11, 7.62263679504394531250e+00) (12, -1.05858707427978515625e+00) (13, 3.52017045021057128906e+00) (14, -7.46504783630371093750e-01) (15, 1.36174130439758300781e+00) (16, -7.60405480861663818359e-01) (17, -1.75068855285644531250e+00) (18, 6.67614281177520751953e-01) (10, 7.97117888927459716797e-01) (11, 3.31224441528320312500e-01) (12, 1.75010037422180175781e+00) (13, -8.17230403423309326172e-01) (14, 1.72699105739593505859e+00) (15, -3.09610843658447265625e+00) (16, 1.12544584274291992188e+00) (17, 2.52621960639953613281e+00) (18, -1.18927443027496337891e+00) (10, -8.35729062557220458984e-01) (11, -3.96776962280273437500e+01) (12, -7.09210485219955444336e-02) (13, 4.81478614807128906250e+01) (14, -3.43975722789764404297e-01) (15, 2.87135982513427734375e+00) (16, 1.07716631889343261719e+00) (17, -1.40323507785797119141e+00) (18, -1.14180827140808105469e+00) (10, -5.22873222827911376953e-01) (11, 2.98381543159484863281e+00) (12, -5.10246574878692626953e-01) (13, 1.23764061927795410156e+00) (14, -6.25510394573211669922e-01) (15, -4.53290313482284545898e-01) (16, -6.21713757514953613281e-01) (17, -9.11326289176940917969e-01) (18, 6.44195795059204101562e-01) (19, -6.63218557834625244141e-01) (20, -6.74148380756378173828e-01) (21, 1.93876349925994873047e+00) (22, 1.92929148674011230469e+00) (23, 2.24138092994689941406e+00) (24, -7.15824604034423828125e-01) (25, -1.64084053039550781250e+00) (26, 1.40291798114776611328e+00) (27, -4.28236246109008789062e-01) 
