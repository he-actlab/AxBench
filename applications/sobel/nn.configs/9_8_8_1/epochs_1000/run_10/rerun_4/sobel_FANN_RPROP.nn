FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 9 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -3.66593807935714721680e-01) (1, 4.35828733444213867188e+00) (2, 4.90939855575561523438e+00) (3, -1.21361911296844482422e-01) (4, -9.11311805248260498047e-02) (5, -1.56139445304870605469e+00) (6, -2.23075240850448608398e-01) (7, -2.48736500740051269531e+00) (8, -4.77945947647094726562e+00) (9, 5.00957429409027099609e-01) (0, -3.96858620643615722656e+00) (1, -2.45899796485900878906e+00) (2, -1.61115419864654541016e+00) (3, -4.89594340324401855469e-01) (4, 3.07045888900756835938e+00) (5, 3.40506613254547119141e-01) (6, -5.52537441253662109375e+00) (7, 1.19517726898193359375e+01) (8, -3.27662289142608642578e-01) (9, -9.32273507118225097656e-01) (0, 1.58719539642333984375e+00) (1, 1.73806607723236083984e+00) (2, 4.46718311309814453125e+00) (3, 1.01358860731124877930e-01) (4, 1.56110391020774841309e-01) (5, -2.67157745361328125000e+00) (6, -6.34995162487030029297e-01) (7, -9.26184475421905517578e-01) (8, -2.19760203361511230469e+00) (9, 1.45112350583076477051e-01) (0, 1.17339169979095458984e+00) (1, 6.75157308578491210938e+00) (2, -4.58780670166015625000e+00) (3, 2.04406052827835083008e-01) (4, 8.54375120252370834351e-03) (5, -4.14801931381225585938e+00) (6, 7.18735009431838989258e-02) (7, -8.02073068916797637939e-03) (8, -8.63588333129882812500e+00) (9, 3.19059014320373535156e-01) (0, -9.91296958923339843750e+00) (1, -4.53262120485305786133e-01) (2, -1.00962686538696289062e+00) (3, 1.16033279895782470703e+00) (4, 5.61674022674560546875e+00) (5, 6.66411340236663818359e-01) (6, -2.90806770324707031250e+00) (7, 4.20943289995193481445e-01) (8, 6.07197475433349609375e+00) (9, -9.32284295558929443359e-01) (0, -4.18960779905319213867e-01) (1, 4.10645866394042968750e+00) (2, 2.75111174583435058594e+00) (3, 4.59807276725769042969e-01) (4, -1.89594719558954238892e-02) (5, -1.50900518894195556641e+00) (6, -5.95138978958129882812e+00) (7, -9.84374433755874633789e-02) (8, -5.02763652801513671875e+00) (9, 2.94105887413024902344e-01) (0, -1.49620324707031250000e+03) (1, -9.99205172061920166016e-01) (2, -7.44661867618560791016e-01) (3, -1.63420531898736953735e-02) (4, 2.24201127886772155762e-01) (5, 2.22584471106529235840e-01) (6, 1.30667173862457275391e+00) (7, -6.68981671333312988281e-01) (8, 3.53218650817871093750e+00) (9, -1.62643563747406005859e+00) (0, -1.03571424484252929688e+01) (1, -9.65864002704620361328e-01) (2, -1.58472537994384765625e+00) (3, 6.54190480709075927734e-01) (4, 5.96618556976318359375e+00) (5, 3.08010697364807128906e+00) (6, -2.42751073837280273438e+00) (7, 4.13783863186836242676e-02) (8, 4.81886529922485351562e+00) (9, -1.49211406707763671875e+00) (10, -4.97860097885131835938e+00) (11, -1.31813831329345703125e+01) (12, 1.13740670680999755859e+00) (13, 1.16043214797973632812e+01) (14, 3.35302972793579101562e+00) (15, 2.71435909271240234375e+01) (16, 1.94685745239257812500e+00) (17, 2.97953338623046875000e+01) (18, -7.53885447978973388672e-01) (10, -2.59387786865234375000e+02) (11, -6.60317016601562500000e+02) (12, 4.55109643936157226562e+00) (13, 9.05827026367187500000e+02) (14, -2.02073715209960937500e+02) (15, -3.87123756408691406250e+01) (16, 3.59344005584716796875e+00) (17, -6.53415771484375000000e+02) (18, 9.17472660541534423828e-01) (10, -1.79444503784179687500e+00) (11, 1.61150951385498046875e+01) (12, -1.08341729640960693359e+00) (13, -1.06670742034912109375e+01) (14, -3.47231364250183105469e+00) (15, -2.26195383071899414062e+00) (16, -8.30821132659912109375e+00) (17, -8.06885051727294921875e+00) (18, 4.67040956020355224609e-01) (10, 1.22007095813751220703e+00) (11, -1.61355113983154296875e+01) (12, 1.22368514537811279297e+00) (13, -7.13685607910156250000e+00) (14, 3.04252862930297851562e+00) (15, 2.77694511413574218750e+00) (16, 1.05172691345214843750e+01) (17, 9.79548072814941406250e+00) (18, 1.35026231408119201660e-01) (10, 4.31581139564514160156e-01) (11, -1.82797374725341796875e+01) (12, 2.57728195190429687500e+00) (13, 1.39070568084716796875e+01) (14, 1.49691832065582275391e+00) (15, 4.32112693786621093750e+00) (16, 2.27224235534667968750e+01) (17, 7.46911144256591796875e+00) (18, -4.36835378408432006836e-01) (10, -7.99158020019531250000e+01) (11, 1.50000000000000000000e+03) (12, -8.25270843505859375000e+01) (13, -6.39287841796875000000e+02) (14, 1.08789924621582031250e+02) (15, -2.40860614776611328125e+01) (16, 1.49944628906250000000e+03) (17, 2.92522945404052734375e+01) (18, -1.10972940921783447266e+00) (10, 8.54049086570739746094e-01) (11, 6.49038085937500000000e+01) (12, -1.17410391569137573242e-01) (13, -4.18666687011718750000e+01) (14, -6.64732599258422851562e+00) (15, -9.06864738464355468750e+00) (16, 7.27341711521148681641e-01) (17, -1.44929814338684082031e+00) (18, 1.01429603993892669678e-01) (10, -1.95024073123931884766e+00) (11, 1.64272460937500000000e+01) (12, -1.37352812290191650391e+00) (13, -1.14477167129516601562e+01) (14, -9.91326451301574707031e-01) (15, -2.63827419281005859375e+00) (16, -8.65008354187011718750e+00) (17, -1.06151180267333984375e+01) (18, 4.10378783941268920898e-01) (19, 9.74085748195648193359e-01) (20, -2.54103001207113265991e-02) (21, -2.03405785560607910156e+00) (22, 8.68648197501897811890e-03) (23, -8.14338400959968566895e-02) (24, 6.42362087965011596680e-02) (25, 4.75503861904144287109e-01) (26, -9.97539579868316650391e-01) (27, -1.96865834295749664307e-02) 
