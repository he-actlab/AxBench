FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 9 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.96115577220916748047e-01) (1, -2.64142066240310668945e-01) (2, -4.18313533067703247070e-01) (3, -3.54170024394989013672e-01) (4, 6.41895309090614318848e-02) (5, -3.74474972486495971680e-01) (6, -1.45295870304107666016e+00) (7, -2.76180648803710937500e+00) (8, -5.81335783004760742188e-01) (9, -2.15544134378433227539e-01) (0, -4.14715826511383056641e-01) (1, -6.77569985389709472656e-01) (2, -1.46866536140441894531e+00) (3, -5.77987968921661376953e-01) (4, 1.09443151950836181641e+00) (5, -4.32819545269012451172e-01) (6, -7.07807004451751708984e-01) (7, -8.91234993934631347656e-01) (8, -9.87334191799163818359e-01) (9, 7.99898058176040649414e-02) (0, -3.70720505714416503906e+00) (1, -1.54922831058502197266e+00) (2, -1.42331447601318359375e+01) (3, 1.24678172171115875244e-01) (4, 3.59544962644577026367e-01) (5, -8.21292102336883544922e-01) (6, 1.49043345451354980469e+00) (7, 1.58609837293624877930e-01) (8, 1.71625569462776184082e-01) (9, 7.22561255097389221191e-02) (0, -9.39445555210113525391e-01) (1, -2.01766163110733032227e-01) (2, -4.86753508448600769043e-02) (3, -3.05887675285339355469e+00) (4, 1.22679281234741210938e+00) (5, 3.80991756916046142578e-01) (6, -3.44601416587829589844e+00) (7, -2.37133890390396118164e-01) (8, 1.86215031147003173828e+00) (9, 3.40320676565170288086e-01) (0, -3.49279952049255371094e+00) (1, -9.64088261127471923828e-01) (2, -1.10619621276855468750e+01) (3, 3.66275422275066375732e-02) (4, -2.76813983917236328125e-01) (5, -7.08200335502624511719e-01) (6, 2.44665765762329101562e+00) (7, -5.35578019917011260986e-02) (8, -6.28081619739532470703e-01) (9, 8.88248831033706665039e-02) (0, 3.97181987762451171875e-01) (1, 1.91401100158691406250e+00) (2, 1.07734823226928710938e+00) (3, -1.32786488533020019531e+00) (4, 2.43584084510803222656e+00) (5, -6.49895310401916503906e-01) (6, -1.96852815151214599609e+00) (7, -2.82492947578430175781e+00) (8, -7.33009815216064453125e+00) (9, 1.27083107829093933105e-01) (0, 4.66599512100219726562e+00) (1, 1.68485438823699951172e+00) (2, 1.13645052909851074219e+00) (3, -1.91492104530334472656e+00) (4, 1.42650938034057617188e+00) (5, -1.11613941192626953125e+00) (6, -4.08532190322875976562e+00) (7, -1.12348997592926025391e+00) (8, -1.44140744209289550781e+00) (9, 1.77128195762634277344e-01) (0, 1.47678552246093750000e+03) (1, -8.47388732910156250000e+02) (2, 7.40421508789062500000e+02) (3, -1.48358569335937500000e+03) (4, -3.83504152297973632812e-01) (5, -3.47230267524719238281e+00) (6, -1.50000000000000000000e+03) (7, 1.66687345504760742188e+00) (8, 1.10356736183166503906e+00) (9, 8.12959134578704833984e-01) (10, -3.36270332336425781250e+00) (11, -8.75441837310791015625e+00) (12, 1.47734212875366210938e+00) (13, 2.13415455818176269531e+00) (14, 1.59606385231018066406e+00) (15, 2.00103998184204101562e+00) (16, 2.09721994400024414062e+00) (17, -2.38909912109375000000e+00) (18, 5.86338341236114501953e-02) (10, 7.04881811141967773438e+00) (11, -5.36419034004211425781e-01) (12, -1.15120267868041992188e+00) (13, -2.49114966392517089844e+00) (14, -1.29622423648834228516e+00) (15, -2.17054510116577148438e+00) (16, -2.21040916442871093750e+00) (17, -5.95210671424865722656e-01) (18, 9.51986074447631835938e-01) (10, -3.50802350044250488281e+00) (11, -8.76106166839599609375e+00) (12, 1.55145370960235595703e+00) (13, 2.19638681411743164062e+00) (14, 1.63884520530700683594e+00) (15, 1.97765076160430908203e+00) (16, 2.00577282905578613281e+00) (17, -2.50821399688720703125e+00) (18, 6.22619353234767913818e-02) (10, -3.30677723884582519531e+00) (11, -8.71423530578613281250e+00) (12, 1.75720179080963134766e+00) (13, 2.15188384056091308594e+00) (14, 1.28250682353973388672e+00) (15, 2.03796982765197753906e+00) (16, 2.02182555198669433594e+00) (17, -2.48615670204162597656e+00) (18, 7.39578157663345336914e-02) (10, -3.40936231613159179688e+00) (11, -8.85801696777343750000e+00) (12, 1.63522100448608398438e+00) (13, 2.18655228614807128906e+00) (14, 1.64456880092620849609e+00) (15, 2.08201789855957031250e+00) (16, 2.03259515762329101562e+00) (17, -2.44621276855468750000e+00) (18, 3.96071523427963256836e-02) (10, -3.40086627006530761719e+00) (11, -8.82173252105712890625e+00) (12, 1.57843554019927978516e+00) (13, 2.24262619018554687500e+00) (14, 1.52432429790496826172e+00) (15, 1.98998951911926269531e+00) (16, 2.01084589958190917969e+00) (17, -2.45598840713500976562e+00) (18, 7.53255933523178100586e-02) (10, 8.46598267555236816406e-01) (11, -1.64669001102447509766e+00) (12, -2.62754893302917480469e+00) (13, -4.89030599594116210938e+00) (14, -1.86972188949584960938e+00) (15, -3.88382935523986816406e+00) (16, -2.44453930854797363281e+00) (17, -1.77565920352935791016e+00) (18, 8.33142578601837158203e-01) (10, -3.09089112281799316406e+00) (11, -9.11287212371826171875e+00) (12, 1.44346451759338378906e+00) (13, 2.13234138488769531250e+00) (14, 1.42581009864807128906e+00) (15, 1.78973054885864257812e+00) (16, 2.00752758979797363281e+00) (17, -2.78136754035949707031e+00) (18, 1.25841528177261352539e-01) (19, 5.56852877140045166016e-01) (20, -5.72605085372924804688e+00) (21, 5.56780397891998291016e-01) (22, 5.26934742927551269531e-01) (23, 6.04525685310363769531e-01) (24, 6.03700280189514160156e-01) (25, -8.14569854736328125000e+00) (26, 7.54933714866638183594e-01) (27, 2.53145307302474975586e-01) 
