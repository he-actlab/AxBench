FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 9 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.50000000000000000000e+03) (1, -7.41245448589324951172e-01) (2, -6.19208753108978271484e-01) (3, -1.55239343643188476562e+00) (4, 7.06274956464767456055e-02) (5, 6.60096347332000732422e-01) (6, -8.78447055816650390625e-01) (7, 3.24062347412109375000e-01) (8, -1.97559177875518798828e-01) (9, -6.82191371917724609375e-01) (0, -4.49452221393585205078e-01) (1, 9.41299140453338623047e-01) (2, -2.27770641446113586426e-01) (3, 1.59145787358283996582e-01) (4, -1.48144650459289550781e+00) (5, 6.38277530670166015625e-01) (6, -2.51996517181396484375e-01) (7, -6.96175217628479003906e-01) (8, -2.10643863677978515625e+00) (9, 4.57667320966720581055e-01) (0, -2.36996746063232421875e+00) (1, -9.94729995727539062500e-01) (2, -2.85900235176086425781e-01) (3, -4.44036215543746948242e-01) (4, 2.53977239131927490234e-01) (5, -1.41191017627716064453e+00) (6, -1.41525316238403320312e+00) (7, -4.30371254682540893555e-01) (8, -7.74898648262023925781e-01) (9, 4.59429882466793060303e-02) (0, -2.87921905517578125000e+00) (1, -1.06836163997650146484e+00) (2, -2.20487162470817565918e-01) (3, -5.58151364326477050781e-01) (4, 3.66811335086822509766e-01) (5, -2.26776838302612304688e-01) (6, -3.63258689641952514648e-01) (7, -1.52619346976280212402e-01) (8, -7.18201637268066406250e-01) (9, -1.66776888072490692139e-02) (0, -2.31631606817245483398e-01) (1, 4.01890903711318969727e-01) (2, -1.86459615826606750488e-01) (3, 3.96094799041748046875e-01) (4, -1.71682822704315185547e+00) (5, 1.00006473064422607422e+00) (6, -9.16877239942550659180e-02) (7, -6.84135437011718750000e-01) (8, -2.20158958435058593750e+00) (9, 4.14563238620758056641e-01) (0, -6.43219590187072753906e-01) (1, 4.92486298084259033203e-01) (2, 3.73032242059707641602e-02) (3, 5.59825301170349121094e-01) (4, -1.30172777175903320312e+00) (5, 2.14848327636718750000e+00) (6, -1.68472470249980688095e-03) (7, -1.12692308425903320312e+00) (8, -4.87816333770751953125e+00) (9, 6.00566804409027099609e-01) (0, -1.20202563703060150146e-01) (1, 3.38517010211944580078e-01) (2, -3.53806734085083007812e-01) (3, 4.89914083480834960938e+00) (4, -4.95728641748428344727e-01) (5, -3.06917166709899902344e+00) (6, 6.22073292732238769531e-01) (7, -5.66309273242950439453e-01) (8, -3.10430455207824707031e+00) (9, 5.07708787918090820312e-01) (0, -3.72932791709899902344e+00) (1, 6.87880665063858032227e-02) (2, -2.73220926523208618164e-01) (3, 1.20209181308746337891e+00) (4, -1.74500739574432373047e+00) (5, 2.38217020034790039062e+00) (6, 1.03749200701713562012e-01) (7, -8.63817334175109863281e-02) (8, -8.51838648319244384766e-01) (9, -4.86898720264434814453e-01) (10, -1.45753164291381835938e+01) (11, -1.67676007747650146484e+00) (12, 4.99959528446197509766e-01) (13, 1.19220924377441406250e+00) (14, -1.57324099540710449219e+00) (15, -2.79029107093811035156e+00) (16, -4.79073190689086914062e+00) (17, -1.16679239273071289062e+00) (18, 8.57876718044281005859e-01) (10, -1.92350692749023437500e+02) (11, 4.45468330383300781250e+00) (12, -5.36381816864013671875e+00) (13, -8.60443038940429687500e+01) (14, 4.64602899551391601562e+00) (15, 6.18713283538818359375e+00) (16, 7.56096649169921875000e+00) (17, -8.34975814819335937500e+00) (18, -2.12157778441905975342e-02) (10, -1.92324081420898437500e+02) (11, 3.50826919078826904297e-01) (12, -3.60871162414550781250e+01) (13, -1.19080734252929687500e+01) (14, 4.25987631082534790039e-01) (15, -2.33893895149230957031e+00) (16, -5.53723752498626708984e-01) (17, 2.98558998107910156250e+00) (18, 1.23800241947174072266e+00) (10, -1.49751377105712890625e+01) (11, -1.17817044258117675781e+00) (12, 8.54721426963806152344e-01) (13, 1.37066030502319335938e+00) (14, -1.13462960720062255859e+00) (15, -2.72621941566467285156e+00) (16, -4.75905799865722656250e+00) (17, -7.58344173431396484375e-01) (18, 4.30482715368270874023e-01) (10, -1.00209913253784179688e+01) (11, -1.16419565677642822266e+00) (12, 9.81310081481933593750e+00) (13, 1.91105842590332031250e+00) (14, -1.18134760856628417969e+00) (15, -2.82032895088195800781e+00) (16, -2.06450080871582031250e+00) (17, -8.09330523014068603516e-01) (18, 4.27986532449722290039e-02) (10, 8.28942031860351562500e+01) (11, 3.90320152044296264648e-01) (12, -4.21408538818359375000e+01) (13, -9.08245658874511718750e+00) (14, 4.47797894477844238281e-01) (15, -2.01083272695541381836e-01) (16, -3.13218355178833007812e-01) (17, 4.20183610916137695312e+00) (18, 2.81831771135330200195e-02) (10, 6.87110671997070312500e+01) (11, 3.58794152736663818359e-01) (12, -1.00530929565429687500e+01) (13, -9.00879955291748046875e+00) (14, -4.51698929071426391602e-01) (15, -5.77898836135864257812e+00) (16, -7.78703927993774414062e-01) (17, 1.90109157562255859375e+01) (18, 7.25528657436370849609e-01) (10, 8.05167007446289062500e+01) (11, 6.76851749420166015625e-01) (12, -3.35736808776855468750e+01) (13, -3.53519515991210937500e+01) (14, 7.43522286415100097656e-01) (15, 4.38798189163208007812e+00) (16, 6.83899164199829101562e+00) (17, 3.10567170381546020508e-01) (18, 5.00879406929016113281e-01) (19, -2.74317092895507812500e+01) (20, 5.28888463973999023438e-01) (21, 6.79424524307250976562e-01) (22, -5.47211694717407226562e+00) (23, -4.99166822433471679688e+00) (24, 4.55925047397613525391e-01) (25, 7.59014368057250976562e-01) (26, 4.73997563123703002930e-01) (27, 4.96677756309509277344e-02) 
