FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 9 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -8.08378028869628906250e+00) (1, -7.87836134433746337891e-01) (2, -6.93998336791992187500e-01) (3, 5.19376695156097412109e-01) (4, -2.06536912918090820312e+00) (5, 3.67996191978454589844e+00) (6, 1.71879839897155761719e+00) (7, 1.14350430667400360107e-01) (8, 2.77740001678466796875e-01) (9, -5.67965984344482421875e-01) (0, -3.21145057678222656250e-01) (1, 4.22172784805297851562e+00) (2, 5.26693463325500488281e-01) (3, -4.84084725379943847656e-01) (4, -7.19040274620056152344e-01) (5, -2.61695891618728637695e-01) (6, -3.47489789128303527832e-02) (7, -1.76344141364097595215e-01) (8, -4.96207046508789062500e+00) (9, 5.32768964767456054688e-01) (0, 2.42491904646158218384e-02) (1, -4.49775838851928710938e+00) (2, 9.37351942062377929688e-01) (3, 3.48048305511474609375e+00) (4, 1.50484561920166015625e+00) (5, 1.43786084651947021484e+00) (6, 1.35779392719268798828e+00) (7, 8.01566064357757568359e-01) (8, -1.94700396060943603516e+00) (9, -8.37710285186767578125e+00) (0, -7.19456481933593750000e+02) (1, -1.05279037475585937500e+02) (2, -4.39088928222656250000e+02) (3, 1.68538153171539306641e-01) (4, -5.30169799804687500000e+02) (5, -1.08303962707519531250e+02) (6, 3.28408300876617431641e-01) (7, 8.35499023437500000000e+02) (8, -9.55877971649169921875e+00) (9, -8.78361403942108154297e-01) (0, -2.30369930267333984375e+01) (1, -6.78780174255371093750e+00) (2, 2.16970462799072265625e+01) (3, 6.47889852523803710938e-01) (4, 2.88301557302474975586e-01) (5, 1.23014163970947265625e+00) (6, 1.21413683891296386719e+00) (7, -8.78387570381164550781e-01) (8, -1.53854322433471679688e+00) (9, -7.20665216445922851562e-01) (0, 2.69268536567687988281e+00) (1, -4.43711042404174804688e+00) (2, -2.15562120079994201660e-01) (3, 8.56265127658843994141e-02) (4, 1.87940388917922973633e-01) (5, -4.80236336588859558105e-02) (6, -2.02446188777685165405e-02) (7, 3.03019613027572631836e-01) (8, 8.36398303508758544922e-01) (9, -6.61972105503082275391e-01) (0, -9.51319634914398193359e-01) (1, 2.73365211486816406250e+00) (2, 1.54771611094474792480e-01) (3, -1.51078432798385620117e-01) (4, 7.71567523479461669922e-01) (5, -2.99698561429977416992e-02) (6, 1.08189976215362548828e+00) (7, -4.21498596668243408203e-01) (8, -2.08720684051513671875e+00) (9, 4.22896116971969604492e-01) (0, -7.33880710601806640625e+00) (1, -6.02528429031372070312e+00) (2, -2.78007912635803222656e+00) (3, 2.96857810020446777344e+00) (4, 2.20105719566345214844e+00) (5, 2.37193512916564941406e+00) (6, 4.83957719802856445312e+00) (7, 1.58871614933013916016e+00) (8, 1.58704781532287597656e+00) (9, -3.05734068155288696289e-01) (10, 4.05037498474121093750e+00) (11, 3.24417495727539062500e+00) (12, 3.54198699951171875000e+02) (13, 1.44943872070312500000e+03) (14, 2.65309381484985351562e+00) (15, 1.33789272308349609375e+01) (16, -7.11682224273681640625e+00) (17, -7.27721786499023437500e+00) (18, -8.53762090206146240234e-01) (10, 2.23590731620788574219e+00) (11, 2.67847228050231933594e+00) (12, 9.79083919525146484375e+00) (13, 1.44943872070312500000e+03) (14, -3.74123716354370117188e+00) (15, -4.35952469706535339355e-02) (16, -8.16076469421386718750e+00) (17, -1.44251745605468750000e+03) (18, -3.22129130363464355469e-02) (10, 6.96147680282592773438e+00) (11, 1.21205940246582031250e+01) (12, 6.32959228515625000000e+02) (13, 1.44943872070312500000e+03) (14, -1.33686733245849609375e+01) (15, 1.98629627227783203125e+01) (16, 4.26710033416748046875e+00) (17, -5.12525672912597656250e+01) (18, -4.30362135171890258789e-01) (10, -3.75572991371154785156e+00) (11, -8.73033940792083740234e-01) (12, 2.39120819091796875000e+02) (13, 6.20582702636718750000e+02) (14, -1.36028349399566650391e+00) (15, -5.75100326538085937500e+00) (16, -1.49697911739349365234e+00) (17, -9.30918514728546142578e-01) (18, 1.04162597656250000000e+00) (10, 4.01571702957153320312e+00) (11, -6.71131610870361328125e+00) (12, 6.50092590332031250000e+02) (13, 1.44943872070312500000e+03) (14, 3.68917727470397949219e+00) (15, 1.60335502624511718750e+01) (16, -2.96607589721679687500e+00) (17, -7.88776254653930664062e+00) (18, -1.46385121345520019531e+00) (10, -2.84500241279602050781e+00) (11, -6.46797227859497070312e+00) (12, -9.15484313964843750000e+02) (13, 6.20582702636718750000e+02) (14, -1.28171503543853759766e+00) (15, 2.72204036712646484375e+01) (16, -5.25281286239624023438e+00) (17, -1.05583059787750244141e+00) (18, 2.03915596008300781250e+00) (10, 1.30819292068481445312e+01) (11, 1.05205869674682617188e+00) (12, -9.10485290527343750000e+02) (13, 1.44943872070312500000e+03) (14, -2.49712300300598144531e+00) (15, 9.10565376281738281250e+00) (16, -1.12872867584228515625e+01) (17, 2.81663970947265625000e+01) (18, -4.20071697235107421875e+00) (10, -3.12512540817260742188e+00) (11, -3.10577297210693359375e+00) (12, -7.49712219238281250000e+02) (13, 7.35633056640625000000e+02) (14, -1.87534344196319580078e+00) (15, -1.09322662353515625000e+02) (16, -3.71942186355590820312e+00) (17, -6.49324157714843750000e+02) (18, -1.37125864028930664062e+01) (19, 2.03753876686096191406e+00) (20, 7.77425110340118408203e-01) (21, 1.48249399662017822266e+00) (22, -6.08399391174316406250e+00) (23, 3.78345698118209838867e-01) (24, -3.21667933464050292969e+00) (25, 2.22111701965332031250e+00) (26, 4.05581951141357421875e+00) (27, -8.47005769610404968262e-02) 
