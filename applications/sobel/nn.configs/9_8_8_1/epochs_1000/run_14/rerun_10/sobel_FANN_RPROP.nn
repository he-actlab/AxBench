FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 9 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -5.57579159736633300781e-01) (1, -1.97912061214447021484e+00) (2, 4.04070228338241577148e-01) (3, -3.31824980676174163818e-02) (4, 3.92947584390640258789e-01) (5, -1.62693727016448974609e+00) (6, -1.72263428568840026855e-01) (7, -5.76699495315551757812e-01) (8, -2.09169924259185791016e-01) (9, 3.90670001506805419922e-01) (0, -1.78838765621185302734e+00) (1, -3.93087005615234375000e+00) (2, -2.62397837638854980469e+00) (3, -1.87162116169929504395e-01) (4, 3.08199495077133178711e-01) (5, -7.39711105823516845703e-01) (6, 3.20994019508361816406e-01) (7, -1.46407222747802734375e+00) (8, -1.58504158258438110352e-01) (9, 1.49238511919975280762e-01) (0, -6.84626340866088867188e-01) (1, -3.26887965202331542969e+00) (2, -6.97242438793182373047e-01) (3, 5.81709742546081542969e-02) (4, 3.36478292942047119141e-01) (5, 1.06246030330657958984e+00) (6, -1.70470559597015380859e+00) (7, -8.77457678318023681641e-01) (8, 2.15653091669082641602e-01) (9, 1.97324737906455993652e-01) (0, 8.12059402465820312500e-01) (1, 5.53393602371215820312e-01) (2, 1.06768858432769775391e+00) (3, -1.21639168262481689453e+00) (4, 4.76419687271118164062e-01) (5, -6.64964139461517333984e-01) (6, -7.84701287746429443359e-01) (7, -2.73167562484741210938e+00) (8, -1.37105095386505126953e+00) (9, 1.11006188392639160156e+00) (0, -6.71182036399841308594e-01) (1, -3.44300460815429687500e+00) (2, -4.92806643247604370117e-01) (3, 3.33767794072628021240e-02) (4, 3.87026757001876831055e-01) (5, 6.25107511878013610840e-02) (6, -4.02691507339477539062e+00) (7, -5.85637092590332031250e-01) (8, 5.11920070648193359375e+00) (9, 2.49764487147331237793e-01) (0, -6.20049059391021728516e-01) (1, -2.15896415710449218750e+01) (2, -8.10917496681213378906e-01) (3, -1.51401117444038391113e-01) (4, 4.57293093204498291016e-01) (5, 2.41079200059175491333e-02) (6, 2.92935580015182495117e-01) (7, -1.28827124834060668945e-01) (8, 8.28393745422363281250e+00) (9, -6.16873204708099365234e-02) (0, -8.13152790069580078125e-01) (1, -9.20514297485351562500e+00) (2, -2.28077545762062072754e-01) (3, -2.17529341578483581543e-01) (4, 2.93348073959350585938e-01) (5, 2.50345468521118164062e-01) (6, 3.64572525024414062500e-01) (7, -1.07629425823688507080e-01) (8, 2.38597273826599121094e+00) (9, 7.37349808216094970703e-01) (0, -1.85807406902313232422e-01) (1, -7.09030687808990478516e-01) (2, 7.22899079322814941406e-01) (3, 1.20031856000423431396e-01) (4, 6.07341766357421875000e-01) (5, -2.18265843391418457031e+00) (6, 2.03658610582351684570e-01) (7, -1.10208404064178466797e+00) (8, -2.25352898240089416504e-01) (9, 4.42633092403411865234e-01) (10, -1.36919534206390380859e+00) (11, -1.17865276336669921875e+00) (12, -1.36267066001892089844e+00) (13, -9.85842323303222656250e+00) (14, -1.73702442646026611328e+00) (15, -1.19340057373046875000e+01) (16, 1.37487010955810546875e+01) (17, -1.65935242176055908203e+00) (18, 1.42913925647735595703e+00) (10, -1.10513854026794433594e+00) (11, 1.70155775547027587891e+00) (12, -1.13354158401489257812e+00) (13, -7.43896532058715820312e+00) (14, -4.70049190521240234375e+00) (15, -2.50634422302246093750e+01) (16, 2.84779815673828125000e+01) (17, -1.45511054992675781250e+00) (18, 4.66439753770828247070e-01) (10, 1.61803007125854492188e-01) (11, 1.20659255981445312500e+00) (12, 1.71375846862792968750e+00) (13, -2.46688866615295410156e+00) (14, -2.07718253135681152344e-01) (15, -2.22469139099121093750e+00) (16, -7.29127645492553710938e+00) (17, -2.27927178144454956055e-01) (18, 3.54018390178680419922e-01) (10, -3.34761905670166015625e+00) (11, -1.32562875747680664062e+00) (12, -1.53367662429809570312e+00) (13, -1.17958936691284179688e+01) (14, -1.75622045993804931641e+00) (15, -3.48539972305297851562e+00) (16, 1.22442328929901123047e+00) (17, -2.31213855743408203125e+00) (18, 2.66771841049194335938e+00) (10, 1.83738005161285400391e+00) (11, 8.30295979976654052734e-01) (12, 6.78474330902099609375e+00) (13, -1.52746536254882812500e+02) (14, 2.57846522331237792969e+00) (15, 1.92922477722167968750e+01) (16, 1.05721168518066406250e+01) (17, 5.28200209140777587891e-01) (18, 1.46805632114410400391e+00) (10, -2.20880001783370971680e-01) (11, 3.01755619049072265625e+00) (12, 5.31878232955932617188e+00) (13, -2.50510144233703613281e+00) (14, -2.81427234411239624023e-01) (15, -2.44060635566711425781e+00) (16, -8.84863471984863281250e+00) (17, 3.93836468458175659180e-01) (18, 3.63828241825103759766e-01) (10, 1.87808692455291748047e+00) (11, 1.56007695198059082031e+00) (12, 1.41631567478179931641e+00) (13, -1.24337097167968750000e+02) (14, 1.51846885681152343750e+01) (15, 1.20108814239501953125e+01) (16, 9.59812641143798828125e+00) (17, -1.90442924499511718750e+01) (18, 5.40741252899169921875e+00) (10, -1.35253822803497314453e+00) (11, -1.34062767028808593750e+00) (12, -9.96003806591033935547e-01) (13, -9.78816032409667968750e+00) (14, -1.60017466545104980469e+00) (15, -1.20241994857788085938e+01) (16, 1.39207849502563476562e+01) (17, -1.55008804798126220703e+00) (18, 1.32490706443786621094e+00) (19, -9.93542075157165527344e-01) (20, -1.13169860839843750000e+00) (21, 1.60375475883483886719e+00) (22, -2.04875507354736328125e+01) (23, 8.33028912544250488281e-01) (24, 1.41187143325805664062e+00) (25, 6.80388391017913818359e-01) (26, -9.95700478553771972656e-01) (27, 1.51089444756507873535e-01) 
