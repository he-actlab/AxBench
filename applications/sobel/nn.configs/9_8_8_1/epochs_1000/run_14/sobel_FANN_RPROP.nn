FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 9 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 7.43178665637969970703e-01) (1, 1.29446411132812500000e+00) (2, 1.94682657718658447266e+00) (3, 4.96959626674652099609e-01) (4, -1.78071606159210205078e+00) (5, 5.83809316158294677734e-01) (6, 2.10479274392127990723e-01) (7, 1.40280497074127197266e+00) (8, 3.21093082427978515625e+00) (9, -3.98602700233459472656e+00) (0, 1.02902078628540039062e+00) (1, -2.74732327461242675781e+00) (2, -1.48996362304687500000e+03) (3, 3.40678483247756958008e-01) (4, 1.34201973676681518555e-01) (5, 1.48713135719299316406e+00) (6, 6.17918312549591064453e-01) (7, 4.66225385665893554688e-01) (8, 1.46908864974975585938e+01) (9, 8.78781199455261230469e-01) (0, 8.11561703681945800781e-01) (1, 4.42999124526977539062e-01) (2, 3.22987914085388183594e+00) (3, 1.18688188493251800537e-01) (4, 3.09110105037689208984e-01) (5, 9.23678457736968994141e-01) (6, -6.23128032684326171875e+00) (7, -3.46197819709777832031e+00) (8, 2.16487860679626464844e+00) (9, -2.39410281181335449219e+00) (0, 1.72631607055664062500e+01) (1, 5.73026514053344726562e+00) (2, 2.51100940704345703125e+01) (3, -1.18616371154785156250e+01) (4, -1.03096675872802734375e+00) (5, -1.85308242797851562500e+02) (6, -6.26342535018920898438e+00) (7, -2.72840671539306640625e+01) (8, 2.27135238647460937500e+02) (9, 9.29080677032470703125e+00) (0, 1.34148022460937500000e+03) (1, 1.34054724121093750000e+03) (2, 1.42364843750000000000e+03) (3, 1.58183646202087402344e+00) (4, 4.51311397552490234375e+00) (5, 5.33781528472900390625e+00) (6, -3.56293426513671875000e+02) (7, -1.25613775253295898438e+01) (8, 1.22111709594726562500e+02) (9, 1.50170944213867187500e+02) (0, 7.23160028457641601562e+00) (1, 3.21212959289550781250e+00) (2, 3.29179496765136718750e+01) (3, 2.20446681976318359375e+00) (4, -4.62757766246795654297e-01) (5, 1.47473861694335937500e+02) (6, -2.52107410430908203125e+01) (7, -9.33597373962402343750e+00) (8, 1.03862350463867187500e+02) (9, 2.94515743255615234375e+01) (0, 2.12279534339904785156e+00) (1, 2.61464524269104003906e+00) (2, 2.26870274543762207031e+00) (3, 1.81884348392486572266e+00) (4, 3.44583463668823242188e+00) (5, 8.60168838500976562500e+00) (6, -2.36939334869384765625e+00) (7, -1.04756629467010498047e+00) (8, 2.37660354614257812500e+02) (9, 3.13095045089721679688e+00) (0, -1.26273810863494873047e+00) (1, -4.71931695938110351562e-01) (2, 6.67673870921134948730e-02) (3, 7.26158380508422851562e-01) (4, 1.79581069946289062500e+01) (5, 2.34398773193359375000e+02) (6, -4.97187232971191406250e+01) (7, -9.65336990356445312500e+00) (8, 2.21248950958251953125e+01) (9, -1.05518162250518798828e+00) (10, -9.38978016376495361328e-01) (11, 6.31276226043701171875e+00) (12, 6.15639066696166992188e+00) (13, 2.70781890869140625000e+02) (14, -1.23012995719909667969e+00) (15, 3.02653074264526367188e-01) (16, -1.19319829940795898438e+01) (17, -9.12928649902343750000e+02) (18, 8.39995145797729492188e-01) (10, -1.66844201087951660156e+00) (11, -6.33973144531250000000e+02) (12, 1.35204980468750000000e+03) (13, -7.67344177246093750000e+02) (14, -1.04244083166122436523e-01) (15, -9.55369353294372558594e-01) (16, -3.97215318679809570312e+00) (17, -1.39190368652343750000e+03) (18, 1.36989504098892211914e-01) (10, -1.36292111873626708984e+00) (11, 8.34758567810058593750e+00) (12, 6.11244297027587890625e+00) (13, 5.19830566406250000000e+02) (14, -8.24989303946495056152e-02) (15, 1.32968515157699584961e-01) (16, -1.21404361724853515625e+01) (17, -9.16457275390625000000e+02) (18, 9.48438122868537902832e-02) (10, 1.03992195129394531250e+02) (11, 1.08399975299835205078e+00) (12, 6.97082519531250000000e+01) (13, -2.03705525398254394531e+00) (14, 1.72814920544624328613e-01) (15, 1.57014436721801757812e+01) (16, -5.83586168289184570312e+00) (17, -3.14369487762451171875e+01) (18, -1.67281758785247802734e+00) (10, 8.96931838989257812500e+01) (11, 4.63929138183593750000e+01) (12, 8.47900772094726562500e+00) (13, -1.52498483657836914062e+00) (14, 1.78891003131866455078e+00) (15, -2.99555444717407226562e+00) (16, -2.85867004394531250000e+01) (17, -2.64391288757324218750e+01) (18, -2.75830245018005371094e+00) (10, 5.41813354492187500000e+01) (11, 1.85283622741699218750e+01) (12, -2.16736564636230468750e+01) (13, -4.49877071380615234375e+00) (14, -6.03047895431518554688e+00) (15, 5.04757285118103027344e-01) (16, -8.40422916412353515625e+00) (17, -9.56344318389892578125e+00) (18, -5.06312513351440429688e+00) (10, 4.57078784704208374023e-01) (11, 3.98105549812316894531e+00) (12, 2.21812095642089843750e+01) (13, -1.79315368652343750000e+02) (14, -1.29256331920623779297e+00) (15, -3.38783174753189086914e-01) (16, -5.90978698730468750000e+01) (17, -1.16011511230468750000e+03) (18, 5.29712498188018798828e-01) (10, 4.62373733520507812500e+01) (11, 1.69963741302490234375e+01) (12, -4.83269071578979492188e+00) (13, -1.04740250110626220703e+00) (14, -4.17089176177978515625e+00) (15, -1.23890912532806396484e+00) (16, -7.93279600143432617188e+00) (17, -1.11888208389282226562e+01) (18, -2.95656752586364746094e+00) (19, 9.40974121093750000000e+01) (20, 1.50000000000000000000e+03) (21, -5.74814491271972656250e+01) (22, 1.99802815914154052734e+00) (23, 2.27186536788940429688e+00) (24, -2.34216237068176269531e+00) (25, 4.15068786621093750000e+02) (26, -1.91348755359649658203e+00) (27, -1.12886667251586914062e+00) 
