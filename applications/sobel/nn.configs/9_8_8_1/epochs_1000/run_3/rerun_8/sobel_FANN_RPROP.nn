FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 9 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 9.10060729980468750000e+02) (1, 1.46680895996093750000e+03) (2, 1.48925219726562500000e+03) (3, -1.42903027343750000000e+03) (4, 5.17572288513183593750e+01) (5, -3.66271087646484375000e+02) (6, -1.45594177246093750000e+03) (7, -1.38700195312500000000e+03) (8, -3.70788177490234375000e+02) (9, -2.27310585975646972656e+00) (0, 7.05453586578369140625e+00) (1, -3.16437530517578125000e+02) (2, 2.75339385986328125000e+02) (3, 1.83648567199707031250e+01) (4, -9.20942306518554687500e-01) (5, -2.89861812591552734375e+01) (6, 4.32313728332519531250e+01) (7, 1.86839187145233154297e+00) (8, -3.52826194763183593750e+01) (9, 3.77756214141845703125e+00) (0, 8.09514427185058593750e+00) (1, -1.73871707916259765625e+01) (2, 9.84809112548828125000e+00) (3, 4.62441062927246093750e+00) (4, -3.34000549316406250000e+01) (5, -4.97914266586303710938e+00) (6, 5.48624000549316406250e+01) (7, 8.76230478286743164062e-01) (8, -4.12730026245117187500e+00) (9, 3.47773337364196777344e+00) (0, 1.49823160171508789062e+01) (1, -8.48939609527587890625e+00) (2, -5.89178733825683593750e+01) (3, 5.00990867614746093750e+00) (4, -5.23758172988891601562e+00) (5, 3.41719937324523925781e+00) (6, 3.38398323059082031250e+01) (7, 8.84745180606842041016e-01) (8, -4.27387420654296875000e+02) (9, 1.08651382446289062500e+02) (0, 2.10962414741516113281e+00) (1, -3.07562971115112304688e+00) (2, 2.13592071533203125000e+01) (3, -1.01024570465087890625e+01) (4, -1.05129661560058593750e+01) (5, 1.46606469154357910156e+00) (6, -7.79359912872314453125e+00) (7, 1.19186811149120330811e-01) (8, -6.34361445903778076172e-01) (9, 3.92834830284118652344e+00) (0, 1.40834932327270507812e+01) (1, -1.64937686920166015625e+01) (2, 3.42231178283691406250e+01) (3, 1.11970529556274414062e+01) (4, 7.49229507446289062500e+01) (5, 1.50000000000000000000e+03) (6, 3.35823898315429687500e+01) (7, 4.90666999816894531250e+01) (8, -4.97312660217285156250e+01) (9, 2.42012958526611328125e+01) (0, 2.06510448455810546875e+01) (1, 5.58714103698730468750e+01) (2, 8.81681442260742187500e+00) (3, 1.96896505355834960938e+00) (4, -1.41564636230468750000e+01) (5, -5.58539237976074218750e+01) (6, 3.26825752258300781250e+01) (7, -1.67199206352233886719e+00) (8, -7.95134201049804687500e+01) (9, 1.65558838844299316406e+00) (0, 6.71148252487182617188e+00) (1, 5.04231691360473632812e+00) (2, 1.32554197311401367188e+01) (3, 1.07394895553588867188e+01) (4, 4.42829376220703125000e+02) (5, 1.50000000000000000000e+03) (6, 3.71418533325195312500e+01) (7, 5.09843978881835937500e+01) (8, 4.12623504638671875000e+02) (9, 1.23161468505859375000e+01) (10, 6.23872613906860351562e+00) (11, -2.92360663414001464844e+00) (12, -2.48879480361938476562e+00) (13, -1.20289385318756103516e+00) (14, -5.73212957382202148438e+00) (15, 2.30217432975769042969e+00) (16, 2.89637541770935058594e+00) (17, 1.16351246833801269531e-03) (18, 1.38200640678405761719e+00) (10, 9.45565673828125000000e+02) (11, 1.20936572265625000000e+03) (12, 1.31864099121093750000e+03) (13, 1.50000000000000000000e+03) (14, 1.16279151916503906250e+02) (15, 3.63417297363281250000e+02) (16, 2.97902709960937500000e+02) (17, -1.27268591308593750000e+03) (18, -8.52397823333740234375e+00) (10, 6.26056274414062500000e+02) (11, -3.37324309349060058594e+00) (12, -3.16435933113098144531e+00) (13, -5.36591529846191406250e+00) (14, -6.19495361328125000000e+02) (15, -5.41718339920043945312e+00) (16, -4.76084852218627929688e+00) (17, 2.22079715728759765625e+01) (18, -6.37717008590698242188e+00) (10, 4.76004272460937500000e+02) (11, -9.17029907226562500000e+02) (12, 5.39804887771606445312e+00) (13, -1.50000000000000000000e+03) (14, -1.29832531738281250000e+03) (15, -1.25192285156250000000e+03) (16, -5.91815979003906250000e+02) (17, -3.70140266418457031250e+00) (18, 3.00826765596866607666e-02) (10, 6.78864929199218750000e+02) (11, -9.17029907226562500000e+02) (12, -1.31099707031250000000e+03) (13, -1.50000000000000000000e+03) (14, -1.45939050292968750000e+03) (15, -1.19966284179687500000e+03) (16, -4.69078948974609375000e+02) (17, -4.71083129882812500000e+02) (18, -3.79249763488769531250e+00) (10, 5.63982482910156250000e+02) (11, 1.20936572265625000000e+03) (12, 2.80800685286521911621e-02) (13, 1.50000000000000000000e+03) (14, 1.48759008789062500000e+03) (15, 1.46804809570312500000e+03) (16, 7.29114624023437500000e+02) (17, 2.91213011741638183594e+00) (18, 2.38041847944259643555e-01) (10, 5.63995544433593750000e+02) (11, 1.20936572265625000000e+03) (12, 1.39261877441406250000e+03) (13, 1.50000000000000000000e+03) (14, 1.48759008789062500000e+03) (15, 1.18738269042968750000e+03) (16, 1.50000000000000000000e+03) (17, 1.50000000000000000000e+03) (18, 4.89789184570312500000e+02) (10, -1.96614980697631835938e-01) (11, 3.88162016868591308594e-01) (12, 2.50395321846008300781e+00) (13, 1.80693638324737548828e+00) (14, -2.69506740570068359375e+01) (15, -1.11949062347412109375e+00) (16, -6.37000143527984619141e-01) (17, -3.25634407997131347656e+00) (18, 8.46042573451995849609e-01) (19, 9.34510529041290283203e-01) (20, -2.62754291296005249023e-01) (21, 1.26607429981231689453e+00) (22, 1.50000000000000000000e+03) (23, 1.50000000000000000000e+03) (24, -5.77363193035125732422e-01) (25, -2.91967988014221191406e-01) (26, 2.31377601623535156250e+00) (27, -1.91322922706604003906e-01) 
