FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 9 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.58305711746215820312e+01) (1, -6.50391311645507812500e+01) (2, -3.56866394042968750000e+02) (3, -1.69475007057189941406e+00) (4, 2.65586525201797485352e-01) (5, -4.64432030916213989258e-01) (6, 1.11062555313110351562e+01) (7, 2.20210845947265625000e+02) (8, -1.59144805908203125000e+02) (9, -3.94478645324707031250e+01) (0, -1.99805855751037597656e-01) (1, -1.00346746444702148438e+01) (2, -9.16297607421875000000e+02) (3, -4.10042762756347656250e+00) (4, -1.66437530517578125000e+02) (5, 1.19311523437500000000e+01) (6, -6.93443012237548828125e+00) (7, -8.27552497386932373047e-01) (8, 1.15783081054687500000e+03) (9, 6.97878956794738769531e-01) (0, -6.48312792181968688965e-02) (1, -4.41467314958572387695e-01) (2, -7.34896004199981689453e-01) (3, -1.52064037322998046875e+00) (4, 1.10838770866394042969e+00) (5, -1.59645959734916687012e-01) (6, 6.89336872100830078125e+00) (7, 3.29989284276962280273e-01) (8, -4.12405109405517578125e+00) (9, 4.38214808702468872070e-01) (0, -7.16207623481750488281e-01) (1, -7.30888700485229492188e+00) (2, -6.40233576297760009766e-01) (3, -1.32521951198577880859e+00) (4, 4.46713775396347045898e-01) (5, 1.07110452651977539062e+00) (6, 1.30004873275756835938e+01) (7, 5.00313162803649902344e-01) (8, -7.07541644573211669922e-01) (9, -4.59713840484619140625e+00) (0, -6.70143556594848632812e+00) (1, -3.36941742897033691406e+00) (2, -5.20665817260742187500e+01) (3, -1.51870405673980712891e+00) (4, -1.11065536737442016602e-01) (5, -1.61415481567382812500e+00) (6, 4.65094947814941406250e+00) (7, 2.44326522827148437500e+02) (8, -1.36637252807617187500e+02) (9, -3.94754714965820312500e+01) (0, -1.26628324389457702637e-01) (1, 2.65489149093627929688e+00) (2, 5.60756778717041015625e+00) (3, -3.67374706268310546875e+00) (4, -7.17369794845581054688e+00) (5, 4.18136060237884521484e-01) (6, -2.62993359565734863281e+00) (7, -1.81563079357147216797e+00) (8, -1.36511135101318359375e+00) (9, -5.14005795121192932129e-02) (0, -1.77691245079040527344e+00) (1, -1.89996314048767089844e+00) (2, -5.10575389862060546875e+00) (3, -5.50133407115936279297e-01) (4, 1.26725268363952636719e+00) (5, -4.50182408094406127930e-01) (6, 1.50479068756103515625e+01) (7, 1.02153277397155761719e+00) (8, -3.33600997924804687500e+00) (9, -5.43083858489990234375e+00) (0, -1.64055272936820983887e-01) (1, 8.03880214691162109375e+00) (2, 2.98601651191711425781e+00) (3, -2.71116662025451660156e+00) (4, -1.15501976013183593750e+00) (5, 2.33202981948852539062e+00) (6, -3.85385632514953613281e+00) (7, -4.34662437438964843750e+00) (8, -6.10983514785766601562e+00) (9, 5.75399259105324745178e-03) (10, 2.32651351928710937500e+02) (11, -6.47093868255615234375e+00) (12, -1.49927690625190734863e-01) (13, 4.13072700500488281250e+01) (14, -2.38438812255859375000e+02) (15, 9.85081577301025390625e+00) (16, 3.47930407524108886719e+00) (17, 6.28729963302612304688e+00) (18, 2.44875531643629074097e-03) (10, 3.20147277832031250000e+02) (11, 4.45930480957031250000e+00) (12, 1.33168411254882812500e+01) (13, 5.67304039001464843750e+00) (14, -2.22015975952148437500e+02) (15, -1.86069643497467041016e+00) (16, -1.39669616699218750000e+02) (17, -4.41893234252929687500e+01) (18, 1.46040832996368408203e+00) (10, -2.72864501953125000000e+02) (11, -1.21202821731567382812e+01) (12, 8.04544091224670410156e-01) (13, -5.44981307983398437500e+01) (14, 4.80828887939453125000e+02) (15, -3.41269721984863281250e+01) (16, 7.01394348144531250000e+01) (17, 3.23368911743164062500e+01) (18, 1.30364155769348144531e+00) (10, -1.66528869628906250000e+02) (11, 1.30725181102752685547e+00) (12, -1.19923794269561767578e+00) (13, 1.85456275939941406250e+01) (14, 2.11439285278320312500e+02) (15, 1.12551975250244140625e+01) (16, -6.21112861633300781250e+01) (17, 1.50000000000000000000e+03) (18, 5.02216339111328125000e+00) (10, 2.12096115112304687500e+02) (11, -1.30611193180084228516e+00) (12, 2.98909687995910644531e+00) (13, 1.59315834045410156250e+01) (14, 8.96170883178710937500e+01) (15, -6.79729270935058593750e+00) (16, -5.15350303649902343750e+01) (17, -6.40054762363433837891e-01) (18, 1.45690262317657470703e+00) (10, -1.25961029529571533203e+00) (11, -1.68355636596679687500e+01) (12, -1.30242738723754882812e+01) (13, 3.72869812011718750000e+02) (14, -1.25961029529571533203e+00) (15, 3.05480060577392578125e+01) (16, -9.93822956085205078125e+00) (17, -6.53712129592895507812e+00) (18, -1.83355891704559326172e+00) (10, -4.45800399780273437500e+01) (11, -3.55805015563964843750e+00) (12, 9.00551605224609375000e+00) (13, 5.28943748474121093750e+01) (14, -1.84143856167793273926e-01) (15, -7.54841766357421875000e+01) (16, -1.90032253265380859375e+01) (17, -1.66234912872314453125e+01) (18, -4.78478372097015380859e-01) (10, -2.72213165283203125000e+02) (11, -5.40523672103881835938e+00) (12, -1.21081280708312988281e+00) (13, -2.10905868530273437500e+02) (14, -2.72213165283203125000e+02) (15, 5.24312324523925781250e+01) (16, 8.19128906250000000000e+02) (17, 1.50000000000000000000e+03) (18, 3.63449394702911376953e-01) (19, 2.89135128259658813477e-01) (20, -6.51605308055877685547e-01) (21, 4.00625139474868774414e-01) (22, 3.77006500959396362305e-01) (23, -7.88572728633880615234e-01) (24, 2.95643419027328491211e-01) (25, -9.20140266418457031250e-01) (26, 2.63464272022247314453e-01) (27, 1.82434499263763427734e-01) 
