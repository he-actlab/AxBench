FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 9 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.39484655857086181641e+00) (1, 2.48753185272216796875e+01) (2, 5.79401105642318725586e-02) (3, -1.04291582107543945312e+01) (4, 7.05157947540283203125e+00) (5, 2.18907952308654785156e+00) (6, -2.77940063476562500000e+01) (7, -2.53748464584350585938e+00) (8, -7.53931999206542968750e-01) (9, -2.74640768766403198242e-01) (0, -1.63887155055999755859e+00) (1, -1.58546686172485351562e+00) (2, -2.09072613716125488281e+00) (3, -9.39784228801727294922e-01) (4, 8.72196018695831298828e-01) (5, 2.41003185510635375977e-01) (6, 1.10152854919433593750e+01) (7, 6.27898931503295898438e-01) (8, -3.03586721420288085938e+00) (9, -2.91558146476745605469e+00) (0, 4.86119174957275390625e+00) (1, 4.92707920074462890625e+00) (2, 2.44490194320678710938e+00) (3, -2.43867683410644531250e+01) (4, 9.07807350158691406250e+00) (5, 4.81772136688232421875e+00) (6, -6.62190389633178710938e+00) (7, -5.18170785903930664062e+00) (8, 9.27770256996154785156e-01) (9, -2.28014625608921051025e-02) (0, -2.92329177856445312500e+01) (1, -3.23453559875488281250e+01) (2, -2.63675079345703125000e+01) (3, 6.16630434989929199219e-01) (4, 4.04805660247802734375e-01) (5, -7.46385526657104492188e+00) (6, 6.61331295967102050781e-01) (7, -2.25937664508819580078e-02) (8, -1.44527880859375000000e+03) (9, 1.75436764955520629883e-01) (0, 2.09289789199829101562e+00) (1, 1.03680782318115234375e+01) (2, 4.17312622070312500000e+00) (3, -1.88674488067626953125e+01) (4, 3.58900129795074462891e-01) (5, 4.46279478073120117188e+00) (6, -1.13936157226562500000e+01) (7, -5.39284801483154296875e+00) (8, 4.59790267050266265869e-02) (9, -4.23028320074081420898e-01) (0, -7.26048767566680908203e-01) (1, -2.15975713729858398438e+00) (2, 4.85742187500000000000e+00) (3, -3.42520070075988769531e+00) (4, 9.76446866989135742188e-01) (5, 1.72414898872375488281e+00) (6, 2.53742432594299316406e+00) (7, -7.22270309925079345703e-01) (8, -6.57174491882324218750e+00) (9, -3.20548117160797119141e-01) (0, -9.04967308044433593750e+00) (1, -9.12591397762298583984e-01) (2, -2.94112606048583984375e+01) (3, 6.79816544055938720703e-01) (4, 4.37996596097946166992e-01) (5, -1.68903026580810546875e+01) (6, 3.88572841882705688477e-01) (7, 2.69737809896469116211e-01) (8, -1.43927929687500000000e+03) (9, 2.18035593628883361816e-01) (0, -1.10668671131134033203e+00) (1, 9.61310148239135742188e-01) (2, 3.35116791725158691406e+00) (3, -2.44121646881103515625e+00) (4, 3.02205264568328857422e-01) (5, 2.80053353309631347656e+00) (6, 3.51051592826843261719e+00) (7, -4.67312932014465332031e-01) (8, -7.76486039161682128906e-01) (9, -8.09948503971099853516e-01) (10, 1.85504817962646484375e+00) (11, 2.11758232116699218750e+00) (12, -2.09476065635681152344e+00) (13, -1.50000000000000000000e+03) (14, 1.87053239345550537109e+00) (15, 3.48380184173583984375e+00) (16, 5.15484380722045898438e+00) (17, -2.52769321203231811523e-01) (18, -7.97563135623931884766e-01) (10, 1.64027297496795654297e+00) (11, 4.86121845245361328125e+00) (12, 1.04018764495849609375e+01) (13, -1.50000000000000000000e+03) (14, 1.04774200916290283203e+00) (15, 3.83860516548156738281e+00) (16, 7.29282617568969726562e-01) (17, -9.73445773124694824219e-01) (18, -1.76222249865531921387e-01) (10, -1.65836215019226074219e+00) (11, -2.84484958648681640625e+00) (12, -1.15542554855346679688e+00) (13, 1.50000000000000000000e+03) (14, -6.81413233280181884766e-01) (15, -3.34939384460449218750e+00) (16, -6.67980313301086425781e-01) (17, 4.85261797904968261719e-01) (18, 1.75759002566337585449e-01) (10, 3.58604717254638671875e+00) (11, 1.97776174545288085938e+00) (12, -2.42376542091369628906e+00) (13, -1.50000000000000000000e+03) (14, 1.61262965202331542969e+00) (15, 9.46686506271362304688e-01) (16, 2.82073745727539062500e+01) (17, 1.20713293552398681641e+00) (18, -4.12614941596984863281e-01) (10, 2.41855740547180175781e+00) (11, 4.57085847854614257812e+00) (12, 1.25483398437500000000e+01) (13, -1.50000000000000000000e+03) (14, 7.01545894145965576172e-01) (15, 3.82108807563781738281e+00) (16, 2.14690685272216796875e+00) (17, -1.04410624504089355469e+00) (18, -1.20849981904029846191e-01) (10, -1.89816033840179443359e+00) (11, -2.94780063629150390625e+00) (12, 4.73187208175659179688e-01) (13, 1.50000000000000000000e+03) (14, -6.40913367271423339844e-01) (15, -2.32993125915527343750e+00) (16, -8.80149650573730468750e+00) (17, -5.18245816230773925781e-01) (18, 1.86715409159660339355e-01) (10, -9.17344629764556884766e-01) (11, -2.46734094619750976562e+00) (12, 1.38040155172348022461e-01) (13, 1.50000000000000000000e+03) (14, -5.48085331916809082031e-01) (15, -1.39435815811157226562e+00) (16, -6.73288679122924804688e+00) (17, -8.61540436744689941406e-01) (18, 2.17692434787750244141e-01) (10, -1.28820621967315673828e+00) (11, -1.18910694122314453125e+00) (12, 2.41450238227844238281e+00) (13, 1.50000000000000000000e+03) (14, -5.95731556415557861328e-01) (15, -1.38723731040954589844e+00) (16, -3.03627777099609375000e+00) (17, -1.03117191791534423828e+00) (18, 2.75619149208068847656e-01) (19, 3.73158335685729980469e-01) (20, 4.55354720354080200195e-01) (21, -2.87834692001342773438e+00) (22, 3.51344585418701171875e-01) (23, 4.59084451198577880859e-01) (24, -2.12852954864501953125e+00) (25, -2.01101636886596679688e+00) (26, -8.68052363395690917969e-01) (27, 6.49203807115554809570e-02) 
