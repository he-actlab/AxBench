FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 9 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -3.20375156402587890625e+00) (1, 3.37193775177001953125e+00) (2, -1.56417703628540039062e+01) (3, 3.58146452903747558594e+00) (4, 1.03776741027832031250e+00) (5, -9.19352948665618896484e-01) (6, -4.73443031311035156250e+00) (7, 1.03339231014251708984e+00) (8, -3.10933899879455566406e+00) (9, 1.57000005245208740234e+00) (0, -1.95487177371978759766e+00) (1, -1.73945868015289306641e+00) (2, -1.33910095691680908203e+00) (3, -3.27609866857528686523e-01) (4, 3.47121730446815490723e-02) (5, -7.71871328353881835938e-01) (6, 5.34430503845214843750e+00) (7, 2.33827665448188781738e-01) (8, -9.20878946781158447266e-01) (9, 3.76137465238571166992e-01) (0, -2.36531496047973632812e+00) (1, 4.90156635642051696777e-02) (2, -1.62315616607666015625e+01) (3, 1.23860053718090057373e-01) (4, 6.18707478046417236328e-01) (5, -8.06774735450744628906e-01) (6, 1.58131265640258789062e+00) (7, 6.32510721683502197266e-01) (8, -3.07379436492919921875e+00) (9, 4.04962450265884399414e-01) (0, -8.07792484760284423828e-01) (1, 2.54735499620437622070e-01) (2, 1.39232957363128662109e+00) (3, -1.64417219161987304688e+00) (4, 3.49433839321136474609e-01) (5, -7.47747421264648437500e-02) (6, 2.28796407580375671387e-01) (7, 5.88122606277465820312e-02) (8, -1.53356623649597167969e+00) (9, 2.13486385345458984375e+00) (0, -1.36868488788604736328e+00) (1, -4.87095236778259277344e-01) (2, -8.38999748229980468750e+00) (3, 1.21032364666461944580e-01) (4, 5.12954711914062500000e-01) (5, 2.50770282745361328125e+00) (6, 6.75152838230133056641e-01) (7, 4.36993211507797241211e-01) (8, -8.22685837745666503906e-01) (9, 6.10685229301452636719e-01) (0, -6.42911434173583984375e+00) (1, -5.38124799728393554688e-01) (2, -1.21922433376312255859e+00) (3, 3.85411024093627929688e+00) (4, -4.28235530853271484375e-01) (5, 3.85205745697021484375e-01) (6, 5.14510583877563476562e+00) (7, 8.47739100456237792969e-01) (8, -1.08988165855407714844e+00) (9, 1.09922611713409423828e+00) (0, -3.77114343643188476562e+00) (1, 2.49438449740409851074e-01) (2, 1.76528625488281250000e+01) (3, 2.76933979988098144531e+00) (4, 6.87480032444000244141e-01) (5, -1.77534174919128417969e+00) (6, 1.34184753894805908203e+00) (7, -1.01420223712921142578e+00) (8, 2.43578419089317321777e-01) (9, -3.75478208065032958984e-01) (0, -8.47802162170410156250e+00) (1, 2.67857253551483154297e-01) (2, -2.11542963981628417969e+00) (3, -2.68737101554870605469e+00) (4, -6.43245829269289970398e-03) (5, 6.33439794182777404785e-02) (6, -1.37598112225532531738e-01) (7, 2.77987629175186157227e-01) (8, -2.88165616989135742188e+00) (9, 8.69377076625823974609e-01) (10, 3.14496326446533203125e+00) (11, -1.18300559997558593750e+02) (12, -9.60187301635742187500e+01) (13, -2.04382400512695312500e+01) (14, 1.91835205078125000000e+02) (15, 2.11719932556152343750e+01) (16, 7.66483879089355468750e+00) (17, -4.41404449462890625000e+02) (18, 4.62883889675140380859e-01) (10, -7.24149322509765625000e+01) (11, -1.49544860839843750000e+03) (12, -9.70775413513183593750e+00) (13, -4.02887916564941406250e+01) (14, 8.29743499755859375000e+01) (15, -1.18099937438964843750e+02) (16, 1.14115705490112304688e+01) (17, 1.20441003417968750000e+03) (18, 8.54199230670928955078e-01) (10, 6.03880691528320312500e+00) (11, 1.25839920043945312500e+01) (12, -5.54081869125366210938e+00) (13, 3.12237119674682617188e+00) (14, -4.79098129272460937500e+00) (15, -5.77345609664916992188e+00) (16, -3.30626654624938964844e+00) (17, 1.35327663421630859375e+01) (18, -2.00920653343200683594e+00) (10, -3.98033447563648223877e-02) (11, -1.49895000457763671875e+00) (12, 1.16183006763458251953e+00) (13, -2.39151740074157714844e+00) (14, 8.60769689083099365234e-01) (15, -5.83736505359411239624e-03) (16, 8.36198151111602783203e-01) (17, -7.57383499145507812500e+01) (18, 1.94846287369728088379e-01) (10, -2.30888805389404296875e+01) (11, -5.26251411437988281250e+01) (12, -2.07121872901916503906e+00) (13, -6.65514516830444335938e+00) (14, -5.29074907302856445312e-01) (15, -4.67837238311767578125e+00) (16, -1.41154125332832336426e-01) (17, 6.29173316955566406250e+01) (18, 8.85791983455419540405e-03) (10, -1.45328918457031250000e+03) (11, -3.25009369850158691406e+00) (12, -1.48424389648437500000e+03) (13, 8.01678562164306640625e+00) (14, -3.12009549140930175781e+00) (15, -1.08845977783203125000e+01) (16, 7.82281875610351562500e-01) (17, 7.34096527099609375000e+01) (18, 8.07690713554620742798e-03) (10, -3.74075508117675781250e+01) (11, -3.46447639465332031250e+01) (12, -1.13539154052734375000e+02) (13, 7.98226594924926757812e+00) (14, -9.56830501556396484375e+00) (15, -6.99411273002624511719e-01) (16, -2.05152422189712524414e-01) (17, 3.01918144226074218750e+01) (18, 1.25498473644256591797e+00) (10, 3.19312572479248046875e+00) (11, -1.18341674804687500000e+02) (12, -9.85851135253906250000e+01) (13, -2.04665431976318359375e+01) (14, 1.91823699951171875000e+02) (15, 2.12400550842285156250e+01) (16, 7.62996387481689453125e+00) (17, -4.41322174072265625000e+02) (18, 4.73934769630432128906e-01) (19, -1.78886556625366210938e+00) (20, -4.91702795028686523438e+00) (21, 1.06594228744506835938e+00) (22, -3.89504003524780273438e+00) (23, -1.15774857997894287109e+00) (24, -4.18845748901367187500e+00) (25, 5.23299551010131835938e+00) (26, -1.77072298526763916016e+00) (27, 5.18423855304718017578e-01) 
