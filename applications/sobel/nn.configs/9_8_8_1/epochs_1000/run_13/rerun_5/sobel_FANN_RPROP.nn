FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 9 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -7.98213243484497070312e-01) (1, 5.53056812286376953125e+00) (2, 9.02093982696533203125e+00) (3, -1.05057525634765625000e+00) (4, 3.51763844490051269531e-01) (5, 3.32909870147705078125e+00) (6, -7.26151561737060546875e+00) (7, -2.06613025665283203125e+01) (8, 3.04755747318267822266e-01) (9, 1.24804198741912841797e+00) (0, -1.09725341796875000000e+01) (1, -5.72894871234893798828e-01) (2, -7.36854934692382812500e+00) (3, -3.03077459335327148438e-01) (4, 1.72663748264312744141e+00) (5, 4.36467981338500976562e+00) (6, 3.74959141016006469727e-01) (7, 1.08610048294067382812e+01) (8, 1.06008255481719970703e+00) (9, -8.87460827827453613281e-01) (0, -1.28613269329071044922e+00) (1, 6.40229225158691406250e+00) (2, -5.59156990051269531250e+00) (3, 9.43048894405364990234e-01) (4, -7.86799728870391845703e-01) (5, -8.13236534595489501953e-01) (6, 5.86326408386230468750e+00) (7, 4.87139016389846801758e-01) (8, 1.65463495254516601562e+00) (9, -1.69680893421173095703e+00) (0, -1.02087745666503906250e+01) (1, 5.27218437194824218750e+00) (2, 1.68163931369781494141e+00) (3, 2.44101926684379577637e-01) (4, -1.80586421489715576172e+00) (5, 1.96318721771240234375e+00) (6, -1.17861490249633789062e+01) (7, -5.04159927368164062500e+00) (8, 1.43903344869613647461e-01) (9, 5.33061027526855468750e-01) (0, -1.21763925552368164062e+01) (1, -3.42077851295471191406e+00) (2, 8.16637426614761352539e-02) (3, -9.60539430379867553711e-02) (4, 2.19450235366821289062e+00) (5, 2.17856955528259277344e+00) (6, 1.03984184563159942627e-01) (7, -8.89049470424652099609e-01) (8, 1.36848640441894531250e+00) (9, 1.79257243871688842773e-01) (0, -1.24898099899291992188e+01) (1, -3.75361919403076171875e-01) (2, -6.43867540359497070312e+00) (3, -3.60445290803909301758e-01) (4, 2.29616194963455200195e-01) (5, 3.98692226409912109375e+00) (6, 5.49766397476196289062e+00) (7, -6.98135852813720703125e-01) (8, 1.08386478424072265625e+01) (9, -2.52336055040359497070e-01) (0, -9.24753856658935546875e+00) (1, -5.26598334312438964844e-01) (2, 5.68749368190765380859e-01) (3, 2.23101735115051269531e+00) (4, 2.59785318374633789062e+00) (5, 2.24110622406005859375e+01) (6, -8.55926990509033203125e-01) (7, -1.89995169639587402344e+00) (8, 1.02704977989196777344e+00) (9, -1.54187607765197753906e+00) (0, -1.36437168121337890625e+01) (1, -6.87308549880981445312e-01) (2, -2.05952620506286621094e+00) (3, -1.19851624965667724609e+00) (4, -5.38583576679229736328e-01) (5, 5.27572810649871826172e-01) (6, 1.17664403915405273438e+01) (7, -5.35873591899871826172e-01) (8, -8.64735916256904602051e-02) (9, -3.56215763092041015625e+00) (10, 3.01010799407958984375e+00) (11, 1.19663929939270019531e+00) (12, -1.97557151317596435547e-01) (13, 9.75317859649658203125e+00) (14, -2.54083961248397827148e-01) (15, 4.78825658559799194336e-01) (16, 3.55779242515563964844e+00) (17, 1.95069611072540283203e-01) (18, -1.41803538799285888672e+00) (10, 2.11260151863098144531e+00) (11, 3.41229963302612304688e+00) (12, -1.53216540813446044922e-01) (13, -1.13275265693664550781e+00) (14, -7.89829194545745849609e-01) (15, -4.13440418243408203125e+00) (16, 3.59360980987548828125e+00) (17, 1.45283684134483337402e-01) (18, -5.34849524497985839844e-01) (10, 8.01236248016357421875e+00) (11, 2.97262516021728515625e+01) (12, -5.01433499157428741455e-02) (13, 3.92027969360351562500e+01) (14, -2.60516319274902343750e+01) (15, 9.87895190715789794922e-01) (16, 3.26814961433410644531e+00) (17, 1.06576323509216308594e+00) (18, -6.28807973861694335938e+00) (10, 3.92257738113403320312e+00) (11, 4.25020027160644531250e+00) (12, -6.79742023348808288574e-02) (13, 4.47038269042968750000e+00) (14, -3.24705153703689575195e-01) (15, -4.24364835023880004883e-01) (16, 3.53922247886657714844e+00) (17, 4.44723069667816162109e-02) (18, -2.38350462913513183594e+00) (10, -2.82862162590026855469e+00) (11, -2.19086909294128417969e+00) (12, -4.52303826808929443359e-01) (13, -5.82250915467739105225e-02) (14, -4.92840230464935302734e-01) (15, -6.67189061641693115234e-01) (16, -8.08495044708251953125e-01) (17, -4.26207661628723144531e-01) (18, -3.01009416580200195312e-01) (10, -2.53246569633483886719e+00) (11, -5.38106262683868408203e-01) (12, -7.38809227943420410156e-01) (13, 1.89981102943420410156e+00) (14, -3.30235481262207031250e-01) (15, -5.12832045555114746094e-01) (16, -6.49936139583587646484e-01) (17, 4.62328381836414337158e-02) (18, -3.26442956924438476562e-01) (10, -2.23476290702819824219e+00) (11, -1.49108314514160156250e+00) (12, -9.30838942527770996094e-01) (13, -2.12458562850952148438e+00) (14, 3.25374662876129150391e-01) (15, -9.39212322235107421875e-01) (16, -5.32970964908599853516e-01) (17, -5.99605739116668701172e-01) (18, -1.26227587461471557617e-01) (10, 9.43169355392456054688e-01) (11, 3.10964398086071014404e-02) (12, 1.00844991207122802734e+00) (13, -4.94722747802734375000e+00) (14, -9.34210181236267089844e-01) (15, -1.70107150077819824219e+00) (16, 8.37396812438964843750e+00) (17, -2.41736340522766113281e+00) (18, -3.18658733367919921875e+00) (19, 2.13202238082885742188e-01) (20, 2.01868578791618347168e-01) (21, 2.41537764668464660645e-01) (22, 2.69929230213165283203e-01) (23, -1.35462069511413574219e+00) (24, -8.44717621803283691406e-01) (25, -4.77648258209228515625e+00) (26, 1.91161498427391052246e-01) (27, -4.51614633202552795410e-02) 
