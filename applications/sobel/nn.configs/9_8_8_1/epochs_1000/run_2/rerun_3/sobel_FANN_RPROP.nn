FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 9 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -8.31746876239776611328e-01) (1, -2.26044273376464843750e+01) (2, -5.26836395263671875000e+00) (3, 2.37589335441589355469e+00) (4, -2.64082121849060058594e+00) (5, -1.29204595088958740234e+00) (6, 5.88166904449462890625e+00) (7, 4.93485003709793090820e-01) (8, 1.71527023315429687500e+01) (9, 3.87427806854248046875e-01) (0, 6.85024559497833251953e-01) (1, -5.87069845199584960938e+00) (2, 4.21608781814575195312e+00) (3, 1.01201355457305908203e+00) (4, -6.24847126007080078125e+00) (5, -1.65001940727233886719e+00) (6, 1.61321473121643066406e+00) (7, -2.77211403846740722656e+00) (8, 5.54016447067260742188e+00) (9, 4.83048111200332641602e-01) (0, -6.46909356117248535156e-01) (1, -3.88846182823181152344e+00) (2, 4.03335857391357421875e+00) (3, 9.63125526905059814453e-01) (4, -7.63495779037475585938e+00) (5, -2.03700637817382812500e+00) (6, 2.61344051361083984375e+00) (7, -4.62615585327148437500e+00) (8, 5.62950706481933593750e+00) (9, 4.92172032594680786133e-01) (0, 2.17025756835937500000e-01) (1, 2.31266727447509765625e+01) (2, 2.33492231369018554688e+00) (3, -9.38396167755126953125e+00) (4, 3.60527753829956054688e-01) (5, -4.12405128479003906250e+01) (6, -7.27452135086059570312e+00) (7, -5.63516438007354736328e-01) (8, -1.83436250686645507812e+00) (9, -3.65677416324615478516e-01) (0, -6.08887970447540283203e-01) (1, 6.27346862792968750000e+02) (2, 6.19943054199218750000e+02) (3, 1.05676245689392089844e+00) (4, -1.15050210952758789062e+01) (5, 2.87044616699218750000e+02) (6, 3.47646427154541015625e+00) (7, -1.18523225188255310059e-01) (8, 8.18083190917968750000e+02) (9, 3.44766587018966674805e-01) (0, -6.90034985542297363281e-01) (1, 5.64719259738922119141e-01) (2, -2.04057941436767578125e+01) (3, 5.62244951725006103516e-02) (4, 1.23676669597625732422e+00) (5, 1.36993148803710937500e+02) (6, -1.57026469707489013672e+00) (7, 6.61247909069061279297e-01) (8, 4.75155687332153320312e+00) (9, -2.02009409666061401367e-01) (0, -5.18342256546020507812e-01) (1, -8.36744213104248046875e+00) (2, 6.59239813685417175293e-02) (3, 1.80300140380859375000e+00) (4, -1.15638751983642578125e+01) (5, -1.80016064643859863281e+00) (6, 3.02038145065307617188e+00) (7, -3.70052009820938110352e-01) (8, 4.95466852188110351562e+00) (9, 2.18367385864257812500e+00) (0, 3.18343353271484375000e+00) (1, -6.78889465332031250000e+00) (2, 4.32523632049560546875e+00) (3, 1.16316020488739013672e+00) (4, -7.37741470336914062500e+00) (5, -2.35268092155456542969e+00) (6, 1.37107002735137939453e+00) (7, -1.83645868301391601562e+00) (8, 5.28108024597167968750e+00) (9, 5.60661554336547851562e-01) (10, -1.66958984375000000000e+02) (11, -9.97339782714843750000e+01) (12, -2.56494293212890625000e+01) (13, -9.12594509124755859375e+00) (14, 1.46825744628906250000e+03) (15, 9.86191689968109130859e-01) (16, 6.31602294921875000000e+02) (17, -8.98505325317382812500e+01) (18, -1.58542081713676452637e-01) (10, -6.55883884429931640625e+00) (11, -7.69268798828125000000e+02) (12, -2.88950967788696289062e+00) (13, -3.95492434501647949219e+00) (14, 3.37088897705078125000e+02) (15, 4.46309041976928710938e+00) (16, -5.33484363555908203125e+00) (17, -2.57105712890625000000e+02) (18, 1.14979386329650878906e-01) (10, -5.19749450683593750000e+01) (11, -3.99812652587890625000e+02) (12, -4.72104675292968750000e+02) (13, -9.00720787048339843750e+00) (14, 5.71899902343750000000e+02) (15, 1.01584014892578125000e+01) (16, -1.33845243453979492188e+01) (17, -5.09910736083984375000e+02) (18, 3.94959479570388793945e-01) (10, -4.93634002685546875000e+02) (11, -1.70205154418945312500e+02) (12, -1.29495162963867187500e+01) (13, -9.08884811401367187500e+00) (14, 1.01082061767578125000e+03) (15, 2.77140116691589355469e+00) (16, -2.23358749389648437500e+02) (17, -4.55271987915039062500e+01) (18, 2.30302751064300537109e-01) (10, 1.49880163574218750000e+03) (11, 2.89366607666015625000e+02) (12, 1.85700454711914062500e+01) (13, 6.12651777267456054688e+00) (14, -1.10964941978454589844e+00) (15, 3.34275603294372558594e-01) (16, 3.87897766113281250000e+02) (17, 1.40123718261718750000e+02) (18, 1.01390607655048370361e-01) (10, 1.49880163574218750000e+03) (11, 4.18333343505859375000e+02) (12, 1.99082708358764648438e+00) (13, 1.43383893966674804688e+01) (14, -5.37091791629791259766e-02) (15, 4.40313011407852172852e-01) (16, 3.86134460449218750000e+02) (17, 4.32129272460937500000e+02) (18, 2.94999212026596069336e-01) (10, -1.06697181701660156250e+02) (11, -1.81256027221679687500e+02) (12, -1.92480850219726562500e+01) (13, -2.45447444915771484375e+00) (14, 2.61319885253906250000e+02) (15, 9.86717414855957031250e+00) (16, -9.43016052246093750000e+01) (17, -2.10511718750000000000e+02) (18, -8.43571871519088745117e-02) (10, -7.18127014160156250000e+02) (11, -9.82304840087890625000e+01) (12, -1.29978771209716796875e+01) (13, 1.42048251628875732422e+00) (14, 1.05181716918945312500e+02) (15, 9.54602301120758056641e-01) (16, -7.33651123046875000000e+01) (17, -7.12757720947265625000e+01) (18, -1.71022981405258178711e-01) (19, 4.73801642656326293945e-01) (20, 5.06046056747436523438e-01) (21, 6.15981221199035644531e-01) (22, 5.82513570785522460938e-01) (23, -6.33684754371643066406e-01) (24, -1.78714632987976074219e+00) (25, 9.72410142421722412109e-01) (26, -4.35148831456899642944e-03) (27, 1.40635311603546142578e-01) 
