FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 9 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.50000000000000000000e+03) (1, -3.91087293624877929688e+00) (2, -8.84640753269195556641e-01) (3, 3.36540889739990234375e+00) (4, 4.02860107421875000000e+02) (5, 2.65932369232177734375e+01) (6, 1.50000000000000000000e+03) (7, 9.99345421791076660156e-01) (8, 9.83246028423309326172e-01) (9, 5.22162318229675292969e-01) (0, -7.45778799057006835938e-01) (1, -4.72829222679138183594e-01) (2, 2.04477667808532714844e+00) (3, -5.85801243782043457031e-01) (4, 1.45945310592651367188e+00) (5, -2.80883669853210449219e-01) (6, -5.00432789325714111328e-01) (7, -3.54591059684753417969e+00) (8, -6.32847905158996582031e-01) (9, 2.97029137611389160156e-01) (0, -1.04737019538879394531e+00) (1, -1.22247314453125000000e+00) (2, -5.95351271331310272217e-02) (3, -1.05157151818275451660e-01) (4, 3.94412994384765625000e+00) (5, -9.66963469982147216797e-01) (6, 1.12386548519134521484e+00) (7, -8.48677933216094970703e-01) (8, -1.13130748271942138672e+00) (9, 2.09194466471672058105e-01) (0, -5.91807484626770019531e-01) (1, -3.27425628900527954102e-01) (2, 2.04883885383605957031e+00) (3, -9.10763978958129882812e-01) (4, 1.71613752841949462891e+00) (5, -1.55709594488143920898e-01) (6, -4.50325280427932739258e-01) (7, -3.49979972839355468750e+00) (8, -9.57219958305358886719e-01) (9, 4.24068778753280639648e-01) (0, -9.62642383575439453125e+00) (1, -1.09126310348510742188e+01) (2, -3.72412276268005371094e+00) (3, 1.56051397323608398438e-01) (4, -1.08330452442169189453e+00) (5, -3.71410816907882690430e-01) (6, 7.45520448684692382812e+00) (7, 2.43066525459289550781e+00) (8, 8.46581745147705078125e+00) (9, -8.03427696228027343750e-01) (0, -3.23136258125305175781e+00) (1, -3.68432909250259399414e-01) (2, 2.00064015388488769531e+00) (3, 1.03298826217651367188e+01) (4, -2.47171449661254882812e+00) (5, -1.67451133728027343750e+01) (6, 3.25898666381835937500e+01) (7, -2.37240719795227050781e+00) (8, -4.89077806472778320312e-01) (9, -1.24949896335601806641e+00) (0, -7.04687118530273437500e-01) (1, -1.84645876288414001465e-01) (2, 3.06727814674377441406e+00) (3, -2.56710320711135864258e-01) (4, 4.96264743804931640625e+00) (5, -1.44791722297668457031e+00) (6, -9.27323162555694580078e-01) (7, -4.73386621475219726562e+00) (8, -1.79540634155273437500e+00) (9, 4.85290437936782836914e-01) (0, -8.96637141704559326172e-01) (1, -4.62081909179687500000e-01) (2, 1.74755454063415527344e+00) (3, -8.24893236160278320312e-01) (4, 2.50686526298522949219e+00) (5, -5.81999182701110839844e-01) (6, -4.22397166490554809570e-01) (7, -2.96009659767150878906e+00) (8, -9.98422443866729736328e-01) (9, 3.02496135234832763672e-01) (10, 1.33483666992187500000e+03) (11, -1.32536267089843750000e+03) (12, 1.15638732910156250000e+01) (13, -1.02585624694824218750e+02) (14, 1.23024121093750000000e+03) (15, -7.11016845703125000000e+02) (16, 2.64117312431335449219e+00) (17, -1.33902130126953125000e+02) (18, 1.39245744794607162476e-02) (10, 1.35171606445312500000e+03) (11, -9.67346313476562500000e+02) (12, 6.18465185165405273438e-01) (13, 4.28257656097412109375e+00) (14, -5.94522766113281250000e+02) (15, -4.95077636718750000000e+02) (16, 3.41516876220703125000e+00) (17, -1.26131210327148437500e+02) (18, 8.07416066527366638184e-02) (10, 1.36471887207031250000e+03) (11, -1.28853344726562500000e+03) (12, 1.91831798553466796875e+01) (13, 5.20723056793212890625e+00) (14, -5.94522766113281250000e+02) (15, -5.12819824218750000000e+02) (16, 3.01073288917541503906e+00) (17, -1.25886802673339843750e+02) (18, 2.43768729269504547119e-02) (10, 1.48796081542968750000e+03) (11, -1.15213098144531250000e+03) (12, 3.06311283111572265625e+01) (13, 4.84758901596069335938e+00) (14, -5.82093566894531250000e+02) (15, -7.50003723144531250000e+02) (16, 2.96246457099914550781e+00) (17, -1.25901725769042968750e+02) (18, 1.27186536788940429688e-01) (10, -5.35405588150024414062e+00) (11, -3.22485389709472656250e+01) (12, 1.89493064880371093750e+01) (13, 1.13997602462768554688e+01) (14, 8.94750366210937500000e+01) (15, -4.96183604001998901367e-01) (16, 6.22500038146972656250e+00) (17, 4.30036115646362304688e+00) (18, 5.15179991722106933594e-01) (10, -5.70495605468750000000e-01) (11, -1.01821470260620117188e+00) (12, -7.80931234359741210938e-01) (13, -1.58126080036163330078e+00) (14, -3.63194227218627929688e+00) (15, 1.60078912973403930664e-01) (16, -5.73274183273315429688e+00) (17, -1.48408389091491699219e+00) (18, 1.77787101268768310547e+00) (10, 1.33456420898437500000e+03) (11, -5.34886596679687500000e+02) (12, 1.15722131729125976562e+01) (13, -2.49903392791748046875e+01) (14, -5.62451362609863281250e+01) (15, -1.16992968750000000000e+03) (16, 4.96931362152099609375e+00) (17, -6.05324516296386718750e+01) (18, 2.79377922415733337402e-02) (10, 6.38024449348449707031e-01) (11, -2.08003926277160644531e+00) (12, -2.16047239303588867188e+00) (13, -2.11713361740112304688e+00) (14, -4.05198192596435546875e+00) (15, 2.61337846517562866211e-01) (16, -2.90967822074890136719e+00) (17, -1.96447384357452392578e+00) (18, 1.69702708721160888672e+00) (19, 1.87563002109527587891e-01) (20, 1.17591530084609985352e-01) (21, 1.40574812889099121094e-01) (22, 1.50610491633415222168e-01) (23, 1.48168742656707763672e-01) (24, -4.19623994827270507812e+00) (25, 1.79317653179168701172e-01) (26, -4.49112224578857421875e+00) (27, 7.51786157488822937012e-02) 
