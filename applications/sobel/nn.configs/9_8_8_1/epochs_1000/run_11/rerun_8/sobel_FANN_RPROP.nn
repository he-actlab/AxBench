FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 9 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.46140885353088378906e+00) (1, 8.17024326324462890625e+00) (2, 6.14032125473022460938e+00) (3, 2.12000465393066406250e+00) (4, -3.50934147834777832031e+00) (5, 1.25964565277099609375e+01) (6, -1.89361248016357421875e+01) (7, -3.92336988449096679688e+00) (8, -3.37722957134246826172e-01) (9, 1.17265272140502929688e+00) (0, -3.77898335456848144531e+00) (1, -1.62910950183868408203e+00) (2, -1.77231674194335937500e+01) (3, -9.61378455162048339844e-01) (4, -1.53845243453979492188e+01) (5, -1.05837547779083251953e+00) (6, 2.44244232177734375000e+01) (7, 3.58566641807556152344e+00) (8, 6.50590419769287109375e+00) (9, 3.82742404937744140625e+00) (0, -3.94103527069091796875e-01) (1, -1.35254430770874023438e+01) (2, -2.68192195892333984375e+01) (3, 2.99365377426147460938e+00) (4, 6.02477502822875976562e+00) (5, 1.42590011596679687500e+02) (6, 1.50571765899658203125e+01) (7, -8.48654937744140625000e+00) (8, -1.30975479125976562500e+02) (9, -1.80426585674285888672e+00) (0, 2.52392864227294921875e+00) (1, 2.31838035583496093750e+00) (2, 1.90695533752441406250e+01) (3, 3.96623778343200683594e+00) (4, -2.04774341583251953125e+01) (5, -9.22327499389648437500e+01) (6, -4.87877321243286132812e+00) (7, 4.58737831115722656250e+01) (8, 7.66685333251953125000e+01) (9, 1.07665929794311523438e+01) (0, -2.15360617637634277344e+00) (1, -1.65568637847900390625e+01) (2, -7.17087829589843750000e+02) (3, 6.00511193275451660156e-01) (4, -8.34259277343750000000e+02) (5, -1.50000000000000000000e+03) (6, -2.24796508789062500000e+02) (7, -2.89341278076171875000e+01) (8, -1.50000000000000000000e+03) (9, 4.19932365417480468750e+00) (0, -3.13627791404724121094e+00) (1, -1.79930877685546875000e+00) (2, -1.67798004150390625000e+01) (3, 1.66887617111206054688e+00) (4, -1.28324460983276367188e+01) (5, -5.65925776958465576172e-01) (6, 1.80868759155273437500e+01) (7, 7.59267377853393554688e+00) (8, 4.86597776412963867188e+00) (9, 2.77609777450561523438e+00) (0, -7.18012142181396484375e+00) (1, -1.71356892585754394531e+00) (2, 1.86372721195220947266e+00) (3, -3.53891301155090332031e+00) (4, 1.26497802734375000000e+01) (5, 5.94927597045898437500e+00) (6, 1.98454046249389648438e+00) (7, -9.04039192199707031250e+00) (8, -1.43865928649902343750e+01) (9, -1.70710906386375427246e-01) (0, 9.60718307495117187500e+01) (1, -1.11881322860717773438e+01) (2, 1.14233764648437500000e+03) (3, 7.52723922729492187500e+01) (4, 6.69401855468750000000e+01) (5, 1.50000000000000000000e+03) (6, 2.26402023315429687500e+02) (7, 1.67427778244018554688e+00) (8, 1.40755017089843750000e+03) (9, 2.14369344711303710938e+00) (10, 1.15431809425354003906e+00) (11, -2.61469459533691406250e+00) (12, 3.26795458793640136719e+00) (13, 2.57191944122314453125e+00) (14, 3.49902801513671875000e+02) (15, -8.34244489669799804688e-01) (16, 3.83218994140625000000e+01) (17, -3.71439385414123535156e+00) (18, 1.53715580701828002930e-01) (10, -9.68025085449218750000e+02) (11, -1.28012588500976562500e+02) (12, -4.78220825195312500000e+02) (13, 4.01470642089843750000e+02) (14, 1.41515039062500000000e+03) (15, -1.04510278320312500000e+03) (16, -1.20797737121582031250e+02) (17, -8.14809326171875000000e+02) (18, -4.95671272277832031250e+00) (10, -8.74817371368408203125e+00) (11, -2.24743377685546875000e+02) (12, -2.17873191833496093750e+00) (13, 2.12426101684570312500e+02) (14, 6.05478027343750000000e+02) (15, -4.16455793380737304688e+00) (16, 8.10158491134643554688e-01) (17, 3.06757431030273437500e+01) (18, -7.52973794937133789062e-01) (10, -3.18945503234863281250e+00) (11, -8.01193773746490478516e-01) (12, -7.15677887201309204102e-02) (13, 6.24173820018768310547e-01) (14, 3.72904133796691894531e+00) (15, -2.34089326858520507812e+00) (16, -1.72317892313003540039e-01) (17, -4.03958037495613098145e-02) (18, 4.35280412435531616211e-01) (10, 3.16785964965820312500e+01) (11, -1.66571884155273437500e+01) (12, 1.30995690822601318359e+00) (13, 1.65383090972900390625e+01) (14, 6.31161071777343750000e+02) (15, -1.33403253555297851562e+00) (16, -3.34949165582656860352e-01) (17, 2.78847664594650268555e-02) (18, 5.88623583316802978516e-01) (10, -9.68087707519531250000e+02) (11, -1.28010208129882812500e+02) (12, -4.78072021484375000000e+02) (13, 4.01470642089843750000e+02) (14, 1.41515039062500000000e+03) (15, -1.04504052734375000000e+03) (16, -1.20617195129394531250e+02) (17, -8.14809326171875000000e+02) (18, -4.97530078887939453125e+00) (10, -1.91598737239837646484e+00) (11, -8.26366233825683593750e+00) (12, 6.79467976093292236328e-01) (13, 2.23123840332031250000e+02) (14, 4.11489959716796875000e+02) (15, 5.84414577484130859375e+00) (16, 2.95982289314270019531e+00) (17, -1.46921813488006591797e+00) (18, -2.74702101945877075195e-01) (10, 1.15066969394683837891e+00) (11, -1.79211974143981933594e+00) (12, -1.44691448658704757690e-02) (13, 8.55466604232788085938e-01) (14, -3.89133739471435546875e+00) (15, -8.75288918614387512207e-02) (16, 1.55759131908416748047e+00) (17, 2.32030510902404785156e+00) (18, -9.89805221557617187500e-01) (19, 4.00253534317016601562e-01) (20, 1.50000000000000000000e+03) (21, -5.85131525993347167969e-01) (22, 3.04821624755859375000e+01) (23, 2.92741388082504272461e-01) (24, 1.50000000000000000000e+03) (25, -2.14387798309326171875e+00) (26, 7.24441260099411010742e-02) (27, 2.23913803696632385254e-01) 
