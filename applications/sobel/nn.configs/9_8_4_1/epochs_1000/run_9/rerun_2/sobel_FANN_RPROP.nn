FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 2.54814356565475463867e-01) (1, -1.78607141971588134766e+00) (2, 6.16962671279907226562e+00) (3, 8.64012539386749267578e-01) (4, -6.62810564041137695312e+00) (5, 2.81431198120117187500e-01) (6, 1.21940207481384277344e+00) (7, 3.70990872383117675781e+00) (8, -1.21333503723144531250e+00) (9, -1.05584573745727539062e+00) (0, 2.44165044277906417847e-02) (1, -6.88759148120880126953e-01) (2, 6.16167211532592773438e+00) (3, 7.32520103454589843750e-01) (4, -6.87585639953613281250e+00) (5, 3.00867140293121337891e-01) (6, 1.96600461006164550781e+00) (7, 1.10455548763275146484e+00) (8, 3.01581084728240966797e-01) (9, -8.37975740432739257812e-01) (0, -2.07297112792730331421e-02) (1, -1.26327991485595703125e+00) (2, 3.70262503623962402344e+00) (3, 4.77363735437393188477e-01) (4, -5.88930273056030273438e+00) (5, 7.43326902389526367188e-01) (6, 1.47830402851104736328e+00) (7, 1.25840544700622558594e+00) (8, -4.58034984767436981201e-02) (9, -2.85596847534179687500e-01) (0, -4.48940336704254150391e-01) (1, -1.37858021259307861328e+00) (2, 5.56043767929077148438e+00) (3, 3.49604159593582153320e-01) (4, -6.85324907302856445312e+00) (5, 6.74953237175941467285e-02) (6, 2.33871769905090332031e+00) (7, 1.16245925426483154297e+00) (8, -9.37014073133468627930e-02) (9, -5.08011102676391601562e-01) (0, -2.31288647651672363281e+00) (1, -6.28045439720153808594e-01) (2, 2.65320301055908203125e+00) (3, 4.37329053878784179688e-01) (4, -5.75668525695800781250e+00) (5, -9.01161372661590576172e-01) (6, 1.09273982048034667969e+00) (7, 5.44242286682128906250e+00) (8, -6.20705270767211914062e+00) (9, 8.87147262692451477051e-02) (0, -3.85959260165691375732e-02) (1, -6.31623566150665283203e-01) (2, 3.30996465682983398438e+00) (3, 4.32167083024978637695e-01) (4, -5.76712322235107421875e+00) (5, 5.98822116851806640625e-01) (6, 1.44817721843719482422e+00) (7, 1.48961710929870605469e+00) (8, -5.35446166992187500000e-01) (9, -3.84807914495468139648e-01) (0, 3.81937205791473388672e-01) (1, -3.78029346466064453125e-01) (2, 6.69912815093994140625e+00) (3, 3.17737102508544921875e+00) (4, -7.14733362197875976562e+00) (5, 6.63360178470611572266e-01) (6, 9.18529808521270751953e-01) (7, 7.66311407089233398438e-01) (8, 2.45133727788925170898e-01) (9, -1.50341165065765380859e+00) (0, -3.36637124419212341309e-02) (1, -5.44198751449584960938e-01) (2, 6.38713645935058593750e+00) (3, 2.06613230705261230469e+00) (4, -6.78317308425903320312e+00) (5, 1.50351428985595703125e+00) (6, 1.72243297100067138672e+00) (7, 1.10441863536834716797e+00) (8, 3.02038103342056274414e-01) (9, -2.22155833244323730469e+00) (10, -4.39748811721801757812e+00) (11, -8.66474723815917968750e+00) (12, 1.04270078241825103760e-01) (13, -6.66573667526245117188e+00) (14, -7.56120085716247558594e-01) (15, 4.47971731424331665039e-01) (16, -1.29851264953613281250e+01) (17, -1.11631555557250976562e+01) (18, 3.12708854675292968750e+01) (10, -5.37672376632690429688e+00) (11, -6.40065574645996093750e+00) (12, -5.10625690221786499023e-02) (13, -5.49351119995117187500e+00) (14, 6.49818062782287597656e-01) (15, 1.40002995729446411133e-01) (16, -7.89227056503295898438e+00) (17, -5.51245164871215820312e+00) (18, 2.10703639984130859375e+01) (10, -1.47898399829864501953e+00) (11, -5.79936647415161132812e+00) (12, 5.98375380039215087891e-01) (13, -1.38975155353546142578e+00) (14, 2.46640796661376953125e+01) (15, 6.02441370487213134766e-01) (16, -8.72361373901367187500e+00) (17, -1.12648849487304687500e+01) (18, 2.05488872528076171875e+01) (10, -1.21465826034545898438e+01) (11, -1.22604262828826904297e+00) (12, -2.75725078582763671875e+00) (13, -1.52226281166076660156e+00) (14, -4.08219051361083984375e+00) (15, -2.67595601081848144531e+00) (16, -1.23099541664123535156e+00) (17, -3.03274846076965332031e+00) (18, 1.16060705184936523438e+01) (19, -7.83761203289031982422e-01) (20, -1.10230958461761474609e+00) (21, -8.23625624179840087891e-01) (22, 3.72192263603210449219e+00) (23, -6.74549639225006103516e-02) 
