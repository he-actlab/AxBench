FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 3.72614450752735137939e-02) (1, 5.20130753517150878906e-01) (2, -1.13249692916870117188e+01) (3, 1.87418305873870849609e+00) (4, 6.75167608261108398438e+00) (5, -8.61845207214355468750e+00) (6, 8.28321933746337890625e+00) (7, -5.42649221420288085938e+00) (8, 1.16342151165008544922e+00) (9, -4.36262525618076324463e-02) (0, 1.19517073035240173340e-01) (1, 3.02660316228866577148e-01) (2, -2.11118745803833007812e+00) (3, 4.58005094528198242188e+00) (4, 5.09285020828247070312e+00) (5, 4.01593923568725585938e-01) (6, -1.96071956306695938110e-02) (7, -2.99803996086120605469e+00) (8, 4.04173803329467773438e+00) (9, -4.61670070886611938477e-01) (0, -1.96793213486671447754e-01) (1, 7.21441805362701416016e-01) (2, -9.82665729522705078125e+00) (3, 3.18466946482658386230e-02) (4, 7.17446279525756835938e+00) (5, -2.30145072937011718750e+00) (6, -8.34999680519104003906e-01) (7, -2.15121841430664062500e+00) (8, -4.37968105077743530273e-01) (9, -2.78017252683639526367e-01) (0, 1.36838185787200927734e+00) (1, 2.71498978137969970703e-01) (2, -2.67043709754943847656e+00) (3, 4.62886095046997070312e-01) (4, 5.25567674636840820312e+00) (5, -4.04271408915519714355e-02) (6, 6.96932649612426757812e+00) (7, -5.49851751327514648438e+00) (8, 4.36628150939941406250e+00) (9, -1.96732032299041748047e+00) (0, -7.37404942512512207031e-01) (1, 7.46388971805572509766e-01) (2, -1.73326225280761718750e+01) (3, 3.54118418693542480469e+00) (4, 6.86815547943115234375e+00) (5, -8.10168361663818359375e+00) (6, 7.34954786300659179688e+00) (7, -4.82106685638427734375e+00) (8, 3.40577483177185058594e+00) (9, 1.72633862495422363281e+00) (0, -4.86310511827468872070e-01) (1, 1.45875024795532226562e+00) (2, -1.33655607700347900391e+00) (3, 7.72042751312255859375e-01) (4, 3.73669409751892089844e+00) (5, 1.66035044193267822266e+00) (6, -1.53571729660034179688e+01) (7, -4.62275743484497070312e+00) (8, 7.08770275115966796875e+00) (9, -1.26170963048934936523e-02) (0, 8.61641824245452880859e-01) (1, 3.14906686544418334961e-01) (2, -4.65097045898437500000e+00) (3, -6.92344665527343750000e-01) (4, 8.84944629669189453125e+00) (5, -3.08629727363586425781e+00) (6, -9.84071671962738037109e-01) (7, -3.54230999946594238281e+00) (8, 3.80897688865661621094e+00) (9, -5.29024243354797363281e-01) (0, -1.86956202983856201172e+00) (1, -1.20981192588806152344e+00) (2, 4.39450740814208984375e-01) (3, -1.00935971736907958984e+00) (4, -6.73673689365386962891e-01) (5, -2.45338559150695800781e-01) (6, -1.60883218050003051758e-01) (7, 4.79209810495376586914e-01) (8, -4.49631834030151367188e+00) (9, 5.53063690662384033203e-01) (10, -1.42640411853790283203e+00) (11, -4.13358151912689208984e-01) (12, -8.69258582592010498047e-01) (13, -1.54676628112792968750e+00) (14, -1.24508142471313476562e+00) (15, -4.37746810913085937500e+00) (16, 4.12751197814941406250e+00) (17, 4.76670360565185546875e+00) (18, -2.19472125172615051270e-01) (10, -5.83805799484252929688e+00) (11, -4.22982335090637207031e-01) (12, -4.23557233810424804688e+00) (13, -1.15939974784851074219e+00) (14, -2.28756332397460937500e+00) (15, -2.26567459106445312500e+00) (16, 4.97970676422119140625e+00) (17, 8.37207376956939697266e-01) (18, -4.63474124670028686523e-01) (10, -1.52171671390533447266e+00) (11, -6.15131080150604248047e-01) (12, -8.59323024749755859375e-01) (13, -1.30512428283691406250e+00) (14, -1.43239974975585937500e+00) (15, -2.79904747009277343750e+00) (16, 1.81236052513122558594e+00) (17, 6.70136404037475585938e+00) (18, -1.76978334784507751465e-01) (10, -1.33974146842956542969e+00) (11, -6.41408562660217285156e-01) (12, -3.99687767028808593750e-01) (13, -1.12603914737701416016e+00) (14, -1.43817889690399169922e+00) (15, -2.05294489860534667969e+00) (16, 1.74955105781555175781e+00) (17, 3.74712443351745605469e+00) (18, -2.62193053960800170898e-01) (19, -5.17554903030395507812e+00) (20, -6.77905499935150146484e-01) (21, -9.49891209602355957031e-01) (22, -2.99701023101806640625e+00) (23, 1.96205985546112060547e+00) 
