FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -3.69576603174209594727e-01) (1, 7.83782660961151123047e-01) (2, -5.88927090167999267578e-01) (3, -5.07699429988861083984e-01) (4, 1.44962877035140991211e-01) (5, 3.10541570186614990234e-01) (6, -1.85597315430641174316e-01) (7, -7.13859856128692626953e-01) (8, -2.30640363693237304688e+00) (9, 5.68785309791564941406e-01) (0, -2.89720624685287475586e-01) (1, -5.00927567481994628906e-01) (2, 1.90103018283843994141e+00) (3, -5.18766355514526367188e+00) (4, 7.67782151699066162109e-01) (5, 1.89556336402893066406e+00) (6, -8.57507407665252685547e-01) (7, -1.94191789627075195312e+00) (8, 2.68106412887573242188e+00) (9, -1.01117514073848724365e-01) (0, -2.47524595260620117188e+00) (1, 2.44107380509376525879e-01) (2, -5.78730583190917968750e-01) (3, -3.54583114385604858398e-01) (4, -1.25332856178283691406e+00) (5, 5.20083963871002197266e-01) (6, -3.95635008811950683594e-01) (7, -1.56905984878540039062e+00) (8, -7.02685713768005371094e-01) (9, 1.36656701564788818359e-01) (0, -2.66786199063062667847e-03) (1, -8.08958783745765686035e-02) (2, 3.88246387243270874023e-01) (3, -1.20118939876556396484e+00) (4, 8.58071446418762207031e-01) (5, 9.83583688735961914062e-01) (6, -5.69833852350711822510e-02) (7, -2.81138110160827636719e+00) (8, -4.82433646917343139648e-01) (9, 7.32016623020172119141e-01) (0, -2.38409221172332763672e-01) (1, 4.39237308502197265625e+00) (2, 1.60241210460662841797e+00) (3, -9.56620723009109497070e-02) (4, -1.85417723655700683594e+00) (5, -2.99908936023712158203e-01) (6, 1.04001307487487792969e+00) (7, -4.90401744842529296875e+00) (8, -2.84554386138916015625e+01) (9, 1.90737657248973846436e-02) (0, -2.41412594914436340332e-01) (1, -8.24117422103881835938e-01) (2, -5.15155568718910217285e-02) (3, -1.20048403739929199219e+00) (4, 9.94767010211944580078e-01) (5, 8.30024063587188720703e-01) (6, -1.39827296137809753418e-01) (7, -1.80199468135833740234e+00) (8, -4.71455216407775878906e-01) (9, 7.43460536003112792969e-01) (0, -2.47986808419227600098e-01) (1, 8.46486210823059082031e-01) (2, -2.74557590484619140625e-01) (3, -5.44354259967803955078e-01) (4, 9.96452644467353820801e-02) (5, -4.73475717008113861084e-02) (6, -6.61797076463699340820e-02) (7, -1.02254235744476318359e+00) (8, -2.40479350090026855469e+00) (9, 4.66204792261123657227e-01) (0, 1.18689060211181640625e+00) (1, 3.77708363533020019531e+00) (2, 1.13949453830718994141e+00) (3, 1.78983955383300781250e+01) (4, -1.06485099792480468750e+01) (5, 6.60367131233215332031e-01) (6, 1.50999426841735839844e+00) (7, 3.52241158485412597656e+00) (8, -8.11591434478759765625e+00) (9, 1.85444295406341552734e+00) (10, -3.25041985511779785156e+00) (11, -3.29151034355163574219e+00) (12, 2.30833358764648437500e+01) (13, -2.60816335678100585938e+00) (14, -4.05371713638305664062e+00) (15, -2.14444923400878906250e+00) (16, -3.27109932899475097656e+00) (17, 1.56871914863586425781e+00) (18, 2.46276170015335083008e-01) (10, 1.65377938747406005859e+00) (11, -3.42849779129028320312e+00) (12, -2.26180286407470703125e+01) (13, 2.60216093063354492188e+00) (14, -6.11884212493896484375e+00) (15, -1.92714020609855651855e-01) (16, 2.52131938934326171875e+00) (17, -6.51707887649536132812e-01) (18, 1.36351072788238525391e+00) (10, -4.28661680221557617188e+00) (11, -1.85138189792633056641e+00) (12, -1.20362176895141601562e+01) (13, -3.24240016937255859375e+00) (14, -1.74370932579040527344e+00) (15, -2.75644850730895996094e+00) (16, -4.18492507934570312500e+00) (17, 1.42741215229034423828e+00) (18, 1.56792950630187988281e+00) (10, 6.89822494983673095703e-01) (11, 1.76777133941650390625e+01) (12, -7.03325271606445312500e+01) (13, 1.93540883064270019531e+00) (14, 1.49120540618896484375e+01) (15, 1.52853918075561523438e+00) (16, 9.26640272140502929688e-01) (17, -2.53569036722183227539e-01) (18, -5.60566425323486328125e-01) (19, -4.06921100616455078125e+00) (20, 1.24402582645416259766e+00) (21, -1.88418750762939453125e+01) (22, 1.03617739677429199219e+00) (23, 5.54586648941040039062e-02) 
