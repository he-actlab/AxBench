FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.08654260635375976562e+00) (1, -1.71803563833236694336e-01) (2, -3.02697706222534179688e+00) (3, 3.28629064559936523438e+00) (4, -1.85005736351013183594e+00) (5, -2.58840537071228027344e+00) (6, 8.26991617679595947266e-01) (7, 3.49722552299499511719e+00) (8, -4.69911873340606689453e-01) (9, -1.23645715415477752686e-01) (0, 7.93248936533927917480e-02) (1, 2.36944627761840820312e+00) (2, -2.11463384330272674561e-02) (3, -5.03265261650085449219e-01) (4, 8.63493084907531738281e-01) (5, 3.90706919133663177490e-02) (6, 3.32002520561218261719e-01) (7, -2.02110362052917480469e+00) (8, -3.36708092689514160156e+00) (9, 3.28872859477996826172e-01) (0, -4.45415824651718139648e-01) (1, -7.89754152297973632812e+00) (2, 2.46342110633850097656e+00) (3, -2.58047127723693847656e+00) (4, 3.07120352983474731445e-01) (5, -5.46256840229034423828e-01) (6, -2.67751693725585937500e-01) (7, -2.95975518226623535156e+00) (8, -9.53539490699768066406e-01) (9, 4.29254800081253051758e-01) (0, -3.03990840911865234375e-01) (1, -2.30492621660232543945e-01) (2, -2.17427119612693786621e-01) (3, -6.24709665775299072266e-01) (4, 1.26234292984008789062e+00) (5, -1.15351557731628417969e+00) (6, -1.25361129641532897949e-01) (7, -2.18994355201721191406e+00) (8, -5.82791924476623535156e-01) (9, 7.69383251667022705078e-01) (0, 2.61772131919860839844e+00) (1, 2.48065531253814697266e-01) (2, -2.09966108202934265137e-01) (3, 2.10604166984558105469e+00) (4, -4.68501424789428710938e+00) (5, -2.10207486152648925781e+00) (6, 8.55008542537689208984e-01) (7, 2.28187656402587890625e+00) (8, -2.83262014389038085938e-01) (9, 9.05135035514831542969e-01) (0, -8.90356957912445068359e-01) (1, 1.50872647762298583984e+00) (2, -5.77901601791381835938e-01) (3, -1.26199889183044433594e+00) (4, 8.86025071144104003906e-01) (5, -4.10473853349685668945e-01) (6, -8.17286789417266845703e-01) (7, -3.18281412124633789062e+00) (8, -7.32196867465972900391e-01) (9, 2.54281187057495117188e+00) (0, -3.81744354963302612305e-01) (1, -3.47289562225341796875e+00) (2, -1.60719585418701171875e+00) (3, -3.76451969146728515625e-01) (4, -8.89199018478393554688e-01) (5, -7.00238168239593505859e-01) (6, 2.11779212951660156250e+00) (7, -2.77619647979736328125e+00) (8, 3.75963337719440460205e-02) (9, 1.23698413372039794922e+00) (0, 8.42294991016387939453e-01) (1, 3.93638670444488525391e-01) (2, 5.56151151657104492188e-01) (3, -5.23868846893310546875e+00) (4, 4.02245426177978515625e+00) (5, -8.32909882068634033203e-01) (6, 3.41395586729049682617e-02) (7, -5.48988044261932373047e-01) (8, -8.29336106777191162109e-01) (9, 4.67255651950836181641e-01) (10, -1.95495581626892089844e+00) (11, -4.88024377822875976562e+00) (12, -1.70260155200958251953e+00) (13, -1.55398774147033691406e+00) (14, 7.06942021846771240234e-01) (15, -6.76301121711730957031e-01) (16, 2.50872936248779296875e+01) (17, -8.00059795379638671875e+00) (18, 4.95561182498931884766e-01) (10, -1.51240038871765136719e+00) (11, 2.41452026367187500000e+00) (12, 2.38110017776489257812e+00) (13, 3.62746286392211914062e+00) (14, -1.55704545974731445312e+00) (15, 3.59065914154052734375e+00) (16, 3.62563776969909667969e+00) (17, 3.12381315231323242188e+00) (18, -2.97696560621261596680e-01) (10, 2.34628820419311523438e+00) (11, -4.62007093429565429688e+00) (12, -2.47855377197265625000e+00) (13, -3.50976991653442382812e+00) (14, 1.42638659477233886719e+00) (15, -2.03528833389282226562e+00) (16, -1.25161371231079101562e+01) (17, -2.22132372856140136719e+00) (18, 5.73732316493988037109e-01) (10, -9.47953701019287109375e-01) (11, 1.02997684478759765625e+00) (12, 3.01661157608032226562e+00) (13, 3.99289441108703613281e+00) (14, -1.15662193298339843750e+00) (15, 3.59006953239440917969e+00) (16, 3.47569894790649414062e+00) (17, 4.17061853408813476562e+00) (18, -5.86532890796661376953e-01) (19, -2.81053876876831054688e+00) (20, 5.98896443843841552734e-01) (21, -1.50906810760498046875e+01) (22, 5.43148100376129150391e-01) (23, -4.10548336803913116455e-02) 
