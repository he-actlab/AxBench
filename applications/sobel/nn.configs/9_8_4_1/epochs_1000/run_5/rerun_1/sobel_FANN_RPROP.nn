FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.41108453273773193359e+00) (1, 4.66766023635864257812e+00) (2, 8.33696007728576660156e-01) (3, -1.52854967117309570312e+00) (4, 1.80269360542297363281e+00) (5, -4.48260593414306640625e+00) (6, 1.50000000000000000000e+03) (7, -3.32822561264038085938e-01) (8, 6.04924082756042480469e-01) (9, 2.39724993705749511719e+00) (0, 6.65260851383209228516e-01) (1, 9.29887580871582031250e+00) (2, -5.87605476379394531250e+00) (3, 5.94242930412292480469e-01) (4, 6.34083569049835205078e-01) (5, 4.54670898616313934326e-02) (6, 5.11955797672271728516e-01) (7, 2.52698945999145507812e+00) (8, 9.13333415985107421875e+00) (9, -5.39429283142089843750e+00) (0, 5.79872608184814453125e-01) (1, 4.95876407623291015625e+00) (2, 1.59571528434753417969e+00) (3, 2.09683895111083984375e+00) (4, 1.81084036827087402344e+00) (5, 6.64749860763549804688e+00) (6, -1.49961030483245849609e+00) (7, 1.92252445220947265625e+00) (8, -1.92699260711669921875e+01) (9, -1.13018095493316650391e+00) (0, -1.58427848815917968750e+01) (1, 7.29629850387573242188e+00) (2, 3.28612899780273437500e+00) (3, -2.29699039459228515625e+00) (4, 1.81464588642120361328e+00) (5, 8.82865965366363525391e-01) (6, -5.25227403640747070312e+00) (7, 7.52319037914276123047e-01) (8, 6.16074228286743164062e+00) (9, -6.79026186466217041016e-01) (0, 1.49203523993492126465e-01) (1, 5.70528888702392578125e+00) (2, -1.11413860321044921875e+00) (3, 1.36736059188842773438e+00) (4, 1.15931653976440429688e+00) (5, -1.91117376089096069336e-01) (6, -2.85479784011840820312e+00) (7, 1.47488403320312500000e+00) (8, 1.43005895614624023438e+00) (9, -9.94289219379425048828e-01) (0, 8.86450052261352539062e-01) (1, -2.71529459953308105469e+00) (2, 5.33140301704406738281e-01) (3, 1.70549571514129638672e+00) (4, -2.92562574148178100586e-01) (5, 3.96341204643249511719e-01) (6, 1.49456167221069335938e+00) (7, 1.76375651359558105469e+00) (8, 2.58498477935791015625e+00) (9, -2.68027806282043457031e+00) (0, 7.43947207927703857422e-01) (1, -2.71708607673645019531e+00) (2, 1.57274723052978515625e+00) (3, 1.51095139980316162109e+00) (4, -7.93061614036560058594e-01) (5, 2.32156440615653991699e-01) (6, 1.45261514186859130859e+00) (7, 1.72862207889556884766e+00) (8, 2.95526957511901855469e+00) (9, -2.80286026000976562500e+00) (0, 7.32344090938568115234e-02) (1, 4.79440927505493164062e+00) (2, -2.11894899606704711914e-01) (3, 1.28140830993652343750e+00) (4, 4.81548458337783813477e-01) (5, -7.98012256622314453125e-01) (6, -1.87428474426269531250e+00) (7, 1.97432100772857666016e+00) (8, 4.10521030426025390625e+00) (9, -7.41212546825408935547e-01) (10, -9.68093335628509521484e-01) (11, -9.45718109607696533203e-01) (12, 1.03796291351318359375e+00) (13, -1.41540423035621643066e-01) (14, 4.16807055473327636719e-01) (15, 2.85883402824401855469e+00) (16, 1.15436172485351562500e+00) (17, 3.76696854829788208008e-01) (18, -1.01556086540222167969e+00) (10, -1.20320093631744384766e+00) (11, -1.10240806579589843750e+02) (12, -2.54924821853637695312e+00) (13, -4.53633594512939453125e+00) (14, -7.96632432937622070312e+00) (15, 1.14625984191894531250e+02) (16, 1.07639320373535156250e+02) (17, -3.72334899902343750000e+01) (18, -1.35925543308258056641e+00) (10, -1.03164064884185791016e+00) (11, -1.09850898742675781250e+02) (12, -8.41965484619140625000e+00) (13, -4.08732652664184570312e+00) (14, -8.03030204772949218750e+00) (15, 1.14765762329101562500e+02) (16, 1.07861404418945312500e+02) (17, -3.70854682922363281250e+01) (18, -1.24399447441101074219e+00) (10, 1.17043638229370117188e+00) (11, -4.92996692657470703125e-01) (12, 2.55303478240966796875e+01) (13, 1.08316221237182617188e+01) (14, -6.80609524250030517578e-01) (15, -1.11084642410278320312e+01) (16, -1.72028613090515136719e+00) (17, -5.17729341983795166016e-01) (18, 1.96030306816101074219e+00) (19, -2.24257588386535644531e+00) (20, -1.68367294311523437500e+02) (21, 1.78335525512695312500e+02) (22, 2.10086441040039062500e+00) (23, -2.08571761846542358398e-01) 
