FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.38202990722656250000e+03) (1, -1.38134948730468750000e+02) (2, -1.50000000000000000000e+03) (3, -3.20598936080932617188e+00) (4, -3.77769559621810913086e-01) (5, -8.77502059936523437500e+00) (6, -6.63692260742187500000e+02) (7, -1.65964376926422119141e+00) (8, -2.68565440177917480469e+00) (9, 4.88102287054061889648e-01) (0, 1.95537650585174560547e+00) (1, 1.97433814406394958496e-01) (2, 3.39705276489257812500e+00) (3, -1.05465936660766601562e+00) (4, -3.94390392303466796875e+00) (5, -3.02137553691864013672e-01) (6, -4.51851308345794677734e-01) (7, -6.77910864353179931641e-01) (8, -4.01924943923950195312e+00) (9, 8.52478802204132080078e-01) (0, -5.84074318408966064453e-01) (1, -2.49674618244171142578e-01) (2, -8.11300277709960937500e-01) (3, -2.52366924285888671875e+00) (4, 2.70140945911407470703e-01) (5, 5.33455967903137207031e-01) (6, -4.73158001899719238281e-01) (7, -1.14952303469181060791e-01) (8, -7.97500967979431152344e-01) (9, 9.86686170101165771484e-01) (0, -3.63022416830062866211e-01) (1, -5.54315038025379180908e-02) (2, -2.75704574584960937500e+00) (3, -2.74582624435424804688e+00) (4, 1.56883919239044189453e+00) (5, 1.09767389297485351562e+00) (6, -6.59569203853607177734e-01) (7, -7.11897537112236022949e-02) (8, -8.62529098987579345703e-01) (9, 1.08991408348083496094e+00) (0, 1.83996871113777160645e-01) (1, -1.87968194484710693359e-01) (2, -6.43376410007476806641e-01) (3, -2.17585396766662597656e+00) (4, -5.19824363291263580322e-02) (5, 2.95104891061782836914e-01) (6, 5.48452913761138916016e-01) (7, -1.49383526295423507690e-02) (8, -2.83976316452026367188e-01) (9, -5.77952682971954345703e-01) (0, -2.25831222534179687500e+00) (1, -1.37821471691131591797e+00) (2, -5.38126182556152343750e+00) (3, -1.74996888637542724609e+00) (4, 3.33042949438095092773e-01) (5, 1.27220773696899414062e+00) (6, 1.35567700862884521484e+00) (7, 4.82963979244232177734e-01) (8, 4.16649907827377319336e-01) (9, 5.14217674732208251953e-01) (0, 1.37383401393890380859e-01) (1, 8.36793601512908935547e-01) (2, -1.16256439685821533203e+00) (3, -4.20672464370727539062e+00) (4, 1.02344602346420288086e-01) (5, 1.80872991681098937988e-01) (6, -4.67341452836990356445e-01) (7, 2.65394162852317094803e-04) (8, 4.78392779827117919922e-01) (9, 6.45514786243438720703e-01) (0, 4.90247964859008789062e+00) (1, 2.43731603026390075684e-01) (2, 9.74507868289947509766e-01) (3, -1.87290382385253906250e+00) (4, -3.94523811340332031250e+00) (5, 4.13725256919860839844e-01) (6, -5.42337834835052490234e-01) (7, -9.10167321562767028809e-02) (8, -3.90573477745056152344e+00) (9, 6.03778660297393798828e-01) (10, -8.00000000000000000000e+02) (11, -8.95858383178710937500e+00) (12, -1.19386076927185058594e+00) (13, -2.27686023712158203125e+00) (14, -3.23956251144409179688e-01) (15, -5.11797857284545898438e+00) (16, -6.42423689365386962891e-01) (17, -9.57724988460540771484e-01) (18, 1.91384279727935791016e+00) (10, 1.50000000000000000000e+03) (11, 1.53929543495178222656e+00) (12, 1.13270258903503417969e+00) (13, -1.14896535873413085938e+00) (14, 9.52171206474304199219e-01) (15, 5.36787700653076171875e+00) (16, 3.17292070388793945312e+00) (17, 5.12458038330078125000e+00) (18, -5.41437268257141113281e-01) (10, -8.00000000000000000000e+02) (11, -6.81832218170166015625e+00) (12, -2.19134497642517089844e+00) (13, -2.39366912841796875000e+00) (14, 2.53389894962310791016e-01) (15, -4.93783187866210937500e+00) (16, -3.75927478075027465820e-01) (17, -2.54487204551696777344e+00) (18, 1.96214747428894042969e+00) (10, 1.50000000000000000000e+03) (11, 6.96733057498931884766e-01) (12, 1.08649742603302001953e+00) (13, -6.05109405517578125000e+00) (14, 1.01260316371917724609e+00) (15, 7.99635362625122070312e+00) (16, 7.94003868103027343750e+00) (17, 6.10678005218505859375e+00) (18, -7.24224627017974853516e-01) (19, -3.20511555671691894531e+00) (20, 4.92670506238937377930e-01) (21, -3.45629882812500000000e+00) (22, 4.80763107538223266602e-01) (23, -1.58773157745599746704e-02) 
