FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 2.46348786354064941406e+00) (1, 6.83086013793945312500e+00) (2, 7.44004726409912109375e-01) (3, 7.83942043781280517578e-01) (4, 3.54953408241271972656e-01) (5, -3.29626107215881347656e+00) (6, 1.56368687748908996582e-01) (7, 4.45190429687500000000e-01) (8, 5.15815258026123046875e-01) (9, -5.21411418914794921875e-01) (0, 5.31485509872436523438e+00) (1, -1.99356377124786376953e+00) (2, 5.28244495391845703125e-01) (3, 5.94840574264526367188e+00) (4, 6.88612401485443115234e-01) (5, -2.35318040847778320312e+00) (6, -5.72797870635986328125e+00) (7, 1.29349529743194580078e-01) (8, 2.09346580505371093750e+00) (9, -1.28703641891479492188e+00) (0, 3.31406855583190917969e+00) (1, 1.10548896789550781250e+01) (2, 1.63763415813446044922e+00) (3, 1.67349457740783691406e+00) (4, 2.47541591525077819824e-01) (5, -5.76540994644165039062e+00) (6, 1.21186995506286621094e+00) (7, -1.99527237564325332642e-02) (8, 1.35872125625610351562e+00) (9, -1.45920443534851074219e+00) (0, -5.17703235149383544922e-01) (1, -2.32348874211311340332e-01) (2, 6.89121723175048828125e-01) (3, -1.81424665451049804688e+00) (4, -1.84021437168121337891e+00) (5, 5.00469624996185302734e-01) (6, -3.94801050424575805664e-01) (7, -3.04038017988204956055e-01) (8, -3.04056596755981445312e+00) (9, 1.62789809703826904297e+00) (0, 4.31208282709121704102e-01) (1, -1.20384144783020019531e+00) (2, 3.00213742256164550781e+00) (3, -5.67689677700400352478e-03) (4, 1.47669959068298339844e+00) (5, -2.94357657432556152344e+00) (6, 1.55223906040191650391e-01) (7, -1.13343954086303710938e+00) (8, 1.86013579368591308594e-01) (9, -2.19534695148468017578e-01) (0, -9.25284326076507568359e-01) (1, -2.48106941580772399902e-01) (2, 1.45932972431182861328e+00) (3, -7.12264716625213623047e-01) (4, -2.46787261962890625000e+00) (5, 8.65434557199478149414e-02) (6, -3.82743626832962036133e-01) (7, -2.06239491701126098633e-01) (8, -3.09239816665649414062e+00) (9, 1.49781882762908935547e+00) (0, -1.35933732986450195312e+00) (1, -5.60669994354248046875e+00) (2, -4.04825806617736816406e-01) (3, -3.73256146907806396484e-01) (4, -3.27353954315185546875e-01) (5, 1.97138893604278564453e+00) (6, -3.99310410022735595703e-01) (7, -4.11812514066696166992e-01) (8, -4.95569616556167602539e-01) (9, -3.29259783029556274414e-01) (0, -5.67242503166198730469e-01) (1, -2.99021393060684204102e-01) (2, 1.44739806652069091797e+00) (3, -9.61594343185424804688e-01) (4, -2.03911232948303222656e+00) (5, -1.66679501533508300781e-01) (6, -6.25835597515106201172e-01) (7, -8.72968435287475585938e-01) (8, -3.31279540061950683594e+00) (9, 1.82662701606750488281e+00) (10, -7.38021194934844970703e-01) (11, -8.34254741668701171875e-01) (12, -3.39523482322692871094e+00) (13, 4.54599285125732421875e+00) (14, 6.60511434078216552734e-01) (15, 4.61147594451904296875e+00) (16, 1.65451955795288085938e+00) (17, 1.78949699401855468750e+01) (18, -1.23778387904167175293e-01) (10, 1.86653628945350646973e-01) (11, -7.81916856765747070312e-01) (12, 3.91760557889938354492e-01) (13, 8.27112197875976562500e+00) (14, -2.87706613540649414062e+00) (15, 2.20222425460815429688e+00) (16, -4.59525346755981445312e-01) (17, 2.40804624557495117188e+00) (18, -6.22730493545532226562e-01) (10, -8.65444302558898925781e-01) (11, -8.58643889427185058594e-01) (12, -3.62674927711486816406e+00) (13, 5.42734146118164062500e+00) (14, 4.28803086280822753906e-01) (15, 3.28684425354003906250e+00) (16, 1.17813503742218017578e+00) (17, 2.08537445068359375000e+01) (18, -1.39148741960525512695e-01) (10, -7.03173458576202392578e-01) (11, -5.73593282699584960938e+00) (12, -1.56283938884735107422e+00) (13, 2.05888252258300781250e+01) (14, -1.73673403263092041016e+00) (15, 2.84206533432006835938e+00) (16, 1.23733878135681152344e+00) (17, 2.55800080299377441406e+00) (18, -3.68493586778640747070e-01) (19, 1.52526640892028808594e+00) (20, -6.81275486946105957031e-01) (21, 1.60881888866424560547e+00) (22, -1.82759031653404235840e-01) (23, -1.40976548194885253906e+00) 
