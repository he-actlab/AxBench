FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 7.21823811531066894531e-01) (1, 8.22237014770507812500e-01) (2, -6.39425873756408691406e-01) (3, 2.69962757825851440430e-01) (4, 3.06963920593261718750e+00) (5, -1.64103627204895019531e-01) (6, -2.54270076751708984375e-01) (7, 7.24500417709350585938e-01) (8, 2.17132043838500976562e+00) (9, -2.78880047798156738281e+00) (0, -8.18486869335174560547e-01) (1, 2.80087918043136596680e-01) (2, 8.17787289619445800781e-01) (3, -7.79497981071472167969e-01) (4, -1.54644918441772460938e+00) (5, 1.88047051429748535156e+00) (6, -3.97418856620788574219e-01) (7, -6.98804706335067749023e-02) (8, -2.95966076850891113281e+00) (9, 9.55631434917449951172e-01) (0, -5.70134878158569335938e-01) (1, 2.06535264849662780762e-01) (2, 1.44364750385284423828e+00) (3, -6.37813866138458251953e-01) (4, -2.49699425697326660156e+00) (5, 1.80713367462158203125e+00) (6, -5.01128017902374267578e-01) (7, 2.23019227385520935059e-01) (8, -2.44639396667480468750e+00) (9, 6.74800932407379150391e-01) (0, -7.22082078456878662109e-01) (1, 1.84019282460212707520e-01) (2, -4.60653603076934814453e-01) (3, -6.53379499912261962891e-01) (4, -1.14126384258270263672e+00) (5, 1.76480126380920410156e+00) (6, -4.23713028430938720703e-01) (7, 1.45469531416893005371e-01) (8, -2.43876457214355468750e+00) (9, 7.43553280830383300781e-01) (0, 9.37253534793853759766e-01) (1, 4.78607237339019775391e-01) (2, -1.21161472797393798828e+00) (3, 1.06372606754302978516e+00) (4, 1.47444713115692138672e+00) (5, -1.08226048946380615234e+00) (6, 7.38384664058685302734e-01) (7, 5.76557591557502746582e-02) (8, 1.62983584403991699219e+00) (9, -1.00881516933441162109e+00) (0, -1.15359258651733398438e+00) (1, -6.45755052566528320312e-01) (2, -7.27940261363983154297e-01) (3, -3.32572042942047119141e-01) (4, -6.09521687030792236328e-01) (5, 1.23517072200775146484e+00) (6, -4.00843888521194458008e-01) (7, -9.47011411190032958984e-02) (8, -2.96544528007507324219e+00) (9, 1.78381896018981933594e+00) (0, 8.07822465896606445312e-01) (1, 1.09846675395965576172e+00) (2, 6.95812523365020751953e-01) (3, -1.38873159885406494141e+00) (4, 3.77652692794799804688e+00) (5, -6.72917068004608154297e-01) (6, 3.92074882984161376953e-01) (7, 6.68414592742919921875e-01) (8, 2.21147131919860839844e+00) (9, -2.66315484046936035156e+00) (0, 9.11284983158111572266e-01) (1, 4.40327912569046020508e-01) (2, 2.55330413579940795898e-01) (3, 3.16000849008560180664e-01) (4, 2.32740712165832519531e+00) (5, -1.34548389911651611328e+00) (6, -1.56894111633300781250e+00) (7, 2.01996326446533203125e-01) (8, 1.04008996486663818359e+00) (9, -9.87690091133117675781e-01) (10, -1.05969896316528320312e+01) (11, 7.47924566268920898438e+00) (12, 5.03487873077392578125e+00) (13, 3.92641496658325195312e+00) (14, -1.67021644115447998047e+00) (15, 2.03462295532226562500e+01) (16, -5.23872232437133789062e+00) (17, -3.56979042291641235352e-01) (18, -9.47719514369964599609e-02) (10, -9.91247081756591796875e+00) (11, 4.40710401535034179688e+00) (12, 3.95563793182373046875e+00) (13, 3.37652516365051269531e+00) (14, -9.15171146392822265625e-01) (15, 1.67118930816650390625e+01) (16, -2.72345972061157226562e+00) (17, -6.59022390842437744141e-01) (18, -8.54166820645332336426e-02) (10, -8.42699527740478515625e+00) (11, 4.36285352706909179688e+00) (12, 5.99011135101318359375e+00) (13, 3.55756735801696777344e+00) (14, -8.63809168338775634766e-01) (15, 1.49989356994628906250e+01) (16, -4.53284120559692382812e+00) (17, -6.92038416862487792969e-01) (18, -2.38484889268875122070e-02) (10, 2.15390796661376953125e+01) (11, 3.03666567802429199219e+00) (12, -1.82626590728759765625e+01) (13, 1.81850302219390869141e+00) (14, 8.97690391540527343750e+00) (15, -4.80961761474609375000e+01) (16, 5.65061378479003906250e+00) (17, 5.05479526519775390625e+00) (18, 6.54654145240783691406e-01) (19, 1.15249752998352050781e+00) (20, 5.93654096126556396484e-01) (21, 6.77398324012756347656e-01) (22, 3.63609313964843750000e-01) (23, -1.55459976196289062500e+00) 
