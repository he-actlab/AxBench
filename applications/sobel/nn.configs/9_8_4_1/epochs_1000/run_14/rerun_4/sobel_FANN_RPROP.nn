FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.29875839233398437500e+02) (1, -1.34439563751220703125e+01) (2, -1.48980920410156250000e+03) (3, -6.24212360382080078125e+00) (4, 1.08560310363769531250e+02) (5, -1.44724584960937500000e+03) (6, 1.50793121337890625000e+02) (7, 5.59184532165527343750e+01) (8, -1.37537475585937500000e+03) (9, 7.47164249420166015625e-01) (0, 1.79471051692962646484e+00) (1, 1.94193935394287109375e+00) (2, 1.70691764354705810547e+00) (3, 1.09727931022644042969e+00) (4, -2.21493631601333618164e-01) (5, -4.59605503082275390625e+00) (6, -2.73572611808776855469e+00) (7, -7.77089178562164306641e-01) (8, -3.42295622825622558594e+00) (9, 4.62290108203887939453e-01) (0, 1.64627015590667724609e+00) (1, 8.40095615386962890625e+00) (2, 2.59501218795776367188e+00) (3, 1.19867229461669921875e+00) (4, -4.25348803400993347168e-02) (5, -3.36739826202392578125e+00) (6, -1.20199613571166992188e+01) (7, -1.15616595745086669922e+00) (8, -2.02391767501831054688e+00) (9, 5.95433294773101806641e-01) (0, 4.05673408508300781250e+00) (1, 1.06722092628479003906e+00) (2, 8.50231075286865234375e+00) (3, 6.73121631145477294922e-01) (4, -4.88330870866775512695e-01) (5, -1.02158269882202148438e+01) (6, -3.94142889976501464844e+00) (7, -6.63042739033699035645e-02) (8, -7.82958650588989257812e+00) (9, 1.07867312431335449219e+00) (0, 2.92049884796142578125e+00) (1, 4.05245494842529296875e+00) (2, 1.44915437698364257812e+00) (3, 8.81569266319274902344e-01) (4, -9.34903562068939208984e-01) (5, -5.33400392532348632812e+00) (6, -1.93847095966339111328e+00) (7, -3.33468747138977050781e+00) (8, -3.03110504150390625000e+00) (9, 5.79213976860046386719e-01) (0, 4.94992160797119140625e+00) (1, 4.10214042663574218750e+00) (2, 4.81461793184280395508e-01) (3, 4.38343286514282226562e-01) (4, -9.72560226917266845703e-01) (5, -5.91904401779174804688e+00) (6, -3.41675257682800292969e+00) (7, -1.19077777862548828125e+00) (8, -3.55340480804443359375e+00) (9, 9.33877527713775634766e-02) (0, -8.43377685546875000000e+01) (1, 9.17000353336334228516e-01) (2, -5.59732131958007812500e+01) (3, -3.72357703745365142822e-02) (4, 1.78276801109313964844e+00) (5, 4.07154142856597900391e-01) (6, -6.14640464782714843750e+01) (7, 9.72802281379699707031e-01) (8, 1.12044563293457031250e+02) (9, 1.15941554307937622070e-01) (0, 1.21582686901092529297e+00) (1, 3.79245996475219726562e+00) (2, 1.67592728137969970703e+00) (3, 5.34884512424468994141e-01) (4, -3.69801491498947143555e-01) (5, -4.12790250778198242188e+00) (6, -3.13555479049682617188e+00) (7, -1.16559803485870361328e+00) (8, -3.46550655364990234375e+00) (9, 6.24297678470611572266e-01) (10, 1.50000000000000000000e+03) (11, 9.23067629337310791016e-01) (12, 4.32639420032501220703e-01) (13, 5.13884603977203369141e-01) (14, 1.16626572608947753906e+00) (15, 3.09811186790466308594e+00) (16, 4.04243326187133789062e+00) (17, 8.76825571060180664062e-01) (18, 2.04028218984603881836e-01) (10, 1.00000000000000000000e+03) (11, -2.08926033973693847656e+00) (12, 8.53545010089874267578e-01) (13, -4.59779143333435058594e-01) (14, -5.65727567672729492188e+00) (15, -2.26351165771484375000e+00) (16, -5.96881723403930664062e+00) (17, -1.41663575172424316406e+00) (18, 1.87327098846435546875e+00) (10, 1.00000000000000000000e+03) (11, -1.13657534122467041016e+00) (12, -1.54701006412506103516e+00) (13, -2.29909396171569824219e+00) (14, -4.32830476760864257812e+00) (15, -7.41006806492805480957e-02) (16, -6.29486036300659179688e+00) (17, -1.13178205490112304688e+00) (18, 2.17728424072265625000e+00) (10, 1.50000000000000000000e+03) (11, 8.88869345188140869141e-01) (12, 1.80582213401794433594e+00) (13, -1.00707006454467773438e+01) (14, 1.75465309619903564453e+00) (15, 7.73046207427978515625e+00) (16, 1.87155270576477050781e+00) (17, 8.82750511169433593750e-01) (18, 1.66528379917144775391e+00) (19, 5.83268284797668457031e-01) (20, -1.19760024547576904297e+00) (21, -2.09898471832275390625e+00) (22, 3.32939118146896362305e-01) (23, -3.76765243709087371826e-03) 
