FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 9.42385971546173095703e-01) (1, 5.03829383850097656250e+00) (2, 1.67329502105712890625e+00) (3, -3.31740826368331909180e-01) (4, -1.04611647129058837891e+00) (5, -1.07129907608032226562e+00) (6, -8.52577495574951171875e+00) (7, 1.53858557343482971191e-01) (8, -2.11491632461547851562e+00) (9, 6.14528834819793701172e-01) (0, -1.40093650817871093750e+01) (1, 1.11440348625183105469e+00) (2, -1.79919338226318359375e+01) (3, 2.92241311073303222656e+00) (4, -1.40434718132019042969e+00) (5, 1.16143264770507812500e+01) (6, -8.81278574466705322266e-01) (7, 3.80049645900726318359e-01) (8, 3.95318150520324707031e+00) (9, 2.55003905296325683594e+00) (0, 6.49047017097473144531e-01) (1, 4.82086277008056640625e+00) (2, -3.77578765153884887695e-01) (3, -4.87137168645858764648e-01) (4, -2.52725899219512939453e-01) (5, -7.66197681427001953125e-01) (6, -4.87200880050659179688e+00) (7, -7.02237784862518310547e-02) (8, -1.44827044010162353516e+00) (9, 4.33055669069290161133e-01) (0, 2.14670568704605102539e-01) (1, 1.20544981956481933594e+00) (2, -3.19726371765136718750e+00) (3, 1.32722035050392150879e-01) (4, -2.07058429718017578125e+00) (5, 1.25701379776000976562e+00) (6, -5.04592537879943847656e-01) (7, -4.27858904004096984863e-02) (8, 2.87105417251586914062e+00) (9, -2.73594945669174194336e-01) (0, 3.10531091690063476562e+00) (1, 5.72622394561767578125e+00) (2, 1.35747039318084716797e+00) (3, -1.21662668883800506592e-01) (4, -5.50287532806396484375e+00) (5, -9.41121578216552734375e-01) (6, -7.31368494033813476562e+00) (7, -1.38720378279685974121e-01) (8, -1.89514350891113281250e+00) (9, 6.37011706829071044922e-01) (0, 4.05662250518798828125e+00) (1, -2.98717349767684936523e-01) (2, -6.92584152221679687500e+01) (3, 1.13942396640777587891e+00) (4, 1.16706025600433349609e+00) (5, 4.61377322673797607422e-01) (6, -1.09498918056488037109e+00) (7, 1.02944552898406982422e+00) (8, 1.47881424427032470703e+00) (9, -3.87922793626785278320e-01) (0, 1.72619552612304687500e+01) (1, 8.17285358905792236328e-01) (2, 3.23023986816406250000e+01) (3, 4.08253073692321777344e-01) (4, 4.26234006881713867188e+00) (5, -5.60371994972229003906e-01) (6, 1.75745356082916259766e+00) (7, -3.34314680099487304688e+00) (8, -2.86184024810791015625e+00) (9, 1.40091490745544433594e+00) (0, -3.52246046066284179688e+00) (1, -5.57776808738708496094e-01) (2, -3.86914939880371093750e+01) (3, 4.22951161861419677734e-01) (4, -2.98998747020959854126e-02) (5, 5.71451425552368164062e-01) (6, 1.03258800506591796875e+00) (7, 8.53844285011291503906e-01) (8, 2.47326493263244628906e+00) (9, -2.54591315984725952148e-01) (10, -3.21948623657226562500e+00) (11, -1.98397170752286911011e-02) (12, -2.45990395545959472656e+00) (13, -3.16840291023254394531e-01) (14, -4.57371807098388671875e+00) (15, -3.20477771759033203125e+00) (16, 1.13846635818481445312e+00) (17, -1.02086439132690429688e+01) (18, 1.11236238479614257812e+00) (10, -3.09734678268432617188e+00) (11, 3.91140818595886230469e-01) (12, -2.39233207702636718750e+00) (13, -4.40371543169021606445e-01) (14, -4.17974853515625000000e+00) (15, -2.52586460113525390625e+00) (16, 1.08794081211090087891e+00) (17, -1.00396795272827148438e+01) (18, 1.14520323276519775391e+00) (10, -3.50466990470886230469e+00) (11, 1.91133630275726318359e+00) (12, 9.58900094032287597656e-01) (13, 3.44541645050048828125e+00) (14, 1.94305109977722167969e+00) (15, 1.54341086745262145996e-01) (16, 1.64536222815513610840e-01) (17, -4.50612068176269531250e+00) (18, 2.88992404937744140625e-01) (10, -3.71449446678161621094e+00) (11, 5.72856378555297851562e+00) (12, 8.85853707790374755859e-01) (13, 3.53093409538269042969e+00) (14, 1.40895009040832519531e+00) (15, -2.27326965332031250000e+00) (16, 2.61352479457855224609e-01) (17, 2.03323402404785156250e+01) (18, 5.71238815784454345703e-01) (19, -1.95785391330718994141e+00) (20, -1.92538249492645263672e+00) (21, 3.91469717025756835938e-01) (22, 2.74295955896377563477e-01) (23, 3.43117564916610717773e-01) 
