FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 4.94457864761352539062e+00) (1, 2.37319231033325195312e-01) (2, 1.46477830410003662109e+00) (3, -1.48066222667694091797e-01) (4, 1.93922929465770721436e-02) (5, 5.82111001014709472656e-01) (6, 6.34967660903930664062e+00) (7, -4.58081054687500000000e+00) (8, -1.31564068794250488281e+00) (9, -1.96770027279853820801e-01) (0, -1.86683058738708496094e+00) (1, 4.52725112438201904297e-01) (2, -1.36690270900726318359e+00) (3, -1.75906147342175245285e-03) (4, 4.41709578037261962891e-01) (5, -1.27620136737823486328e+00) (6, -1.00273513793945312500e+00) (7, 1.33523070812225341797e+00) (8, -2.04638314247131347656e+00) (9, 1.18965554237365722656e+00) (0, -3.12177729606628417969e+00) (1, -4.45505523681640625000e+00) (2, -1.49650692939758300781e+00) (3, 1.53691005706787109375e+00) (4, -3.23520004749298095703e-01) (5, 1.45038485527038574219e-01) (6, 1.40337443351745605469e+00) (7, 4.87284779548645019531e-01) (8, 5.48916578292846679688e-01) (9, 4.15466874837875366211e-01) (0, -2.87976354360580444336e-01) (1, 7.70206511020660400391e-01) (2, -1.46654224395751953125e+00) (3, -7.61290565133094787598e-02) (4, 9.22686830163002014160e-02) (5, -1.18115627765655517578e+00) (6, -1.05796849727630615234e+00) (7, -4.29386556148529052734e-01) (8, -1.49985873699188232422e+00) (9, 1.01339972019195556641e+00) (0, 3.08893918991088867188e-01) (1, 5.96210420131683349609e-01) (2, -1.43377923965454101562e+00) (3, 5.31009174883365631104e-02) (4, -4.06679958105087280273e-01) (5, -1.19520199298858642578e+00) (6, -1.06550610065460205078e+00) (7, -3.24882030487060546875e-01) (8, -1.60051107406616210938e+00) (9, 2.86112993955612182617e-01) (0, -4.77672042846679687500e+01) (1, -3.67120146751403808594e+00) (2, -1.55716419219970703125e+00) (3, -5.81235706806182861328e-01) (4, -7.04690739512443542480e-02) (5, 1.44055271148681640625e+00) (6, 1.40234637260437011719e+00) (7, 2.47225046157836914062e+00) (8, 5.16888022422790527344e-01) (9, -2.23262095451354980469e+00) (0, -5.38833811879158020020e-02) (1, 5.29231250286102294922e-01) (2, -1.39590716361999511719e+00) (3, 2.95479632914066314697e-02) (4, -3.48501354455947875977e-01) (5, -1.21206581592559814453e+00) (6, -9.45859432220458984375e-01) (7, -3.29980403184890747070e-01) (8, -1.64612269401550292969e+00) (9, 4.37320232391357421875e-01) (0, -1.34924426674842834473e-01) (1, 7.41887271404266357422e-01) (2, -1.52514827251434326172e+00) (3, -6.10455013811588287354e-02) (4, 3.17811891436576843262e-02) (5, -1.16965794563293457031e+00) (6, -1.17438983917236328125e+00) (7, -4.29335385560989379883e-01) (8, -1.50247502326965332031e+00) (9, 9.67184722423553466797e-01) (10, 2.34905886650085449219e+00) (11, -3.26318454742431640625e+00) (12, -2.85335302352905273438e+00) (13, -5.17602682113647460938e+00) (14, -4.80815219879150390625e+00) (15, -2.11793613433837890625e+00) (16, -9.29053688049316406250e+00) (17, -4.66564798355102539062e+00) (18, 6.08712732791900634766e-01) (10, 2.41612219810485839844e+00) (11, -4.20133495330810546875e+00) (12, -3.01168203353881835938e+00) (13, -5.06715393066406250000e+00) (14, -4.59404945373535156250e+00) (15, -2.11793613433837890625e+00) (16, -7.94447517395019531250e+00) (17, -4.70137596130371093750e+00) (18, 8.05064916610717773438e-01) (10, 8.73168110847473144531e-01) (11, 1.35201621055603027344e+00) (12, -2.11599559783935546875e+01) (13, 2.93637824058532714844e+00) (14, 1.62772452831268310547e+00) (15, 7.36177673339843750000e+02) (16, 1.22259199619293212891e+00) (17, 2.91553473472595214844e+00) (18, 8.93585920333862304688e-01) (10, 8.71643662452697753906e-01) (11, -9.71214485168457031250e+00) (12, -1.69148635864257812500e+01) (13, -8.28394055366516113281e-01) (14, -2.58049631118774414062e+00) (15, -8.49812221527099609375e+00) (16, -3.20666980743408203125e+00) (17, -5.90529084205627441406e-01) (18, 2.70526504516601562500e+00) (19, -1.94137442111968994141e+00) (20, -4.14331388473510742188e+00) (21, 2.12445068359375000000e+00) (22, 1.41022419929504394531e+00) (23, -1.24999308586120605469e+00) 
