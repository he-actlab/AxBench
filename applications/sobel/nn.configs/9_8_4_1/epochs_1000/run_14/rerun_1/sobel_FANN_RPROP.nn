FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.18987584114074707031e-01) (1, 2.51459765434265136719e+00) (2, -1.59064972400665283203e+00) (3, -3.17272186279296875000e-01) (4, -2.06387639045715332031e-01) (5, -1.64898276329040527344e+00) (6, -2.46052074432373046875e+00) (7, -5.58263480663299560547e-01) (8, 4.41775947809219360352e-01) (9, 1.02078258991241455078e+00) (0, 2.66037130355834960938e+00) (1, 6.29890203475952148438e-01) (2, 4.76381182670593261719e-02) (3, 3.59630107879638671875e-01) (4, 4.22784119844436645508e-01) (5, -4.17148619890213012695e-01) (6, -7.93490707874298095703e-02) (7, 6.91694140434265136719e-01) (8, -2.40909308195114135742e-03) (9, 2.34489530324935913086e-01) (0, -4.35049486160278320312e+00) (1, -7.82025873661041259766e-01) (2, -1.99951267242431640625e+00) (3, -1.40898096561431884766e+00) (4, -2.51417779922485351562e+00) (5, 2.55918592214584350586e-01) (6, 4.84332926571369171143e-02) (7, 8.66342306137084960938e-01) (8, 2.76301026344299316406e-01) (9, 2.58782267570495605469e+00) (0, -6.62460510253906250000e+02) (1, -4.25785779953002929688e-01) (2, -5.85323333740234375000e-01) (3, -1.22642409801483154297e+00) (4, -6.90466260910034179688e+00) (5, 2.29752802848815917969e+00) (6, 8.47593247890472412109e-02) (7, -5.50836658477783203125e+00) (8, 7.60289716720581054688e+00) (9, 4.79477357864379882812e+00) (0, 3.74123873189091682434e-03) (1, 2.88683199882507324219e+00) (2, -1.04962110519409179688e+00) (3, -4.00108814239501953125e-01) (4, -1.46489918231964111328e-01) (5, -1.47024345397949218750e+00) (6, -2.42111396789550781250e+00) (7, -5.26827931404113769531e-01) (8, -1.44872176647186279297e+00) (9, 9.33623850345611572266e-01) (0, -2.17670230865478515625e+01) (1, -4.14792925119400024414e-01) (2, -4.45929974317550659180e-01) (3, -2.64719438552856445312e+00) (4, 4.71223068237304687500e+00) (5, 4.19643592834472656250e+00) (6, -9.97964367270469665527e-02) (7, 1.57688832283020019531e+00) (8, 2.25969243049621582031e+00) (9, 7.23995938897132873535e-02) (0, 3.53987127542495727539e-01) (1, 7.27140486240386962891e-01) (2, -1.45962464809417724609e+00) (3, -1.68144965171813964844e+00) (4, 7.31054395437240600586e-02) (5, -2.29105305671691894531e+00) (6, -5.38718032836914062500e+00) (7, 2.31421756744384765625e+00) (8, -1.22535681724548339844e+00) (9, 4.40173268318176269531e-01) (0, 1.07883620262145996094e+00) (1, 1.84390294551849365234e+00) (2, 3.67631644010543823242e-01) (3, 1.07975438237190246582e-01) (4, -3.05919479578733444214e-02) (5, -1.58119833469390869141e+00) (6, -1.90657663345336914062e+00) (7, -1.27256929874420166016e+00) (8, -3.08007264137268066406e+00) (9, 3.65190863609313964844e-01) (10, 1.90430283546447753906e+00) (11, 5.05214273929595947266e-01) (12, -1.13118534088134765625e+01) (13, 1.93215408325195312500e+01) (14, 3.96671915054321289062e+00) (15, -6.66927719116210937500e+00) (16, -4.73890113830566406250e+00) (17, 5.88877534866333007812e+00) (18, 6.23143970966339111328e-01) (10, -5.88507366180419921875e+00) (11, 2.92515921592712402344e+00) (12, -1.53056449890136718750e+01) (13, -3.75458717346191406250e+01) (14, -5.75285673141479492188e+00) (15, 3.76264533996582031250e+01) (16, 2.15025215148925781250e+01) (17, -5.41873264312744140625e+00) (18, 9.71165716648101806641e-01) (10, -5.05632734298706054688e+00) (11, 1.01016449928283691406e+00) (12, 7.77097225189208984375e+00) (13, 5.46301066875457763672e-01) (14, -5.21654891967773437500e+00) (15, -1.13475236892700195312e+01) (16, 8.89608478546142578125e+00) (17, -5.78848934173583984375e+00) (18, 1.12410438060760498047e+00) (10, 2.60663652420043945312e+00) (11, 1.21662700176239013672e+00) (12, -1.32753248214721679688e+01) (13, 1.01189498901367187500e+01) (14, 2.17759919166564941406e+00) (15, 2.35638871788978576660e-01) (16, -1.21523036956787109375e+01) (17, 9.75664901733398437500e+00) (18, 1.19386148452758789062e+00) (19, 4.56577062606811523438e-01) (20, -3.01155185699462890625e+00) (21, -2.08934926986694335938e+00) (22, 4.90361273288726806641e-01) (23, 2.34286133199930191040e-02) 
