FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -9.67977881431579589844e-01) (1, -3.36134195327758789062e-01) (2, 2.79009163379669189453e-01) (3, 2.56444275379180908203e-01) (4, -6.68966025114059448242e-02) (5, -2.63186156749725341797e-01) (6, -6.93257451057434082031e-01) (7, 3.38274657726287841797e-01) (8, 7.05684542655944824219e-01) (9, -2.13773399591445922852e-01) (0, 3.61547142267227172852e-01) (1, 9.42661476135253906250e+00) (2, 9.83734190464019775391e-01) (3, -6.11115264892578125000e+00) (4, 2.29082059860229492188e+00) (5, 9.98627948760986328125e+00) (6, -9.63984203338623046875e+00) (7, -4.23864650726318359375e+00) (8, -2.75215595960617065430e-01) (9, 3.61143708229064941406e-01) (0, 1.14032335281372070312e+01) (1, -3.17419099807739257812e+00) (2, 2.10199430584907531738e-02) (3, 2.44195032119750976562e+00) (4, 1.26488029956817626953e-01) (5, -1.16765089333057403564e-01) (6, 7.76947736740112304688e+00) (7, -1.83146819472312927246e-01) (8, -1.22457065582275390625e+01) (9, 2.18386724591255187988e-01) (0, -5.19771203398704528809e-02) (1, 2.18446660041809082031e+00) (2, 1.27229833602905273438e+00) (3, -1.00801343917846679688e+01) (4, 2.24079513549804687500e+00) (5, 1.37724742889404296875e+01) (6, -1.55240697860717773438e+01) (7, -3.07616233825683593750e+00) (8, -3.09427559375762939453e-01) (9, 7.40829050540924072266e-01) (0, -3.34743022918701171875e+00) (1, 3.00811433792114257812e+00) (2, -2.36536369323730468750e+01) (3, 2.88250660896301269531e+00) (4, 1.41515970230102539062e+00) (5, -2.34388160705566406250e+00) (6, 8.98778247833251953125e+00) (7, 2.65800786018371582031e+00) (8, 4.47189033031463623047e-01) (9, -4.19327646493911743164e-01) (0, 1.86096966266632080078e-01) (1, 2.16797661781311035156e+00) (2, 4.63869512081146240234e-01) (3, -5.27047348022460937500e+00) (4, 3.58683609962463378906e+00) (5, 3.87895584106445312500e+00) (6, -2.15202178955078125000e+01) (7, 9.73036670684814453125e+00) (8, 6.15780293941497802734e-01) (9, 1.99941074848175048828e+00) (0, -1.75522193312644958496e-01) (1, 2.64697575569152832031e+00) (2, 5.01992046833038330078e-01) (3, -5.05374670028686523438e+00) (4, 2.91277956962585449219e+00) (5, 1.21334915161132812500e+01) (6, -1.85383968353271484375e+01) (7, -5.02286100387573242188e+00) (8, 9.42307487130165100098e-02) (9, 1.39098691940307617188e+00) (0, -9.88331079483032226562e-01) (1, -6.95829689502716064453e-02) (2, 1.75559729337692260742e-01) (3, -7.08971023559570312500e-01) (4, -2.65332758426666259766e-01) (5, 4.84917648136615753174e-02) (6, -8.09439837932586669922e-01) (7, 6.48471176624298095703e-01) (8, 8.82792547345161437988e-02) (9, 1.03746905922889709473e-01) (10, 9.95155051350593566895e-02) (11, 1.04658806324005126953e+00) (12, 1.78994014859199523926e-02) (13, 9.03391897678375244141e-01) (14, 4.57440137863159179688e+00) (15, -4.04175329208374023438e+00) (16, 1.71373176574707031250e+00) (17, 8.69574323296546936035e-02) (18, 6.46461427211761474609e-01) (10, 1.90441489219665527344e+00) (11, -3.11546969413757324219e+00) (12, 2.82162785530090332031e+00) (13, -3.64820742607116699219e+00) (14, 1.69355046749114990234e+00) (15, 2.79771232604980468750e+00) (16, -3.31059479713439941406e+00) (17, -5.63767385482788085938e+00) (18, 7.76002228260040283203e-01) (10, 1.16819691658020019531e+00) (11, -8.44403803348541259766e-01) (12, 4.16096538305282592773e-01) (13, -9.33066189289093017578e-01) (14, -4.90098905563354492188e+00) (15, 8.80154490470886230469e-01) (16, -1.44927668571472167969e+00) (17, -1.52878001332283020020e-01) (18, 1.08881795406341552734e+00) (10, -6.87219202518463134766e-02) (11, 9.70794439315795898438e-01) (12, 1.49405777454376220703e-01) (13, 9.33013379573822021484e-01) (14, 4.10641336441040039062e+00) (15, -5.13398933410644531250e+00) (16, 1.48859918117523193359e+00) (17, -7.72140771150588989258e-02) (18, 9.62077736854553222656e-01) (19, 1.15086698532104492188e+00) (20, -2.62986016273498535156e+00) (21, -2.34665369987487792969e+00) (22, 2.11602735519409179688e+00) (23, 3.27987641096115112305e-01) 
