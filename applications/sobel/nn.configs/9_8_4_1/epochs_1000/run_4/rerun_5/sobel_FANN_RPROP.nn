FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.00888979434967041016e+00) (1, 3.66256737709045410156e+00) (2, 1.47757625579833984375e+00) (3, -7.50396776199340820312e+00) (4, 1.08245456218719482422e+00) (5, 1.42588376998901367188e+01) (6, -1.56187210083007812500e+01) (7, -9.71854782104492187500e+00) (8, 5.08000659942626953125e+00) (9, 1.70026600360870361328e+00) (0, 8.95879936218261718750e+00) (1, -1.09864444732666015625e+01) (2, -2.13207817077636718750e+01) (3, 2.37139654159545898438e+00) (4, -4.27191877365112304688e+00) (5, -2.37950229644775390625e+00) (6, 1.38972740173339843750e+01) (7, 8.03974628448486328125e-01) (8, 1.66922152042388916016e-01) (9, -8.97245705127716064453e-01) (0, 7.58906424045562744141e-01) (1, 1.10400867462158203125e+00) (2, 3.04218864440917968750e+00) (3, -1.11535558700561523438e+01) (4, 1.13451504707336425781e+00) (5, 1.41750535964965820312e+01) (6, -2.75991439819335937500e+01) (7, -7.78939056396484375000e+00) (8, 3.49282574653625488281e+00) (9, 6.09687231481075286865e-02) (0, 1.29651963710784912109e+00) (1, 1.22771275043487548828e+00) (2, -2.58550815582275390625e+01) (3, 3.65047955513000488281e+00) (4, 3.14990490674972534180e-01) (5, -1.01277375221252441406e+00) (6, 1.14301500320434570312e+01) (7, -1.46781206130981445312e+00) (8, 3.59380626678466796875e+00) (9, 1.09232015907764434814e-01) (0, 9.83283638954162597656e-01) (1, 2.81521606445312500000e+00) (2, 3.60453057289123535156e+00) (3, -7.63865041732788085938e+00) (4, 1.26193988323211669922e+00) (5, 1.31056118011474609375e+01) (6, -1.55299873352050781250e+01) (7, -7.33275365829467773438e+00) (8, 4.67708921432495117188e+00) (9, -3.78162935376167297363e-02) (0, 1.01255035400390625000e+00) (1, 3.67367148399353027344e+00) (2, 1.43060827255249023438e+00) (3, -6.78704833984375000000e+00) (4, 1.48826348781585693359e+00) (5, 1.41324281692504882812e+01) (6, -1.70294361114501953125e+01) (7, -8.23812007904052734375e+00) (8, 4.47926568984985351562e+00) (9, 1.02990877628326416016e+00) (0, 3.06528067588806152344e+00) (1, -2.50025004148483276367e-01) (2, -1.94565429687500000000e+01) (3, -3.03653459995985031128e-02) (4, 1.31802034378051757812e+00) (5, -7.80910372734069824219e-01) (6, -6.54884862899780273438e+00) (7, 1.03944349288940429688e+01) (8, 7.29793119430541992188e+00) (9, 3.64236474037170410156e+00) (0, -1.96717882156372070312e+00) (1, 1.06984663009643554688e+01) (2, 2.03442955017089843750e+00) (3, -5.28408241271972656250e+00) (4, 1.96191406250000000000e+00) (5, 1.13809900283813476562e+01) (6, -1.25816135406494140625e+01) (7, -1.52192716598510742188e+01) (8, 6.06076717376708984375e+00) (9, 1.05475938320159912109e+00) (10, -1.50177168846130371094e+00) (11, -1.74477875232696533203e+00) (12, 7.93652713298797607422e-01) (13, -1.93630428314208984375e+01) (14, -9.55487489700317382812e-01) (15, -1.06989991664886474609e+00) (16, 3.51444572210311889648e-01) (17, -1.49938106536865234375e+00) (18, 5.81583309173583984375e+00) (10, 1.92656183242797851562e+00) (11, 4.25584733486175537109e-01) (12, 3.58702802658081054688e+00) (13, 4.08972740173339843750e+00) (14, 4.62417095899581909180e-01) (15, 7.33133971691131591797e-01) (16, -1.07472772598266601562e+01) (17, 3.73167943954467773438e+00) (18, 4.58543348312377929688e+00) (10, 3.97095370292663574219e+00) (11, 1.57077610492706298828e+00) (12, 1.70376288890838623047e+00) (13, 4.66708326339721679688e+00) (14, 8.63595306873321533203e-01) (15, 8.31776261329650878906e-01) (16, -9.83500289916992187500e+00) (17, 2.63150024414062500000e+00) (18, 4.46984767913818359375e+00) (10, -1.06513404846191406250e+00) (11, -2.21196293830871582031e+00) (12, -5.84326624870300292969e-01) (13, -1.41144943237304687500e+01) (14, -1.04377210140228271484e+00) (15, -1.09353852272033691406e+00) (16, -2.40076228976249694824e-01) (17, -2.83677792549133300781e+00) (18, 5.81397342681884765625e+00) (19, -1.50032067298889160156e+00) (20, 1.62943947315216064453e+00) (21, 1.38469004631042480469e+00) (22, -1.73884415626525878906e+00) (23, -3.60237270593643188477e-01) 
