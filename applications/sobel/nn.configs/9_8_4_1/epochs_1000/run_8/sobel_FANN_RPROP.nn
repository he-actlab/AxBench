FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.52707076072692871094e+00) (1, 1.07691146433353424072e-01) (2, 2.76719957590103149414e-01) (3, -4.67486500740051269531e-01) (4, -5.38253307342529296875e-01) (5, -2.34971523284912109375e-01) (6, -1.40052247047424316406e+00) (7, -3.42403292655944824219e-01) (8, -4.33180302381515502930e-01) (9, 1.50589036941528320312e+00) (0, 2.73885228671133518219e-03) (1, 2.45092320442199707031e+00) (2, -6.13933992385864257812e+00) (3, 7.76235044002532958984e-01) (4, 2.02791437506675720215e-01) (5, -1.94743883609771728516e+00) (6, 1.46430361270904541016e+00) (7, 3.13473033905029296875e+00) (8, -2.14203810691833496094e+00) (9, 6.55337691307067871094e-01) (0, -2.65779805183410644531e+00) (1, 2.83347606658935546875e-01) (2, -6.93040713667869567871e-02) (3, -3.85630935430526733398e-01) (4, 1.89193010330200195312e-01) (5, -8.19292485713958740234e-01) (6, -3.14892858266830444336e-01) (7, -3.52679163217544555664e-01) (8, -8.14077079296112060547e-01) (9, 1.43305337429046630859e+00) (0, -6.80939435958862304688e-01) (1, 2.71583795547485351562e-01) (2, -5.57111561298370361328e-01) (3, -5.75544416904449462891e-01) (4, -1.86402165889739990234e+00) (5, 3.19081038236618041992e-01) (6, -8.14518749713897705078e-01) (7, -2.98376590013504028320e-01) (8, -1.19495213031768798828e-01) (9, 2.88502961397171020508e-01) (0, -1.67171490192413330078e+00) (1, 5.67162632942199707031e-01) (2, -6.94752857089042663574e-02) (3, -4.57483053207397460938e-01) (4, -3.13275605440139770508e-01) (5, -1.31198316812515258789e-01) (6, -7.28509843349456787109e-01) (7, -3.22873771190643310547e-01) (8, -8.43846321105957031250e-01) (9, 1.44845926761627197266e+00) (0, 7.44615867733955383301e-02) (1, 1.66112792491912841797e+00) (2, -3.82504606246948242188e+00) (3, 4.68078814446926116943e-02) (4, 1.61598950624465942383e-01) (5, -1.70403182506561279297e+00) (6, -1.12965238094329833984e+00) (7, 2.06921547651290893555e-01) (8, -4.76644754409790039062e-01) (9, 5.29239118099212646484e-01) (0, 1.06780558824539184570e-01) (1, 4.45165961980819702148e-01) (2, -9.53800380229949951172e-01) (3, -5.44791817665100097656e-01) (4, -1.08615040779113769531e+00) (5, -4.74378913640975952148e-01) (6, -1.33926427364349365234e+00) (7, 4.29322943091392517090e-02) (8, -2.31945589184761047363e-01) (9, 4.69549477100372314453e-01) (0, -5.42269945144653320312e-01) (1, 6.33280277252197265625e-01) (2, -6.83808088302612304688e-01) (3, -1.16048610210418701172e+00) (4, -2.03348055481910705566e-01) (5, 1.17907178401947021484e+00) (6, -5.51663017272949218750e+00) (7, -1.58490669727325439453e+00) (8, 1.06246456503868103027e-01) (9, 5.87508201599121093750e-01) (10, -1.65002608299255371094e+00) (11, -7.50285014510154724121e-02) (12, -6.82167232036590576172e-01) (13, -1.25445091724395751953e+00) (14, -1.54581081867218017578e+00) (15, 1.51111483573913574219e-01) (16, -1.60884952545166015625e+00) (17, -4.24940538406372070312e+00) (18, 6.55159235000610351562e-01) (10, 2.08178925514221191406e+00) (11, -2.62407350540161132812e+00) (12, -8.54133510589599609375e+00) (13, -5.47826480865478515625e+00) (14, 2.18140935897827148438e+00) (15, -3.18415594100952148438e+00) (16, 1.56870675086975097656e+00) (17, -6.48338651657104492188e+00) (18, 5.08292388916015625000e+00) (10, 3.72606158256530761719e+00) (11, 7.49367117881774902344e-01) (12, -3.88154014945030212402e-02) (13, 2.16088533401489257812e-01) (14, 2.49916410446166992188e+00) (15, 1.39097750186920166016e-01) (16, 1.99177956581115722656e+00) (17, -6.53838932514190673828e-01) (18, 6.87184989452362060547e-01) (10, -4.49897909164428710938e+00) (11, -3.14621567726135253906e+00) (12, -1.18158793449401855469e+00) (13, -1.89270997047424316406e+00) (14, -2.24891352653503417969e+00) (15, -6.38729512691497802734e-01) (16, -1.65371930599212646484e+00) (17, -5.69809436798095703125e+00) (18, 3.22490715980529785156e+00) (19, 2.42235556244850158691e-01) (20, 7.40234076976776123047e-01) (21, 4.05708909034729003906e-01) (22, -7.89729452133178710938e+00) (23, 4.54562127590179443359e-01) 
