FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -6.85277652740478515625e+00) (1, 4.14366215467453002930e-01) (2, -6.97540760040283203125e+00) (3, 2.42862701416015625000e+00) (4, -1.59616306424140930176e-01) (5, 5.87323904037475585938e-01) (6, 3.59714341163635253906e+00) (7, 1.11061656475067138672e+00) (8, 3.18052709102630615234e-01) (9, 6.71279132366180419922e-01) (0, -2.09935262799263000488e-01) (1, 1.97819232940673828125e+00) (2, 2.08620261400938034058e-02) (3, -1.53849029541015625000e+00) (4, -8.14024031162261962891e-01) (5, -8.05196642875671386719e-01) (6, -3.28360652923583984375e+00) (7, -3.82537722587585449219e-01) (8, -1.66120302677154541016e+00) (9, 2.76465415954589843750e+00) (0, -1.40617597103118896484e+00) (1, 4.73643153905868530273e-01) (2, -1.50946872308850288391e-02) (3, -1.19649863243103027344e+00) (4, 3.97141188383102416992e-01) (5, 2.18801036477088928223e-01) (6, -1.07302820682525634766e+00) (7, -4.63953316211700439453e-01) (8, -1.05547058582305908203e+00) (9, 1.54542160034179687500e+00) (0, -7.75893926620483398438e-01) (1, 1.48979806900024414062e+00) (2, -1.56907117366790771484e+00) (3, 2.32109483331441879272e-02) (4, -5.96955060958862304688e-01) (5, -3.59856009483337402344e-01) (6, -1.39149379730224609375e+00) (7, -2.36277163028717041016e-01) (8, -3.68315982818603515625e+00) (9, 3.81205606460571289062e+00) (0, -1.66690349578857421875e+00) (1, 2.43091297149658203125e+00) (2, -1.65301752090454101562e+00) (3, 3.91465201973915100098e-02) (4, -2.13985025882720947266e-01) (5, -5.73648333549499511719e-01) (6, 3.14867272973060607910e-02) (7, -1.34682729840278625488e-02) (8, -3.63083052635192871094e+00) (9, 2.85979461669921875000e+00) (0, 5.34119367599487304688e-01) (1, -6.60368502140045166016e-02) (2, 4.83864784240722656250e-01) (3, 2.65887647867202758789e-01) (4, 8.63529324531555175781e-01) (5, 2.26420834660530090332e-01) (6, 2.25314706563949584961e-01) (7, 6.14559173583984375000e-01) (8, -6.56562745571136474609e-02) (9, -2.04904451966285705566e-01) (0, 1.01709556579589843750e+00) (1, 1.87548148632049560547e+00) (2, 9.27370667457580566406e-01) (3, 2.79737758636474609375e+00) (4, 1.75439128875732421875e+01) (5, 1.48704003906250000000e+03) (6, 2.71556711196899414062e+00) (7, 3.60719323158264160156e+00) (8, 2.09545183181762695312e+00) (9, 3.93084359169006347656e+00) (0, 1.06839740276336669922e+00) (1, -8.99234637618064880371e-02) (2, 9.59733426570892333984e-01) (3, 2.82811343669891357422e-01) (4, 2.08670586347579956055e-01) (5, 2.60632447898387908936e-02) (6, 8.07113707065582275391e-01) (7, 1.25551700592041015625e-01) (8, 4.75930333137512207031e-01) (9, -5.16483128070831298828e-01) (10, -3.20616912841796875000e+00) (11, -4.01278734207153320312e+00) (12, -8.85480213165283203125e+00) (13, -1.10494184494018554688e+00) (14, -4.66751396656036376953e-01) (15, 7.38197445869445800781e-01) (16, 1.02963662147521972656e+00) (17, 2.23331832885742187500e+00) (18, 1.02689898014068603516e+00) (10, 4.28422117233276367188e+00) (11, 6.88370275497436523438e+00) (12, 5.83053886890411376953e-01) (13, 1.53327536582946777344e+00) (14, 9.63911414146423339844e-01) (15, -1.21083176136016845703e+00) (16, -4.78848934173583984375e-01) (17, -1.09278488159179687500e+00) (18, -4.94115054607391357422e-01) (10, 4.38654708862304687500e+00) (11, 6.94033718109130859375e+00) (12, 5.67439794540405273438e-01) (13, 2.03250432014465332031e+00) (14, 9.91007626056671142578e-01) (15, -1.25628852844238281250e+00) (16, -7.38685071468353271484e-01) (17, -1.10753130912780761719e+00) (18, -5.72089374065399169922e-01) (10, -2.94638228416442871094e+00) (11, -3.74647259712219238281e+00) (12, -9.02471351623535156250e+00) (13, -6.67181253433227539062e-01) (14, -6.41429781913757324219e-01) (15, 9.93204772472381591797e-01) (16, 1.19144916534423828125e+00) (17, 2.73469090461730957031e+00) (18, 1.54799921438097953796e-03) (19, -1.66979789733886718750e+00) (20, 5.19984900951385498047e-01) (21, 5.66915631294250488281e-01) (22, -3.06371665000915527344e+00) (23, -1.67189955711364746094e-01) 
