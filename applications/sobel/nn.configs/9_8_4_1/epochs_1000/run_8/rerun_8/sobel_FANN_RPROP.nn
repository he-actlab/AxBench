FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -8.44427883625030517578e-01) (1, 8.87623429298400878906e-01) (2, -1.52754271030426025391e+00) (3, -1.45788168907165527344e+00) (4, 4.12552833557128906250e-01) (5, 1.09305059909820556641e+00) (6, -1.61787652969360351562e+00) (7, -2.26734161376953125000e-01) (8, 9.14422124624252319336e-02) (9, 5.85793852806091308594e-01) (0, -2.14707994461059570312e+00) (1, 1.13785326480865478516e+00) (2, -1.79745686054229736328e+00) (3, -2.70198613405227661133e-01) (4, 5.58960616588592529297e-01) (5, 1.22570061683654785156e+00) (6, -2.14014577865600585938e+00) (7, -5.80646917223930358887e-02) (8, 6.27272307872772216797e-01) (9, 5.34947097301483154297e-01) (0, -2.15240025520324707031e+00) (1, 2.37618893384933471680e-01) (2, -1.90279567241668701172e+00) (3, 4.72429990768432617188e+00) (4, -3.52003313601016998291e-02) (5, -5.33003377914428710938e+00) (6, 1.48371887207031250000e+00) (7, 6.90100729465484619141e-01) (8, -5.46561479568481445312e-01) (9, 6.09446883201599121094e-01) (0, -6.42507135868072509766e-01) (1, 1.08215165138244628906e+00) (2, -1.67296624183654785156e+00) (3, -1.11610186100006103516e+00) (4, 2.10272595286369323730e-01) (5, 6.52147233486175537109e-01) (6, -1.25717079639434814453e+00) (7, -1.80202567577362060547e+00) (8, 4.29173046723008155823e-03) (9, 6.28712594509124755859e-01) (0, 1.56302660703659057617e-01) (1, 2.62146770954132080078e-01) (2, 3.15634727478027343750e-01) (3, -1.08608078956604003906e+00) (4, -2.03315830230712890625e+00) (5, -1.89354360103607177734e-01) (6, -3.17614436149597167969e+00) (7, -1.54627144336700439453e+00) (8, -1.37328624725341796875e+00) (9, 3.73491120338439941406e+00) (0, -1.23227250576019287109e+00) (1, 1.17214655876159667969e+00) (2, -1.86617183685302734375e+00) (3, -1.38398456573486328125e+00) (4, 5.91225028038024902344e-01) (5, 1.26857066154479980469e+00) (6, -2.09832525253295898438e+00) (7, -3.43881219625473022461e-01) (8, 3.92800122499465942383e-01) (9, 7.56980657577514648438e-01) (0, -1.78416049480438232422e+00) (1, 6.80565953254699707031e-01) (2, -1.53894305229187011719e+00) (3, -5.95188736915588378906e-01) (4, 5.97265362739562988281e-01) (5, 1.42883777618408203125e+00) (6, -1.81084382534027099609e+00) (7, -3.33739399909973144531e-01) (8, 1.91631376743316650391e-01) (9, 6.84515476226806640625e-01) (0, -1.78339517116546630859e+00) (1, 7.76462733745574951172e-01) (2, -1.63956630229949951172e+00) (3, -6.41838014125823974609e-01) (4, 4.32603478431701660156e-01) (5, 8.26184689998626708984e-01) (6, -1.12946426868438720703e+00) (7, 2.37529724836349487305e-01) (8, -5.56379966437816619873e-02) (9, 7.24643826484680175781e-01) (10, 7.23083555698394775391e-01) (11, 1.45010972023010253906e+00) (12, 2.30063509941101074219e+00) (13, -3.27492904663085937500e+00) (14, 5.07103586196899414062e+00) (15, 1.16088461875915527344e+00) (16, 7.82862186431884765625e-01) (17, 1.12368488311767578125e+00) (18, -7.32663691043853759766e-01) (10, 7.71491408348083496094e-01) (11, 1.26820600032806396484e+00) (12, 2.35136246681213378906e+00) (13, -3.69526457786560058594e+00) (14, 5.03228855133056640625e+00) (15, 1.25830149650573730469e+00) (16, 8.18032503128051757812e-01) (17, 1.30237603187561035156e+00) (18, -6.99037373065948486328e-01) (10, 1.04158294200897216797e+00) (11, 1.56618511676788330078e+00) (12, 2.07559752464294433594e+00) (13, -5.77058172225952148438e+00) (14, 5.23356056213378906250e+00) (15, 9.24716949462890625000e-01) (16, 1.30963838100433349609e+00) (17, 1.24652493000030517578e+00) (18, -3.36981058120727539062e-01) (10, -1.47185802459716796875e+00) (11, -1.87245678901672363281e+00) (12, -3.16773414611816406250e+00) (13, -8.41055452823638916016e-01) (14, -4.26758003234863281250e+00) (15, -1.36516845226287841797e+00) (16, -1.40211296081542968750e+00) (17, -5.96056938171386718750e-01) (18, 2.64320039749145507812e+00) (19, 2.76031911373138427734e-01) (20, 3.08328956365585327148e-01) (21, 2.34369710087776184082e-01) (22, -8.43167400360107421875e+00) (23, 1.63920044898986816406e-01) 
