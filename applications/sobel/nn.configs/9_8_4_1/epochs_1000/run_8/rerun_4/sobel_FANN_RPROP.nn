FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.71677935123443603516e+00) (1, 5.00346422195434570312e-01) (2, -6.33916333317756652832e-02) (3, -8.30858111381530761719e-01) (4, -7.33835920691490173340e-02) (5, -4.59881365299224853516e-01) (6, -2.18487024307250976562e+00) (7, -2.98740953207015991211e-01) (8, -6.40569806098937988281e-01) (9, 2.80430769920349121094e+00) (0, 1.50000000000000000000e+03) (1, 1.50000000000000000000e+03) (2, 1.18940002441406250000e+03) (3, 8.89467895030975341797e-01) (4, 1.28726034164428710938e+01) (5, 9.85800048828125000000e+02) (6, 2.65344190597534179688e+00) (7, -5.58436989784240722656e-01) (8, 1.08580004882812500000e+03) (9, -9.78726005554199218750e+00) (0, -2.70697975158691406250e+00) (1, 1.76365971565246582031e+00) (2, -7.86375939846038818359e-01) (3, -2.39957809448242187500e-01) (4, -3.84839028120040893555e-02) (5, -2.09046065807342529297e-01) (6, -3.77757459878921508789e-01) (7, 1.57543383538722991943e-02) (8, -1.25637686252593994141e+00) (9, 1.92870426177978515625e+00) (0, -1.53418540954589843750e+00) (1, 5.99687218666076660156e-01) (2, -2.68962502479553222656e-01) (3, -8.74378025531768798828e-01) (4, 3.36485505104064941406e-01) (5, -2.48632639646530151367e-01) (6, -2.16530442237854003906e+00) (7, -2.72729367017745971680e-01) (8, -1.16058373451232910156e+00) (9, 2.18206405639648437500e+00) (0, -2.59683251380920410156e+00) (1, 4.58886206150054931641e-01) (2, -5.39896547794342041016e-01) (3, -7.76247084140777587891e-01) (4, 7.62411773204803466797e-01) (5, 2.38788574934005737305e-01) (6, -1.83711361885070800781e+00) (7, -1.33350178599357604980e-01) (8, -1.13141393661499023438e+00) (9, 2.36837649345397949219e+00) (0, -1.46897937011718750000e+03) (1, 8.09468173980712890625e+00) (2, 7.59877502918243408203e-01) (3, -9.61144268512725830078e-01) (4, -3.34234610199928283691e-02) (5, -1.79398977756500244141e+00) (6, -2.36592864990234375000e+00) (7, -5.92049896717071533203e-01) (8, -1.07846622467041015625e+01) (9, 1.96352529525756835938e+00) (0, -7.79457950592041015625e+00) (1, -1.10261954367160797119e-01) (2, 1.30751237273216247559e-01) (3, -1.01364004611968994141e+00) (4, 4.15475338697433471680e-01) (5, 2.20123214721679687500e+01) (6, -2.18311738967895507812e+00) (7, -5.20545005798339843750e-01) (8, -1.01837744140625000000e+03) (9, 2.20325350761413574219e+00) (0, -2.04745903015136718750e+01) (1, 2.93032474517822265625e+01) (2, -1.04909631347656250000e+03) (3, 2.90503025054931640625e-01) (4, -3.38000917434692382812e+00) (5, -1.48028015136718750000e+03) (6, -4.55096423625946044922e-01) (7, 3.85585606098175048828e-01) (8, -1.16678112792968750000e+03) (9, 5.41559159755706787109e-01) (10, 7.44907855987548828125e-01) (11, 7.10695007324218750000e+02) (12, 1.64565241336822509766e+00) (13, -1.56421089172363281250e+01) (14, -2.67968153953552246094e+00) (15, -7.48329849243164062500e+01) (16, -1.25339324951171875000e+02) (17, -1.35292327880859375000e+02) (18, -5.36335229873657226562e-01) (10, -3.33411240577697753906e+00) (11, 3.47778588533401489258e-01) (12, -5.53255081176757812500e+00) (13, -3.37857365608215332031e+00) (14, -2.93242979049682617188e+00) (15, 6.88834333419799804688e+00) (16, -1.28033256530761718750e+00) (17, 1.50735270977020263672e+00) (18, 4.63810157775878906250e+00) (10, -3.15253406763076782227e-01) (11, 1.19303149414062500000e+03) (12, 1.58917450904846191406e+00) (13, -1.73128433227539062500e+01) (14, -8.42212104797363281250e+00) (15, -2.59274475097656250000e+02) (16, -1.56754821777343750000e+02) (17, -1.06969161987304687500e+02) (18, -3.37719500064849853516e-01) (10, -4.91446644067764282227e-01) (11, 1.20185131835937500000e+03) (12, 9.84035015106201171875e-01) (13, -9.19414138793945312500e+00) (14, -7.81896305084228515625e+00) (15, -1.96030349731445312500e+02) (16, -1.78365859985351562500e+02) (17, -2.08390960693359375000e+02) (18, -3.34130257368087768555e-01) (19, 2.85921990871429443359e-01) (20, -6.82208919525146484375e+00) (21, 2.70888298749923706055e-01) (22, 3.33519428968429565430e-01) (23, 1.74379751086235046387e-01) 
