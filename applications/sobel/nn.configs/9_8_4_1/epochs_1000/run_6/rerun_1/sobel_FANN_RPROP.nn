FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.48999416828155517578e+00) (1, -1.62805519104003906250e+01) (2, 5.92522621154785156250e-01) (3, -3.13527762889862060547e-01) (4, -4.12998867034912109375e+00) (5, 3.29885816574096679688e+00) (6, 3.50351977348327636719e+00) (7, 9.31960296630859375000e+00) (8, 1.06758975982666015625e+01) (9, -4.32599484920501708984e-01) (0, -1.92162156105041503906e+00) (1, -1.26908912658691406250e+01) (2, -9.94787788391113281250e+00) (3, 2.32579097151756286621e-01) (4, -1.39952206611633300781e+00) (5, 2.45724034309387207031e+00) (6, 4.74799442291259765625e+00) (7, 9.79092025756835937500e+00) (8, 8.08139801025390625000e+00) (9, 1.49528419971466064453e+00) (0, -1.03651881217956542969e+00) (1, -3.91599845886230468750e+00) (2, -1.14038705825805664062e-01) (3, 7.70409964025020599365e-03) (4, -2.03224822878837585449e-01) (5, -1.21317136287689208984e+00) (6, 2.43971800804138183594e+00) (7, 8.69034588336944580078e-01) (8, 5.48536729812622070312e+00) (9, -1.17933142185211181641e+00) (0, 3.48673987388610839844e+00) (1, -1.18631496429443359375e+01) (2, -2.53485646098852157593e-02) (3, 1.29632568359375000000e+00) (4, -1.88672199845314025879e-01) (5, 7.13478183746337890625e+00) (6, 1.31049156188964843750e+01) (7, 1.49448251724243164062e+01) (8, 9.50089263916015625000e+00) (9, 3.76595705747604370117e-01) (0, 1.67698907852172851562e+00) (1, -1.03335428237915039062e+01) (2, -1.22284030914306640625e+00) (3, 4.24630343914031982422e-01) (4, 3.90824526548385620117e-01) (5, 2.07557511329650878906e+00) (6, 6.16894149780273437500e+00) (7, 8.99184942245483398438e-01) (8, 1.23782176971435546875e+01) (9, 2.58066356182098388672e-01) (0, -2.05256342887878417969e+00) (1, -1.09860124588012695312e+01) (2, -3.34183740615844726562e+00) (3, 3.47171247005462646484e-01) (4, -4.58097743988037109375e+00) (5, 1.10357177257537841797e+00) (6, 3.83657932281494140625e+00) (7, 1.10035543441772460938e+01) (8, 8.09134101867675781250e+00) (9, -3.13581615686416625977e-01) (0, -3.47112715244293212891e-01) (1, -1.22590150833129882812e+01) (2, -1.02668821811676025391e+00) (3, 7.47912406921386718750e-01) (4, -7.96109139919281005859e-01) (5, -1.33554458618164062500e+00) (6, 2.80535125732421875000e+00) (7, -3.91318988800048828125e+00) (8, 3.74878501892089843750e+00) (9, 1.06320798397064208984e+00) (0, -7.15015411376953125000e-01) (1, -8.45357036590576171875e+00) (2, -5.47079205513000488281e-01) (3, 6.95876419544219970703e-01) (4, 1.75693416595458984375e+00) (5, -7.62511539459228515625e+00) (6, 6.75406217575073242188e+00) (7, 2.04359388351440429688e+00) (8, 3.19634318351745605469e+00) (9, -5.05299091339111328125e-01) (10, 4.57601666450500488281e-01) (11, -8.26099205017089843750e+00) (12, 3.98676443099975585938e+00) (13, -2.81599491834640502930e-01) (14, 2.94274181127548217773e-01) (15, -1.21607112884521484375e+00) (16, -3.09916473388671875000e+02) (17, -8.17740380764007568359e-01) (18, 1.10634410381317138672e+00) (10, -3.74760198593139648438e+00) (11, -1.70292437076568603516e+00) (12, 6.42850112915039062500e+00) (13, -5.07123708724975585938e-01) (14, -3.13541889190673828125e-02) (15, -1.95851969718933105469e+00) (16, -2.42822909355163574219e+00) (17, 8.58813285827636718750e+00) (18, -4.61808331310749053955e-02) (10, -5.18542575836181640625e+00) (11, -1.24851739406585693359e+00) (12, 8.40939235687255859375e+00) (13, -5.13505578041076660156e-01) (14, -5.94895482063293457031e-01) (15, -1.32626807689666748047e+00) (16, -3.56222796440124511719e+00) (17, 8.19141292572021484375e+00) (18, -1.61457080394029617310e-02) (10, -2.93342304229736328125e+00) (11, -4.08894777297973632812e+00) (12, 7.18739795684814453125e+00) (13, -5.33530414104461669922e-01) (14, -3.72641921043395996094e-01) (15, -1.26136875152587890625e+00) (16, -9.45176243782043457031e-01) (17, 1.90772323608398437500e+01) (18, 7.71907046437263488770e-02) (19, 2.17753982543945312500e+00) (20, 8.25542747974395751953e-01) (21, 8.83291721343994140625e-01) (22, 1.35673904418945312500e+00) (23, -2.17559361457824707031e+00) 
