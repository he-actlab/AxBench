FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.20439205169677734375e+01) (1, -3.84790968894958496094e+00) (2, -4.19644862413406372070e-02) (3, 4.45489978790283203125e+00) (4, -3.31756901741027832031e+00) (5, -9.66124534606933593750e+00) (6, -9.88794898986816406250e+00) (7, -4.60914182662963867188e+00) (8, -2.77654304504394531250e+01) (9, 3.26569056510925292969e+00) (0, -6.55493140220642089844e-01) (1, 2.91272330284118652344e+00) (2, -4.44497528076171875000e+02) (3, 5.28931140899658203125e-01) (4, 4.45287317037582397461e-01) (5, 8.91712188720703125000e+01) (6, -6.34498310089111328125e+00) (7, -4.96365606784820556641e-01) (8, -8.06623687744140625000e+01) (9, 4.82816696166992187500e-01) (0, 1.39508843421936035156e-01) (1, 8.86978030204772949219e-01) (2, -1.78597736358642578125e+01) (3, 1.04993236064910888672e+00) (4, 9.50079262256622314453e-01) (5, -5.47092008590698242188e+00) (6, 6.20592594146728515625e+00) (7, 4.10980129241943359375e+00) (8, 1.37327969074249267578e+00) (9, 5.81244170665740966797e-01) (0, -3.17761778831481933594e+00) (1, -3.94355893135070800781e+00) (2, 2.64750671386718750000e+01) (3, -4.41291618347167968750e+00) (4, -4.19275140762329101562e+00) (5, 1.51142282485961914062e+01) (6, -6.68809127807617187500e+00) (7, -2.75772571563720703125e+00) (8, -2.92729473114013671875e+00) (9, -1.70388579368591308594e+00) (0, -6.39284849166870117188e+00) (1, -1.19303760528564453125e+01) (2, -1.59067468643188476562e+01) (3, 6.13102674484252929688e+00) (4, 5.04571962356567382812e+00) (5, 2.61318373680114746094e+00) (6, -4.62765264511108398438e+00) (7, 1.66055548191070556641e+00) (8, 1.50961370468139648438e+01) (9, 6.21741390228271484375e+00) (0, -5.49868408203125000000e+02) (1, -5.07294769287109375000e+02) (2, -4.47322631835937500000e+02) (3, 3.64739913940429687500e+01) (4, -6.04007542133331298828e-01) (5, 1.48075427246093750000e+03) (6, -1.90023284912109375000e+02) (7, -1.16739245605468750000e+03) (8, -1.22626904296875000000e+03) (9, -6.09638571739196777344e-01) (0, -7.52598047256469726562e-01) (1, -3.15421557426452636719e+00) (2, -1.39177906513214111328e+00) (3, 2.42177784442901611328e-01) (4, -9.47358012199401855469e-01) (5, 4.93971157073974609375e+00) (6, 5.10758876800537109375e-01) (7, -2.05014616250991821289e-01) (8, 8.76700162887573242188e-01) (9, 3.80542457103729248047e-01) (0, -1.14738166332244873047e-01) (1, 4.72670507431030273438e+00) (2, 9.11717796325683593750e+00) (3, 1.07053890824317932129e-01) (4, -3.53084713220596313477e-01) (5, 3.30842375755310058594e+00) (6, -9.57576847076416015625e+00) (7, -2.13567876815795898438e+00) (8, -6.90154027938842773438e+00) (9, -9.09882560372352600098e-02) (10, -5.69328117370605468750e+01) (11, -1.43225738525390625000e+02) (12, 7.02145690917968750000e+01) (13, -1.37159357070922851562e+01) (14, -1.42917919158935546875e+01) (15, 1.49410998535156250000e+03) (16, 7.42974138259887695312e+00) (17, 2.18440876007080078125e+01) (18, -6.09645664691925048828e-01) (10, -1.22606110572814941406e+00) (11, 5.58571815490722656250e+00) (12, -7.29645204544067382812e+00) (13, 1.66423761844635009766e+00) (14, 1.61479067802429199219e+00) (15, 6.42983474731445312500e+01) (16, 1.82400524616241455078e+00) (17, -6.67592048645019531250e+00) (18, 6.64656460285186767578e-01) (10, 4.93315429687500000000e+01) (11, 9.32678680419921875000e+01) (12, 3.05132222175598144531e+00) (13, -7.56516575813293457031e-01) (14, -1.82244157791137695312e+00) (15, 1.49410998535156250000e+03) (16, -1.27688720822334289551e-01) (17, 4.51444816589355468750e+00) (18, 1.49661660194396972656e-01) (10, 5.36006689071655273438e+00) (11, -8.20300388336181640625e+00) (12, -2.14122629165649414062e+00) (13, 1.33703362941741943359e+00) (14, 1.92383944988250732422e+00) (15, 1.49410998535156250000e+03) (16, 2.22043752670288085938e+00) (17, 4.18057298660278320312e+00) (18, 3.42398971319198608398e-01) (19, 1.82049885392189025879e-01) (20, -2.84993720054626464844e+00) (21, 4.10065710544586181641e-01) (22, 4.10476088523864746094e-01) (23, 1.10057473182678222656e-01) 
