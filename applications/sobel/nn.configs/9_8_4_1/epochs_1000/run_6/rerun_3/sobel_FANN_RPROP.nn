FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -5.05176894366741180420e-02) (1, 8.94251167774200439453e-01) (2, 2.60111188888549804688e+00) (3, 1.02640822529792785645e-01) (4, -2.61339843273162841797e-01) (5, 1.51291862130165100098e-01) (6, -1.12402975559234619141e+00) (7, -6.82381987571716308594e-01) (8, -4.98220777511596679688e+00) (9, 4.79782462120056152344e-01) (0, -7.32144415378570556641e-01) (1, 5.63663482666015625000e+00) (2, -3.00975084304809570312e-01) (3, -1.02243614196777343750e+00) (4, -1.15903127193450927734e+00) (5, -5.44563233852386474609e-01) (6, -9.68559920787811279297e-01) (7, -6.05407357215881347656e-01) (8, -7.14022517204284667969e-01) (9, 4.17912900447845458984e-01) (0, -1.05483090877532958984e+00) (1, 6.18523359298706054688e-01) (2, -3.76186203956604003906e+00) (3, 1.61744073033332824707e-01) (4, 5.64848408102989196777e-02) (5, 2.60294258594512939453e-01) (6, -5.66652603447437286377e-02) (7, -1.71901300549507141113e-01) (8, -1.37884330749511718750e+00) (9, 2.45824247598648071289e-01) (0, 3.29330325126647949219e-01) (1, 3.80770742893218994141e-01) (2, -1.78894939422607421875e+01) (3, 1.62884140014648437500e+00) (4, 9.32401478290557861328e-01) (5, -7.18501043319702148438e+00) (6, 1.44415163993835449219e+00) (7, 1.26207244396209716797e+00) (8, 3.71024012565612792969e+00) (9, 5.37349522113800048828e-01) (0, -6.92029818892478942871e-02) (1, 2.52111852169036865234e-01) (2, -1.59409742355346679688e+01) (3, 1.05781316757202148438e+00) (4, 8.95236313343048095703e-01) (5, -2.74878978729248046875e-01) (6, 1.04933655261993408203e+00) (7, 4.94951188564300537109e-01) (8, -5.58787882328033447266e-01) (9, 5.06627976894378662109e-01) (0, -2.63323575258255004883e-01) (1, 3.68564724922180175781e+00) (2, 1.24507255852222442627e-01) (3, -9.06610131263732910156e-01) (4, -2.18791112303733825684e-01) (5, -3.33142042160034179688e-01) (6, -8.10492873191833496094e-01) (7, -1.30797648429870605469e+00) (8, -9.30280685424804687500e-02) (9, -2.42807455360889434814e-02) (0, 2.71736860275268554688e-01) (1, 1.04438018798828125000e+00) (2, -1.08826979994773864746e-01) (3, 8.84425193071365356445e-02) (4, 3.38582813739776611328e-01) (5, -2.62571811676025390625e-01) (6, -1.46803486347198486328e+00) (7, -1.41905236244201660156e+00) (8, -8.90716433525085449219e-01) (9, 1.64201751351356506348e-01) (0, 2.05907329916954040527e-01) (1, 1.00423192977905273438e+00) (2, 9.44661498069763183594e-01) (3, -1.14356231689453125000e+00) (4, -2.02079266309738159180e-02) (5, 1.62651687860488891602e-02) (6, -1.44683682918548583984e+00) (7, -7.74174869060516357422e-01) (8, -4.99493694305419921875e+00) (9, 6.19429826736450195312e-01) (10, -8.30085849761962890625e+00) (11, -1.50741171836853027344e+00) (12, 1.65573310852050781250e+01) (13, -2.30793724060058593750e+01) (14, -1.59046792984008789062e+01) (15, -1.49597716331481933594e+00) (16, -2.60578298568725585938e+00) (17, -4.13783121109008789062e+00) (18, 3.13929319381713867188e+00) (10, 1.12089371681213378906e+00) (11, 5.31379461288452148438e-01) (12, -1.43003263473510742188e+01) (13, 3.46253299713134765625e+00) (14, 6.35294866561889648438e+00) (15, 5.70137441158294677734e-01) (16, 1.05380737781524658203e+00) (17, -6.81059479713439941406e-01) (18, 2.01288104057312011719e-01) (10, -6.71278238296508789062e-01) (11, -3.88841301202774047852e-01) (12, 1.54124927520751953125e+01) (13, -2.63045454025268554688e+00) (14, -1.71265316009521484375e+00) (15, -1.01627051830291748047e+00) (16, -1.14383161067962646484e+00) (17, 1.68716490268707275391e-01) (18, 1.23234428465366363525e-01) (10, 1.31745171546936035156e+00) (11, 9.20412361621856689453e-01) (12, -1.39156694412231445312e+01) (13, 1.63547861576080322266e+00) (14, 7.25330209732055664062e+00) (15, 9.88064765930175781250e-01) (16, 1.44719529151916503906e+00) (17, 3.17966532707214355469e+00) (18, 3.58491122722625732422e-01) (19, -6.81156110763549804688e+00) (20, 7.68282651901245117188e-01) (21, -1.21612608432769775391e+00) (22, 1.05813753604888916016e+00) (23, 1.69260397553443908691e-01) 
