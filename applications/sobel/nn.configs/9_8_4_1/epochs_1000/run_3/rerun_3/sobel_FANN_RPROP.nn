FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.03011369705200195312e-01) (1, 6.26752197742462158203e-01) (2, 2.57463276386260986328e-01) (3, 1.38696753978729248047e+00) (4, 2.47565954923629760742e-01) (5, -1.06133222579956054688e+00) (6, 2.03072428703308105469e-01) (7, 6.94615662097930908203e-01) (8, -6.80376243591308593750e+00) (9, 1.91539335250854492188e+00) (0, -1.36772956848144531250e+01) (1, -1.54325306415557861328e-01) (2, -7.16592741012573242188e+00) (3, 1.60791528224945068359e+00) (4, 3.74349415302276611328e-01) (5, 7.59621337056159973145e-02) (6, 6.15862274169921875000e+00) (7, 1.40191733837127685547e+00) (8, 5.92493772506713867188e+00) (9, 6.14831686019897460938e-01) (0, 3.58291476964950561523e-01) (1, 4.73287850618362426758e-01) (2, 1.51897192001342773438e+00) (3, 1.50672185420989990234e+00) (4, 7.60325789451599121094e-02) (5, -2.77878940105438232422e-01) (6, -1.29120647907257080078e+00) (7, -3.52132749557495117188e+00) (8, -5.71488809585571289062e+00) (9, 2.01781582832336425781e+00) (0, -7.54926872253417968750e+00) (1, -6.13437843322753906250e+00) (2, -4.40949010848999023438e+00) (3, 2.09248995780944824219e+00) (4, -1.33733320236206054688e+00) (5, -1.98006153106689453125e+00) (6, 2.43991351127624511719e+00) (7, 3.99121046066284179688e-01) (8, -9.04039919376373291016e-01) (9, 8.91636967658996582031e-01) (0, 2.38001272082328796387e-01) (1, 1.40493786334991455078e+00) (2, 1.60902273654937744141e+00) (3, 8.34642827510833740234e-01) (4, -2.45846016332507133484e-03) (5, -2.18126326799392700195e-01) (6, -6.92688107490539550781e-01) (7, -4.01682138442993164062e+00) (8, -5.93880701065063476562e+00) (9, 1.90473711490631103516e+00) (0, -1.34302949905395507812e+01) (1, -5.35754024982452392578e-01) (2, -7.30831146240234375000e+00) (3, 3.29742431640625000000e+00) (4, 4.23925489187240600586e-01) (5, -5.19265294075012207031e-01) (6, 3.82415795326232910156e+00) (7, 1.36636972427368164062e+00) (8, 6.96051025390625000000e+00) (9, 6.82153224945068359375e-01) (0, -1.33818540573120117188e+01) (1, -4.62312906980514526367e-01) (2, -7.73955726623535156250e+00) (3, 3.21152758598327636719e+00) (4, 3.83886516094207763672e-01) (5, -3.30230116844177246094e-01) (6, 3.91712164878845214844e+00) (7, 1.72174417972564697266e+00) (8, 6.92210388183593750000e+00) (9, 5.33728361129760742188e-01) (0, -7.48482704162597656250e+00) (1, 6.23740673065185546875e+00) (2, -4.44268989562988281250e+00) (3, 2.18614816665649414062e+00) (4, 7.67936706542968750000e-01) (5, -1.08784663677215576172e+00) (6, 2.27027750015258789062e+00) (7, 3.12596708536148071289e-01) (8, -9.21213924884796142578e-01) (9, 9.39094305038452148438e-01) (10, 1.66557824611663818359e+00) (11, 4.85571718215942382812e+00) (12, 1.05589590072631835938e+01) (13, -7.59284496307373046875e-01) (14, 9.86355209350585937500e+00) (15, 5.59000062942504882812e+00) (16, 5.22238445281982421875e+00) (17, -6.67799425125122070312e+00) (18, -4.95972394943237304688e+00) (10, 1.65292763710021972656e+00) (11, 3.48327827453613281250e+00) (12, 6.32700729370117187500e+00) (13, 2.14445543289184570312e+00) (14, 1.43586788177490234375e+01) (15, 6.18795442581176757812e+00) (16, 6.48981237411499023438e+00) (17, -6.00767660140991210938e+00) (18, -5.24361133575439453125e+00) (10, 1.51045167446136474609e+00) (11, 4.02149105072021484375e+00) (12, 6.32788038253784179688e+00) (13, 1.08468163013458251953e+00) (14, 1.41682891845703125000e+01) (15, 5.33143711090087890625e+00) (16, 6.09517288208007812500e+00) (17, -6.12772846221923828125e+00) (18, -5.17235469818115234375e+00) (10, 1.83956277370452880859e+00) (11, 4.82714033126831054688e+00) (12, 9.86358261108398437500e+00) (13, -7.95171976089477539062e-01) (14, 1.04646310806274414062e+01) (15, 5.67069673538208007812e+00) (16, 5.41758108139038085938e+00) (17, -6.90142107009887695312e+00) (18, -4.91070413589477539062e+00) (19, 4.14954125881195068359e-01) (20, 4.05398309230804443359e-01) (21, 4.66205984354019165039e-01) (22, 4.70734447240829467773e-01) (23, -8.81502866744995117188e-01) 
