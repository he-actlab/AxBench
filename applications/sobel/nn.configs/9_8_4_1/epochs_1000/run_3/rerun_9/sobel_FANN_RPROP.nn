FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.08939857482910156250e+01) (1, -6.59185256958007812500e+01) (2, 3.69472198486328125000e+01) (3, -8.32242584228515625000e+00) (4, 2.00312256813049316406e+00) (5, 5.08966178894042968750e+01) (6, 9.48122382164001464844e-01) (7, 4.50097608566284179688e+00) (8, -3.85260047912597656250e+01) (9, 1.96216368675231933594e+00) (0, -2.71351188421249389648e-01) (1, 1.69115126132965087891e+00) (2, -2.45466256141662597656e+00) (3, 6.17346143722534179688e+00) (4, 6.81110048294067382812e+00) (5, -5.48127794265747070312e+00) (6, 2.03077926635742187500e+01) (7, -1.61670989990234375000e+01) (8, -1.08981647491455078125e+01) (9, 4.18720722198486328125e+00) (0, 3.71929466724395751953e-01) (1, 4.79904145002365112305e-01) (2, 6.27840089797973632812e+00) (3, -2.48002552986145019531e+00) (4, -1.05920410156250000000e+00) (5, 2.83661341667175292969e+00) (6, -4.38131237030029296875e+00) (7, -8.74400901794433593750e+00) (8, 7.78345623984932899475e-04) (9, 1.45258224010467529297e+00) (0, 3.01648116111755371094e+00) (1, 2.58572530746459960938e+00) (2, 9.98755812644958496094e-01) (3, -9.05792713165283203125e+00) (4, -3.64794313907623291016e-01) (5, 6.99482619762420654297e-01) (6, -5.32830858230590820312e+00) (7, 9.91742193698883056641e-01) (8, 3.01650524139404296875e+00) (9, -4.63028526306152343750e+00) (0, 4.43905448913574218750e+00) (1, 8.56869757175445556641e-01) (2, 2.93819737434387207031e+00) (3, -1.07047691345214843750e+01) (4, 2.79757231473922729492e-01) (5, 1.04902803897857666016e+00) (6, -3.25042963027954101562e+00) (7, 6.03750228881835937500e-01) (8, 9.22858774662017822266e-01) (9, 9.63201344013214111328e-01) (0, 4.90986299514770507812e+00) (1, 3.37126421928405761719e+00) (2, 1.39219152927398681641e+00) (3, -4.51156568527221679688e+00) (4, -5.36271512508392333984e-01) (5, 1.30957973003387451172e+00) (6, -6.95273208618164062500e+00) (7, 3.04905486106872558594e+00) (8, 1.31342303752899169922e+00) (9, -2.33872604370117187500e+00) (0, 6.57338905334472656250e+00) (1, 4.30448627471923828125e+00) (2, 5.14201259613037109375e+00) (3, -6.44436645507812500000e+00) (4, -5.82654029130935668945e-02) (5, 5.76260137557983398438e+00) (6, -7.75764560699462890625e+00) (7, -9.77056175470352172852e-02) (8, -5.07979774475097656250e+00) (9, -5.36944687366485595703e-01) (0, -1.19595491886138916016e+00) (1, -6.10949575901031494141e-01) (2, -5.50181818008422851562e+00) (3, -9.64541077613830566406e-01) (4, -4.79871839284896850586e-01) (5, 6.58389866352081298828e-01) (6, -8.80563378334045410156e-01) (7, 4.23522615432739257812e+00) (8, 1.15496377944946289062e+01) (9, -2.01968240737915039062e+00) (10, 2.06841751933097839355e-01) (11, 3.00852328538894653320e-01) (12, -9.67834353446960449219e-01) (13, -7.82817780971527099609e-01) (14, -3.92894434928894042969e+00) (15, -1.44877028465270996094e+00) (16, -4.61735439300537109375e+00) (17, 3.65541005134582519531e+00) (18, 8.04164409637451171875e-02) (10, 7.31579542160034179688e-01) (11, 9.40460014343261718750e+00) (12, 1.06343784332275390625e+01) (13, 2.43814873695373535156e+00) (14, -7.54650384187698364258e-02) (15, -3.10217761993408203125e+00) (16, -7.23693752288818359375e+00) (17, -3.93221330642700195312e+00) (18, 6.79720997810363769531e-01) (10, -4.16638612747192382812e-01) (11, -1.66262730956077575684e-01) (12, -6.25856876373291015625e-01) (13, 1.96686565876007080078e+00) (14, 2.30014586448669433594e+00) (15, -1.70409345626831054688e+00) (16, -3.83354854583740234375e+00) (17, -1.72123387455940246582e-01) (18, 1.06211192905902862549e-01) (10, -8.58856260776519775391e-01) (11, 5.78642606735229492188e-01) (12, 1.28877964019775390625e+01) (13, -1.63438916206359863281e-01) (14, 5.14158248901367187500e-01) (15, 4.01046848297119140625e+00) (16, -4.86235767602920532227e-01) (17, -1.20463323593139648438e+01) (18, -1.80938262492418289185e-02) (19, 1.08225178718566894531e+00) (20, 4.38531160354614257812e-01) (21, 4.74948972463607788086e-01) (22, 1.22457659244537353516e+00) (23, -8.01813960075378417969e-01) 
