FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.32807517051696777344e+00) (1, -1.95075309276580810547e+00) (2, -9.94313430786132812500e+00) (3, 8.68374824523925781250e-01) (4, -2.45689702033996582031e+00) (5, -1.07056360244750976562e+01) (6, 1.01016197204589843750e+01) (7, 9.43555831909179687500e-01) (8, -1.53805923461914062500e+00) (9, 2.53831028938293457031e-01) (0, 3.98845672607421875000e-01) (1, 2.78409302234649658203e-01) (2, 6.89429569244384765625e+00) (3, 6.89657270908355712891e-01) (4, -2.74536520242691040039e-01) (5, -2.55253016948699951172e-01) (6, 5.98931193351745605469e-01) (7, -5.09528684616088867188e+00) (8, -6.97501802444458007812e+00) (9, 1.03633880615234375000e+00) (0, -1.25234832763671875000e+01) (1, -1.52397811412811279297e+00) (2, -3.84392070770263671875e+00) (3, 7.87481784820556640625e-01) (4, 2.40061521530151367188e-01) (5, -1.83860945701599121094e+00) (6, 3.14674139022827148438e+00) (7, 2.85971093177795410156e+00) (8, 7.27971076965332031250e+00) (9, 2.34677523374557495117e-01) (0, 4.51728761196136474609e-01) (1, 9.06712532043457031250e-01) (2, 6.71839046478271484375e+00) (3, 5.68555176258087158203e-01) (4, -3.37668687105178833008e-01) (5, -4.36763372272253036499e-03) (6, 5.78095495700836181641e-01) (7, -5.35282850265502929688e+00) (8, -7.73183155059814453125e+00) (9, 1.18611347675323486328e+00) (0, -3.57935595512390136719e+00) (1, -1.02685558795928955078e+00) (2, -1.07733659744262695312e+01) (3, 1.53008019924163818359e+00) (4, 3.65563869476318359375e-01) (5, -1.26714420318603515625e+00) (6, 1.72720038890838623047e+00) (7, 2.47693109512329101562e+00) (8, 4.16080522537231445312e+00) (9, 4.10747468471527099609e-01) (0, -1.72600936889648437500e+00) (1, -2.50421673059463500977e-01) (2, -6.74323290586471557617e-02) (3, 4.40917730331420898438e+00) (4, 1.12225043773651123047e+00) (5, 3.11241292953491210938e+00) (6, 1.46024525165557861328e+00) (7, -5.66908001899719238281e-01) (8, -9.75908184051513671875e+00) (9, 2.28838488459587097168e-01) (0, 2.99726277589797973633e-01) (1, 1.43347308039665222168e-01) (2, 3.66481328010559082031e+00) (3, -1.36158287525177001953e-01) (4, -9.44735556840896606445e-02) (5, 4.56230074167251586914e-01) (6, -2.54564166069030761719e-01) (7, -1.00391852855682373047e+00) (8, -1.04645643234252929688e+01) (9, 2.57208943367004394531e+00) (0, -7.12828457355499267578e-01) (1, -4.35834980010986328125e+00) (2, -2.02236728668212890625e+01) (3, 1.06988191604614257812e+00) (4, 3.85152339935302734375e-01) (5, -9.36718523502349853516e-01) (6, 4.40921401977539062500e+00) (7, 3.53616857528686523438e+00) (8, 7.70922040939331054688e+00) (9, 2.78831362724304199219e-01) (10, 1.63247489929199218750e+00) (11, 3.23252725601196289062e+00) (12, 5.26363229751586914062e+00) (13, 4.04638481140136718750e+00) (14, 9.12133634090423583984e-01) (15, -5.13271188735961914062e+00) (16, 3.39349699020385742188e+00) (17, 1.73299837112426757812e+00) (18, -1.34637486934661865234e+00) (10, 1.67906776070594787598e-01) (11, 3.25243782997131347656e+00) (12, 6.44594812393188476562e+00) (13, 4.38365697860717773438e+00) (14, 5.47428965568542480469e-01) (15, -5.15832233428955078125e+00) (16, 3.41319894790649414062e+00) (17, 1.30011546611785888672e+00) (18, -1.63120925426483154297e+00) (10, 6.82126402854919433594e-01) (11, 3.27155208587646484375e+00) (12, 5.79710674285888671875e+00) (13, 4.15010786056518554688e+00) (14, 7.43330299854278564453e-01) (15, -5.12667274475097656250e+00) (16, 3.35825657844543457031e+00) (17, 1.56622147560119628906e+00) (18, -1.42123174667358398438e+00) (10, -2.42433905601501464844e+00) (11, -3.49639797210693359375e+00) (12, -4.17203903198242187500e+00) (13, -2.11352896690368652344e+00) (14, -2.78483867645263671875e-01) (15, 5.07039308547973632812e+00) (16, -3.41375160217285156250e+00) (17, -1.96428287029266357422e+00) (18, 1.03262953460216522217e-01) (19, 2.88003295660018920898e-01) (20, 2.23954632878303527832e-01) (21, 2.73545950651168823242e-01) (22, -5.07696247100830078125e+00) (23, 1.56705692410469055176e-01) 
