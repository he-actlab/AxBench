FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.95511019229888916016e+00) (1, -1.14895868301391601562e+00) (2, 1.93593531847000122070e-01) (3, 1.27875149250030517578e+00) (4, 2.32532000541687011719e+00) (5, 2.87915420532226562500e+00) (6, 2.30556583404541015625e+00) (7, -5.93963027000427246094e-01) (8, -7.61481857299804687500e+00) (9, 1.41937375068664550781e-01) (0, 3.15287423133850097656e+00) (1, 3.29603433609008789062e+00) (2, 3.19160199165344238281e+00) (3, 4.69023346900939941406e-01) (4, 8.16318541765213012695e-02) (5, 1.01580895483493804932e-01) (6, 2.11288690567016601562e-01) (7, -4.14624214172363281250e+00) (8, -1.09385395050048828125e+01) (9, 3.25208991765975952148e-01) (0, -3.31090241670608520508e-01) (1, 2.71957731246948242188e+00) (2, 5.57036828994750976562e+00) (3, 4.60272610187530517578e-01) (4, -1.06587961316108703613e-01) (5, -1.72484919428825378418e-01) (6, 9.66785028576850891113e-02) (7, -4.71794366836547851562e+00) (8, -8.25406932830810546875e+00) (9, 5.48884809017181396484e-01) (0, -1.35161619186401367188e+01) (1, -3.35316479206085205078e-01) (2, -2.07482171058654785156e+00) (3, 1.14639282226562500000e+00) (4, 5.12452304363250732422e-01) (5, -7.98705160617828369141e-01) (6, 3.45474767684936523438e+00) (7, 2.94685792922973632812e+00) (8, 2.27306747436523437500e+00) (9, 4.12067621946334838867e-01) (0, -4.77090692520141601562e+00) (1, -1.26110470294952392578e+00) (2, -1.52809791564941406250e+01) (3, 1.35659813880920410156e+00) (4, 5.93674719333648681641e-01) (5, -8.85812163352966308594e-01) (6, 1.39911994934082031250e+01) (7, 2.10486888885498046875e-01) (8, 1.37878847122192382812e+00) (9, 5.73638498783111572266e-01) (0, -3.60339927673339843750e+00) (1, -4.92811292409896850586e-01) (2, 6.30068719387054443359e-01) (3, 1.01666688919067382812e+01) (4, 6.34743273258209228516e-01) (5, 6.91040945053100585938e+00) (6, 3.41186189651489257812e+00) (7, -5.10227346420288085938e+00) (8, -1.57487592697143554688e+01) (9, -9.92951452732086181641e-01) (0, -3.48565101623535156250e-01) (1, 1.13111853599548339844e+00) (2, 9.71534252166748046875e+00) (3, -1.22373414039611816406e+00) (4, -1.99245312251150608063e-03) (5, 1.27206230163574218750e+00) (6, -2.67136633396148681641e-01) (7, -4.94233179092407226562e+00) (8, -9.91040515899658203125e+00) (9, 2.69576251506805419922e-01) (0, 4.99717903137207031250e+00) (1, 6.43622016906738281250e+00) (2, 5.52881097793579101562e+00) (3, -3.59860515594482421875e+00) (4, 2.46121287345886230469e-01) (5, 3.10888409614562988281e-01) (6, -1.51047408580780029297e+00) (7, -1.34505538940429687500e+01) (8, -6.52174711227416992188e+00) (9, 1.55798590183258056641e+00) (10, -1.09119486808776855469e+00) (11, 2.74101376533508300781e+00) (12, 6.88461720943450927734e-01) (13, 1.42073237895965576172e+00) (14, 7.11423540115356445312e+00) (15, -4.73311567306518554688e+00) (16, 5.88123035430908203125e+00) (17, 2.46388697624206542969e+00) (18, -1.80092132091522216797e+00) (10, 1.93173170089721679688e+00) (11, 1.98995077610015869141e+00) (12, 4.39138263463973999023e-01) (13, 1.26481974124908447266e+00) (14, 4.83128070831298828125e+00) (15, -4.91296434402465820312e+00) (16, 4.72049474716186523438e+00) (17, 2.49257016181945800781e+00) (18, -8.22937369346618652344e-01) (10, 7.24615383148193359375e+00) (11, 2.32736611366271972656e+00) (12, 6.27922296524047851562e-01) (13, 2.56924927234649658203e-01) (14, 4.55190706253051757812e+00) (15, -7.76905918121337890625e+00) (16, 5.54921007156372070312e+00) (17, 1.11325478553771972656e+00) (18, -8.13598453998565673828e-01) (10, 2.77155280113220214844e+00) (11, -4.09870004653930664062e+00) (12, -5.21879255771636962891e-01) (13, -2.74787211418151855469e+00) (14, -4.16016483306884765625e+00) (15, 2.50603413581848144531e+00) (16, -3.14769744873046875000e+00) (17, -1.17163503170013427734e+00) (18, 1.64131119847297668457e-01) (19, 2.76539802551269531250e-01) (20, 2.15196743607521057129e-01) (21, 2.74106264114379882812e-01) (22, -3.17681789398193359375e+00) (23, 1.48073375225067138672e-01) 
