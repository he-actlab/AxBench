FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.31406247615814208984e-01) (1, -2.69277300685644149780e-02) (2, 5.60150766372680664062e+00) (3, 4.89640861749649047852e-01) (4, -3.06170821189880371094e-01) (5, -2.70871996879577636719e+00) (6, -3.80740702152252197266e-01) (7, 4.70654107630252838135e-02) (8, -3.28590899705886840820e-01) (9, -5.83576381206512451172e-01) (0, 6.04884147644042968750e+00) (1, 4.33442682027816772461e-01) (2, 8.82740707397460937500e+01) (3, -1.57678246498107910156e+00) (4, -1.89805996417999267578e+00) (5, 1.50000000000000000000e+03) (6, -2.11295676231384277344e+00) (7, -8.66279900074005126953e-01) (8, 1.37797632217407226562e+01) (9, 9.61405575275421142578e-01) (0, -8.98553311824798583984e-01) (1, -9.11039590835571289062e-01) (2, -5.00674009323120117188e+00) (3, 2.67418360710144042969e+00) (4, -1.26579865813255310059e-01) (5, -5.95969390869140625000e+00) (6, 2.14396893978118896484e-01) (7, 7.83706331253051757812e+00) (8, 1.20312433242797851562e+01) (9, -1.97373270988464355469e+00) (0, 1.89862295985221862793e-01) (1, 3.06265980005264282227e-01) (2, 2.16024923324584960938e+00) (3, 3.21866124868392944336e-01) (4, 3.03142637014389038086e-01) (5, -8.05782794952392578125e-01) (6, 6.98841154575347900391e-01) (7, 9.14198517799377441406e-01) (8, 2.95282632112503051758e-01) (9, -1.56289243698120117188e+00) (0, 2.11679995059967041016e-01) (1, 4.45668816566467285156e-01) (2, 3.75111341476440429688e+00) (3, 2.51642853021621704102e-01) (4, 3.20089012384414672852e-01) (5, -1.95938706398010253906e+00) (6, 7.03900873661041259766e-01) (7, 9.00044858455657958984e-01) (8, 1.83770999312400817871e-01) (9, -1.60848510265350341797e+00) (0, 2.03806853294372558594e+00) (1, 1.36783421039581298828e+00) (2, 3.41874217987060546875e+00) (3, 1.25012743473052978516e+00) (4, 1.74817931652069091797e+00) (5, -5.55343568325042724609e-01) (6, 5.31508731842041015625e+00) (7, 7.34574258327484130859e-01) (8, 2.58524107933044433594e+00) (9, -5.81904554367065429688e+00) (0, -2.41681665182113647461e-01) (1, -2.90757209062576293945e-01) (2, 2.25436162948608398438e+00) (3, -2.19359189271926879883e-01) (4, -4.14782524108886718750e-01) (5, 1.88873946666717529297e+00) (6, -2.42046892642974853516e-01) (7, 6.93963050842285156250e-01) (8, -1.42745077610015869141e+00) (9, -1.01012492179870605469e+00) (0, 2.65424519777297973633e-01) (1, 9.06598269939422607422e-02) (2, 2.17967009544372558594e+00) (3, 3.68266224861145019531e-01) (4, 2.07991063594818115234e-01) (5, -7.65418231487274169922e-01) (6, 8.55269610881805419922e-01) (7, 8.51975679397583007812e-01) (8, 3.89872014522552490234e-01) (9, -1.55711555480957031250e+00) (10, -3.81759256124496459961e-01) (11, -1.59185087680816650391e+00) (12, 2.88956809043884277344e+00) (13, -1.85027018189430236816e-01) (14, -1.67912572622299194336e-01) (15, 3.66452789306640625000e+00) (16, -3.65296483039855957031e+00) (17, -9.72422063350677490234e-02) (18, -1.03202176094055175781e+00) (10, -4.14640843868255615234e-01) (11, -7.50826239585876464844e-01) (12, -2.83200144767761230469e-01) (13, -4.50931131839752197266e-01) (14, -4.95713323354721069336e-01) (15, 9.22078728675842285156e-01) (16, -7.69243597984313964844e-01) (17, -4.38837319612503051758e-01) (18, 1.72417211532592773438e+00) (10, 1.77621889114379882812e+00) (11, 1.59210157394409179688e+00) (12, 6.92220497131347656250e+00) (13, 1.79408144950866699219e+00) (14, 2.61604428291320800781e+00) (15, -5.81720972061157226562e+00) (16, 1.73406076431274414062e+00) (17, 1.82649374008178710938e+00) (18, -7.92784690856933593750e+00) (10, -2.52158135175704956055e-01) (11, 3.21991741657257080078e-02) (12, -4.04099792242050170898e-01) (13, 2.23555397242307662964e-02) (14, 1.33056744933128356934e-01) (15, 4.03105318546295166016e-01) (16, -8.75544130802154541016e-01) (17, 3.26908752322196960449e-02) (18, 8.44625353813171386719e-01) (19, 1.26389348506927490234e+00) (20, 2.32015919685363769531e+00) (21, -4.05528593063354492188e+00) (22, 1.46582341194152832031e+00) (23, -1.12414860725402832031e+00) 
