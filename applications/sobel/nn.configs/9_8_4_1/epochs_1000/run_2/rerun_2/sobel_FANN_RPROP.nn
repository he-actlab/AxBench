FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 9.69335556030273437500e-01) (1, -5.52785217761993408203e-01) (2, 3.52722883224487304688e+00) (3, -5.80387592315673828125e-01) (4, 1.33329463005065917969e+00) (5, 5.43580007553100585938e+00) (6, 5.69444799423217773438e+00) (7, 2.18764832243323326111e-03) (8, -1.69138946533203125000e+01) (9, -2.75308299064636230469e+00) (0, -2.19906187057495117188e+00) (1, -2.85868835449218750000e+02) (2, 5.78093767166137695312e-01) (3, -4.40838479995727539062e+00) (4, 5.68362474441528320312e+00) (5, 1.99110388755798339844e+00) (6, 8.00059413909912109375e+00) (7, 6.05324089527130126953e-01) (8, -5.60554695129394531250e+01) (9, 5.91428995132446289062e-01) (0, -1.86666703224182128906e+00) (1, 2.26029491424560546875e+00) (2, 8.18621814250946044922e-01) (3, -9.37101125717163085938e-01) (4, 7.17223262786865234375e+00) (5, 4.37122917175292968750e+00) (6, -9.42098975181579589844e-01) (7, -1.71887755393981933594e-01) (8, -2.89578704833984375000e+01) (9, 7.77918279170989990234e-01) (0, -7.61568009853363037109e-01) (1, -3.94890867173671722412e-02) (2, -4.50572401285171508789e-01) (3, 4.63782787322998046875e+00) (4, 3.02715563774108886719e+00) (5, -2.72056484222412109375e+00) (6, 2.82651424407958984375e+00) (7, -7.62116968631744384766e-01) (8, -5.84672212600708007812e+00) (9, 1.24904072284698486328e+00) (0, 1.47216832637786865234e+00) (1, 5.56749839782714843750e+01) (2, 3.39021253585815429688e+00) (3, -8.95388507843017578125e+00) (4, -7.81780767440795898438e+00) (5, 3.10206246376037597656e+00) (6, -2.55834865570068359375e+01) (7, -1.65333974361419677734e+00) (8, -2.04300880432128906250e+01) (9, 1.90735769271850585938e+00) (0, -1.83238220214843750000e+01) (1, -3.16084474325180053711e-01) (2, 4.05210316181182861328e-01) (3, 6.65015697479248046875e-01) (4, 1.23319149017333984375e+00) (5, -1.10322129726409912109e+00) (6, 1.17228107452392578125e+01) (7, 6.86760127544403076172e-01) (8, 5.66713762283325195312e+00) (9, 9.82163131237030029297e-01) (0, -5.57312631607055664062e+00) (1, 3.12437295913696289062e-01) (2, 2.41644144058227539062e-01) (3, 6.05191183090209960938e+00) (4, -8.76642227172851562500e-01) (5, 1.56939297914505004883e-01) (6, 1.13536815643310546875e+01) (7, -1.41603469848632812500e+00) (8, -7.73344230651855468750e+00) (9, 2.04231810569763183594e+00) (0, 1.50000000000000000000e+03) (1, 7.23828136920928955078e-01) (2, -5.37001419067382812500e+00) (3, 1.33551586914062500000e+03) (4, 5.86263716220855712891e-01) (5, -2.28776907920837402344e+00) (6, 4.89643135070800781250e+01) (7, 2.98799753189086914062e-01) (8, -6.20897674560546875000e+00) (9, 1.82516944408416748047e+00) (10, 2.63648128509521484375e+00) (11, -1.28952697753906250000e+03) (12, -1.50000000000000000000e+03) (13, -2.25164842605590820312e+00) (14, -6.15733032226562500000e+02) (15, -5.83541822433471679688e+00) (16, -3.85511493682861328125e+00) (17, 5.66009330749511718750e+00) (18, 9.73149948120117187500e+01) (10, 3.50535850524902343750e+01) (11, 1.11464557647705078125e+01) (12, -4.02781066894531250000e+01) (13, -5.20123577117919921875e+00) (14, 7.03656971454620361328e-01) (15, -9.64264965057373046875e+00) (16, -7.37008619308471679688e+00) (17, 1.53888010978698730469e+00) (18, 1.13650856018066406250e+01) (10, 1.13741054534912109375e+01) (11, -1.58494768142700195312e+01) (12, 1.49218063354492187500e+01) (13, -3.93872690200805664062e+00) (14, -3.63349646329879760742e-01) (15, -1.89766454696655273438e+00) (16, -7.52686917781829833984e-01) (17, -1.99092462658882141113e-01) (18, 3.93722987174987792969e+00) (10, -3.44960021972656250000e+01) (11, -1.81486862182617187500e+02) (12, 1.45622216796875000000e+03) (13, -3.44187011718750000000e+01) (14, -1.57443557739257812500e+02) (15, -4.57740098237991333008e-01) (16, -6.23224449157714843750e+01) (17, -9.94777465820312500000e+02) (18, 3.71311879158020019531e+00) (19, 3.18767166137695312500e+00) (20, 1.80137300491333007812e+00) (21, 2.22127318382263183594e+00) (22, 1.47993981838226318359e+00) (23, -2.76713085174560546875e+00) 
