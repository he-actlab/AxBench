FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.28116726875305175781e+00) (1, 9.89269971847534179688e-01) (2, -3.18572878837585449219e-01) (3, -1.40694963932037353516e+00) (4, -1.13548004627227783203e+00) (5, 5.00095725059509277344e-01) (6, 6.43557980656623840332e-02) (7, -1.76690256595611572266e+00) (8, 2.31758266687393188477e-01) (9, 4.53540384769439697266e-01) (0, -2.33713293075561523438e+00) (1, -4.57570791244506835938e-01) (2, -3.46221327781677246094e-01) (3, 1.88433969020843505859e+00) (4, -4.04929399490356445312e-01) (5, 7.18404501676559448242e-02) (6, -1.70865333080291748047e+00) (7, -4.34681683778762817383e-01) (8, 1.54212281107902526855e-01) (9, 6.59197449684143066406e-01) (0, 4.18751358985900878906e-01) (1, 1.38847911357879638672e+00) (2, 2.53270328044891357422e-01) (3, 6.19901657104492187500e-01) (4, -1.62098491191864013672e+00) (5, -3.89307975769042968750e-01) (6, 1.82679556310176849365e-02) (7, -3.50923919677734375000e+00) (8, -1.01638519763946533203e+00) (9, 6.27190411090850830078e-01) (0, -3.41870710253715515137e-02) (1, 1.56875967979431152344e+00) (2, 1.34830489754676818848e-01) (3, 1.92883938550949096680e-01) (4, -1.58498227596282958984e+00) (5, -5.09307444095611572266e-01) (6, 3.78454625606536865234e-02) (7, -2.37023663520812988281e+00) (8, -8.57784867286682128906e-01) (9, 4.73283082246780395508e-01) (0, 2.98720955848693847656e-01) (1, 1.87730491161346435547e+00) (2, 1.85770064592361450195e-01) (3, 2.08209827542304992676e-01) (4, -1.36859774589538574219e+00) (5, -6.17945015430450439453e-01) (6, -2.96470951288938522339e-02) (7, -3.06115293502807617188e+00) (8, -9.40779089927673339844e-01) (9, 5.81771016120910644531e-01) (0, 3.18116635084152221680e-01) (1, 1.51578426361083984375e+00) (2, 1.82473018765449523926e-01) (3, 1.00811488926410675049e-01) (4, -1.32142472267150878906e+00) (5, -6.82869374752044677734e-01) (6, 2.27514002472162246704e-02) (7, -2.35704421997070312500e+00) (8, -8.28505337238311767578e-01) (9, 3.66358518600463867188e-01) (0, -9.83460545539855957031e-01) (1, -5.99162876605987548828e-01) (2, 2.24029988050460815430e-01) (3, -3.56101584434509277344e+00) (4, 2.25844597816467285156e+00) (5, 2.27980352938175201416e-02) (6, 6.82893157005310058594e-01) (7, 4.63837289810180664062e+00) (8, 1.69943630695343017578e-01) (9, -1.04576013982295989990e-01) (0, -1.15530776977539062500e+01) (1, -2.79182214289903640747e-02) (2, 4.35086429119110107422e-01) (3, -1.95330536365509033203e+00) (4, 2.77837657928466796875e+00) (5, -1.39322853088378906250e+00) (6, -8.06752204895019531250e+00) (7, 2.88764381408691406250e+00) (8, 7.98846101760864257812e+00) (9, 5.60354828834533691406e-01) (10, -3.18533096313476562500e+01) (11, 1.85242450237274169922e+00) (12, 2.96808362007141113281e+00) (13, 2.84344911575317382812e+00) (14, 3.28294277191162109375e+00) (15, 3.05644655227661132812e+00) (16, 3.25837790966033935547e-01) (17, 1.08940620422363281250e+01) (18, 4.80607658624649047852e-01) (10, -2.69971542358398437500e+01) (11, 1.27648663520812988281e+00) (12, 2.23585462570190429688e+00) (13, 3.31735229492187500000e+00) (14, 3.77308607101440429688e+00) (15, 3.61841201782226562500e+00) (16, 9.03202712535858154297e-01) (17, 1.10857009887695312500e+01) (18, 3.09545040130615234375e-01) (10, 3.87789773941040039062e+00) (11, -1.78868293762207031250e+00) (12, -8.48496723175048828125e+00) (13, -3.13445806503295898438e+00) (14, -3.25430703163146972656e+00) (15, -3.10058665275573730469e+00) (16, 6.51753306388854980469e-01) (17, -6.28343820571899414062e+00) (18, 2.01920533180236816406e+00) (10, 6.24936771392822265625e+00) (11, -1.88355541229248046875e+00) (12, -7.41474723815917968750e+00) (13, -3.89500546455383300781e+00) (14, -4.32912302017211914062e+00) (15, -1.91358876228332519531e+00) (16, 6.50364041328430175781e-01) (17, -6.68937492370605468750e+00) (18, 1.73071432113647460938e+00) (19, 4.96555477380752563477e-01) (20, 4.44209396839141845703e-01) (21, -9.60231685638427734375e+00) (22, -3.28721785545349121094e+00) (23, 9.00034308433532714844e-02) 
