FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.27682819366455078125e+01) (1, -3.79232764244079589844e+00) (2, -3.41695904731750488281e-01) (3, -6.33679747581481933594e-01) (4, -9.44268107414245605469e-01) (5, 5.38473464548587799072e-02) (6, -2.74299359321594238281e+00) (7, -7.78881534934043884277e-02) (8, -8.81724059581756591797e-01) (9, -8.50361466407775878906e-01) (0, 2.83553123474121093750e+01) (1, -3.70742654800415039062e+00) (2, -1.88299670815467834473e-01) (3, -9.69604909420013427734e-01) (4, -9.48861122131347656250e-01) (5, 2.93506026268005371094e-01) (6, 1.94235593080520629883e-02) (7, -1.01364277303218841553e-01) (8, -9.08401429653167724609e-01) (9, -6.19771838188171386719e-01) (0, 2.57230606079101562500e+01) (1, -5.22918760776519775391e-01) (2, 2.40773230791091918945e-01) (3, -1.26715302467346191406e+00) (4, -3.11013054847717285156e+00) (5, -6.06050789356231689453e-01) (6, 8.39123249053955078125e+00) (7, 4.36440020799636840820e-01) (8, -1.68395004272460937500e+01) (9, 1.26862549781799316406e+00) (0, -6.64368152618408203125e-01) (1, 5.06686782836914062500e+00) (2, -8.52529227733612060547e-01) (3, -5.83460628986358642578e-01) (4, -2.88745498657226562500e+00) (5, -6.84262156486511230469e-01) (6, -7.76381015777587890625e-01) (7, -6.87090206146240234375e+00) (8, -7.56264925003051757812e-01) (9, 4.06972980499267578125e+00) (0, 5.43451805114746093750e+01) (1, -8.64086246490478515625e+00) (2, -3.79216551780700683594e-01) (3, -1.76439061760902404785e-01) (4, 1.37055352330207824707e-01) (5, -3.37105661630630493164e-01) (6, 2.92379903793334960938e+00) (7, -1.61042523384094238281e+00) (8, -8.00258159637451171875e-01) (9, -2.55146813392639160156e+00) (0, 1.33660049438476562500e+01) (1, -2.62909650802612304688e+00) (2, 2.61280126869678497314e-02) (3, -3.90096306800842285156e+00) (4, 5.14030551910400390625e+00) (5, -5.40286600589752197266e-01) (6, 2.31247004121541976929e-02) (7, -1.06039059162139892578e+00) (8, -1.89498245716094970703e+00) (9, -4.46254462003707885742e-01) (0, 4.03904876708984375000e+01) (1, -8.89391040802001953125e+00) (2, -4.19598400592803955078e-01) (3, -5.14612579345703125000e+00) (4, -4.88520652055740356445e-01) (5, 3.62515735626220703125e+00) (6, 9.14224609732627868652e-02) (7, -2.38299965858459472656e+00) (8, 1.20392823219299316406e+00) (9, -5.79330444335937500000e-01) (0, -5.16177833080291748047e-01) (1, 5.78859090805053710938e-01) (2, -4.87967967987060546875e-01) (3, -6.75209879875183105469e-01) (4, -2.00967407226562500000e+00) (5, -6.03646159172058105469e-01) (6, -1.94056642055511474609e+00) (7, -2.48457717895507812500e+00) (8, -1.08743977546691894531e+00) (9, 4.26453113555908203125e+00) (10, -1.16486215591430664062e+00) (11, -1.46434187889099121094e+00) (12, -1.08824834823608398438e+01) (13, 2.13774871826171875000e+02) (14, -2.74691638946533203125e+01) (15, -1.19491422176361083984e+00) (16, -3.04344558715820312500e+01) (17, 6.46228551864624023438e+00) (18, -1.84375822544097900391e-01) (10, -1.16861331462860107422e+00) (11, -1.26543140411376953125e+00) (12, -2.12543320655822753906e+00) (13, 1.62283382415771484375e+01) (14, -2.86937546730041503906e+00) (15, -2.56169414520263671875e+00) (16, -1.72339344024658203125e+00) (17, 8.70252037048339843750e+00) (18, 5.20428538322448730469e-01) (10, 8.76118361949920654297e-01) (11, 1.24904656410217285156e+00) (12, 2.13478279113769531250e+00) (13, -1.20039720535278320312e+01) (14, 1.05252337455749511719e+00) (15, 1.28630745410919189453e+00) (16, 1.86652207374572753906e+00) (17, -4.39277458190917968750e+00) (18, 1.67991980910301208496e-01) (10, -4.65117835998535156250e+00) (11, -2.91570854187011718750e+00) (12, 3.63895845413208007812e+00) (13, 1.22775802612304687500e+01) (14, 4.93460088968276977539e-01) (15, 2.81585782766342163086e-01) (16, 4.91305708885192871094e-01) (17, 4.17221933603286743164e-01) (18, -6.19630813598632812500e+00) (19, 7.52015173435211181641e-01) (20, 9.70960319042205810547e-01) (21, -1.91930627822875976562e+00) (22, -7.76753783226013183594e-01) (23, -2.86431670188903808594e-01) 
