FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.24586546421051025391e+00) (1, -3.95024955272674560547e-01) (2, 1.22791213989257812500e+01) (3, -1.17117395401000976562e+01) (4, -1.08295127749443054199e-01) (5, 2.71864843368530273438e+00) (6, -1.82622170448303222656e+00) (7, 2.80543899536132812500e+00) (8, 1.41557812690734863281e+00) (9, -1.06904797255992889404e-01) (0, 2.43554935455322265625e+01) (1, -8.72357273101806640625e+00) (2, 1.08460330963134765625e+01) (3, 4.31350564956665039062e+00) (4, -1.59663069248199462891e+00) (5, -9.72527384757995605469e-01) (6, 4.53227424621582031250e+00) (7, -9.12388420104980468750e+00) (8, -1.64658308029174804688e+00) (9, -2.95155191421508789062e+00) (0, 3.01390480995178222656e+00) (1, 2.18251705169677734375e+00) (2, 6.90850555896759033203e-01) (3, 2.32686257362365722656e+00) (4, -3.21489477157592773438e+00) (5, -1.27575373649597167969e+00) (6, -1.89556431770324707031e+00) (7, 2.58443355560302734375e+00) (8, -4.86142635345458984375e-01) (9, -3.98871231079101562500e+00) (0, 3.95362567901611328125e+00) (1, -3.66785478591918945312e+00) (2, 2.22542300820350646973e-01) (3, 1.66646802425384521484e+00) (4, 1.49987354874610900879e-01) (5, 2.03160509467124938965e-01) (6, 7.88306951522827148438e-01) (7, 2.56426215171813964844e+00) (8, 1.56531858444213867188e+00) (9, -3.74195432662963867188e+00) (0, 5.54466133117675781250e+01) (1, 9.05460059642791748047e-01) (2, 9.46116256713867187500e+00) (3, -4.53148841857910156250e+00) (4, 6.55425691604614257812e+00) (5, 5.15104007720947265625e+00) (6, 3.16269016265869140625e+00) (7, -3.29842720031738281250e+01) (8, -1.12913787364959716797e+00) (9, -1.86272192001342773438e+00) (0, 2.20128655433654785156e+00) (1, 5.04103422164916992188e-01) (2, 1.25769119262695312500e+01) (3, -1.41298837661743164062e+01) (4, -3.99832934141159057617e-01) (5, 2.60185003280639648438e+00) (6, -2.79618310928344726562e+00) (7, 2.79255962371826171875e+00) (8, 2.40898895263671875000e+00) (9, -3.30955475568771362305e-01) (0, -2.58779907226562500000e+00) (1, 7.87114024162292480469e-01) (2, 9.27762603759765625000e+00) (3, -6.61353921890258789062e+00) (4, 1.45082104206085205078e+00) (5, 1.91156888008117675781e+00) (6, -1.45176136493682861328e+00) (7, 2.55671596527099609375e+00) (8, 4.19613838195800781250e-01) (9, -1.01909436285495758057e-01) (0, -1.71654391288757324219e+00) (1, 1.23042273521423339844e+00) (2, -3.20918202400207519531e-01) (3, -2.45201230049133300781e+00) (4, 5.18865406513214111328e-01) (5, 4.70153808593750000000e-01) (6, -9.27720010280609130859e-01) (7, -5.29959440231323242188e+00) (8, 5.93395173549652099609e-01) (9, 4.17024374008178710938e+00) (10, -7.02614113688468933105e-02) (11, -5.66014528274536132812e-01) (12, -3.88029903173446655273e-01) (13, -9.02385902404785156250e+00) (14, -5.00333011150360107422e-01) (15, -2.40939170122146606445e-01) (16, -2.90772765874862670898e-01) (17, 1.25278530120849609375e+01) (18, 1.57645288854837417603e-02) (10, -5.02201437950134277344e-01) (11, -5.40126800537109375000e-01) (12, 1.00129966735839843750e+01) (13, -1.10553903579711914062e+01) (14, -7.44454741477966308594e-01) (15, -3.99209231138229370117e-01) (16, -3.28162193298339843750e-01) (17, 1.55854291915893554688e+01) (18, 4.69516180455684661865e-02) (10, -4.74200189113616943359e-01) (11, -8.88438761234283447266e-01) (12, 1.46993341445922851562e+01) (13, 1.35528171062469482422e+00) (14, -2.28212475776672363281e+00) (15, -8.21677923202514648438e-01) (16, -3.77735257148742675781e-01) (17, -7.37638831138610839844e-01) (18, -2.48906835913658142090e-01) (10, -2.30455368757247924805e-01) (11, -4.71283942461013793945e-01) (12, -4.10778343677520751953e-01) (13, -6.36448907852172851562e+00) (14, -5.85124850273132324219e-01) (15, -1.89636066555976867676e-01) (16, -3.26601743698120117188e-01) (17, 9.84143161773681640625e+00) (18, 3.11640463769435882568e-02) (19, 8.84400308132171630859e-01) (20, 2.63802790641784667969e+00) (21, 2.04256296157836914062e+00) (22, 7.52432525157928466797e-01) (23, -3.62022542953491210938e+00) 
