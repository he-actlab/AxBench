FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -9.12116885185241699219e-01) (1, 1.39851045608520507812e+00) (2, -1.03690624237060546875e+00) (3, -3.26558399200439453125e+00) (4, -1.63510107994079589844e+00) (5, -6.11127316951751708984e-01) (6, -1.48648474121093750000e+03) (7, 2.58761912584304809570e-01) (8, 2.98994898796081542969e+00) (9, 2.10608288645744323730e-01) (0, -2.75390893220901489258e-01) (1, 4.70796155929565429688e+00) (2, 1.76051810383796691895e-01) (3, -5.49423694610595703125e-01) (4, -8.14171433448791503906e-01) (5, -1.71281397342681884766e+00) (6, -3.75340133905410766602e-01) (7, 4.64996397495269775391e-01) (8, -1.78161048889160156250e+01) (9, -3.46049696207046508789e-01) (0, 9.39438641071319580078e-01) (1, 2.15932583808898925781e+00) (2, -4.20661896467208862305e-01) (3, -2.18383240699768066406e+00) (4, -7.36077356338500976562e+00) (5, -6.12039804458618164062e-01) (6, -1.17934179306030273438e+01) (7, 7.93183818459510803223e-02) (8, 1.05765857696533203125e+01) (9, -8.69992449879646301270e-02) (0, 2.78013627976179122925e-02) (1, 5.20059204101562500000e+00) (2, 6.60577487945556640625e+00) (3, -1.22935935854911804199e-01) (4, -5.11324286460876464844e-01) (5, -5.62656700611114501953e-01) (6, 1.40661135315895080566e-01) (7, 1.73883616924285888672e+00) (8, -2.74716358184814453125e+01) (9, 1.07222497463226318359e-01) (0, -6.02315645664930343628e-03) (1, 1.00231254100799560547e+00) (2, 7.62458419799804687500e+00) (3, -4.82261516153812408447e-02) (4, -1.59449291229248046875e+00) (5, 8.46475315093994140625e+00) (6, 2.79087877273559570312e+00) (7, 1.08168613910675048828e+00) (8, -3.54849319458007812500e+01) (9, 8.24127197265625000000e-02) (0, -3.53506445884704589844e-01) (1, 3.31778669357299804688e+00) (2, 3.07434052228927612305e-01) (3, -4.23249661922454833984e-01) (4, -5.55059194564819335938e-01) (5, -1.40250074863433837891e+00) (6, -4.97338086366653442383e-01) (7, 1.17410039901733398438e+00) (8, -1.94473209381103515625e+01) (9, 1.35791629552841186523e-01) (0, -1.96712523698806762695e-01) (1, 5.88682603836059570312e+00) (2, 4.52265977859497070312e+00) (3, -2.68484294414520263672e-01) (4, -5.79984366893768310547e-01) (5, -6.30338311195373535156e-01) (6, 7.18114373739808797836e-04) (7, 2.86151313781738281250e+00) (8, -2.66626911163330078125e+01) (9, 2.68789857625961303711e-01) (0, -4.85521125793457031250e+00) (1, 9.82405006885528564453e-01) (2, -3.93056631088256835938e-01) (3, -1.09835112094879150391e+00) (4, -1.95960450172424316406e+00) (5, 1.10325109958648681641e+00) (6, -1.16518223285675048828e+00) (7, 1.43330669403076171875e+00) (8, 3.75508403778076171875e+00) (9, 5.27596175670623779297e-01) (10, -3.82895255088806152344e+00) (11, 2.33890116214752197266e-01) (12, 1.85492590069770812988e-01) (13, 9.92629945278167724609e-01) (14, -1.56838524341583251953e+00) (15, 1.06962643563747406006e-01) (16, 9.84959185123443603516e-01) (17, 2.62146306037902832031e+00) (18, 8.09687077999114990234e-02) (10, -1.54265671968460083008e-01) (11, -3.82133483886718750000e-01) (12, -2.27279996871948242188e+00) (13, -1.99750792980194091797e+00) (14, -6.06276571750640869141e-01) (15, -5.62622070312500000000e-01) (16, -1.27348160743713378906e+00) (17, -5.16794872283935546875e+00) (18, 1.99459111690521240234e+00) (10, 3.09410572052001953125e-01) (11, -4.59337115287780761719e-01) (12, -1.68304491043090820312e+00) (13, -3.01719617843627929688e+00) (14, -3.26836407184600830078e-01) (15, 2.64432936906814575195e-01) (16, -1.54312372207641601562e+00) (17, -4.58160448074340820312e+00) (18, 1.90176916122436523438e+00) (10, -6.25645935535430908203e-01) (11, 2.32136532664299011230e-01) (12, 1.19870209693908691406e+00) (13, 1.18910861015319824219e+00) (14, 4.97693538665771484375e-01) (15, 3.99688243865966796875e-01) (16, 9.81887102127075195312e-01) (17, 2.81959867477416992188e+00) (18, -4.67742793262004852295e-02) (19, 8.76273810863494873047e-01) (20, -3.21732425689697265625e+00) (21, -9.61914777755737304688e-01) (22, 3.71135145425796508789e-01) (23, 1.19490794837474822998e-01) 
