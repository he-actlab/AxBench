FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.48175573348999023438e+00) (1, 4.51539188623428344727e-01) (2, 6.50523126125335693359e-01) (3, -9.29514586925506591797e-01) (4, 3.27623307704925537109e-01) (5, -8.16584706306457519531e-01) (6, -9.25058424472808837891e-02) (7, -6.00265786051750183105e-02) (8, -3.52730917930603027344e+00) (9, 5.71359097957611083984e-01) (0, 2.19339418411254882812e+00) (1, 9.19999837875366210938e-01) (2, 4.47777318954467773438e+00) (3, -2.49555960297584533691e-01) (4, -1.05087026953697204590e-01) (5, -7.44057536125183105469e-01) (6, 1.17657870054244995117e-01) (7, 2.48230099678039550781e-01) (8, -1.79163131713867187500e+01) (9, 4.57545757293701171875e-01) (0, -1.44311773777008056641e+00) (1, 6.68394505977630615234e-01) (2, 7.96324983239173889160e-02) (3, -1.55449914932250976562e+00) (4, -1.79999634623527526855e-01) (5, -2.60754108428955078125e-01) (6, -4.06229466199874877930e-01) (7, 2.28011772036552429199e-01) (8, 1.84248530864715576172e+00) (9, 5.72126567363739013672e-01) (0, -1.49788153171539306641e+00) (1, 6.14234387874603271484e-01) (2, -3.22298221290111541748e-02) (3, -1.41177880764007568359e+00) (4, -3.24966192245483398438e-01) (5, -1.98851406574249267578e-01) (6, -5.20808160305023193359e-01) (7, 3.46167683601379394531e-01) (8, 1.85562753677368164062e+00) (9, 4.61715072393417358398e-01) (0, -2.42685928344726562500e+01) (1, 1.18631601333618164062e+00) (2, -2.77428954839706420898e-01) (3, -7.91945159435272216797e-01) (4, -9.96747314929962158203e-02) (5, 1.00680484771728515625e+01) (6, 1.00816033780574798584e-01) (7, 1.31554341316223144531e+00) (8, 3.08477067947387695312e+00) (9, 1.75676989555358886719e+00) (0, 1.89185702800750732422e+00) (1, 8.43968391418457031250e-01) (2, 3.90727400779724121094e+00) (3, -6.03617489337921142578e-01) (4, 5.33943399786949157715e-02) (5, -9.48679804801940917969e-01) (6, 3.51416505873203277588e-02) (7, 1.22685335576534271240e-01) (8, -1.91471920013427734375e+01) (9, 4.39279377460479736328e-01) (0, -2.18312244415283203125e+01) (1, 7.21984326839447021484e-01) (2, -1.58789443969726562500e+00) (3, -1.31538605690002441406e+00) (4, -1.25642474740743637085e-02) (5, -4.96773183345794677734e-01) (6, -8.79365876317024230957e-02) (7, 1.30462038516998291016e+00) (8, 8.53157043457031250000e-01) (9, 6.90645217895507812500e-01) (0, -2.27296009659767150879e-01) (1, 6.80918157100677490234e-01) (2, -1.41325756907463073730e-01) (3, -1.87738859653472900391e+00) (4, -2.43038225173950195312e+00) (5, -3.58052194118499755859e-01) (6, -2.51153826713562011719e+00) (7, 5.21862864494323730469e-01) (8, 3.58739304542541503906e+00) (9, 3.43258708715438842773e-01) (10, -1.44219779968261718750e+01) (11, 1.01160068511962890625e+01) (12, 1.42161297798156738281e+00) (13, 1.64420974254608154297e+00) (14, 3.33920335769653320312e+00) (15, -5.25534200668334960938e+00) (16, 2.14410591125488281250e+00) (17, 2.15206313133239746094e+00) (18, 2.80147939920425415039e-01) (10, -1.40970716476440429688e+01) (11, 8.48796463012695312500e+00) (12, 5.82512795925140380859e-01) (13, 6.00842535495758056641e-01) (14, 2.71428847312927246094e+00) (15, 4.27948236465454101562e+00) (16, 5.05039572715759277344e-01) (17, 3.42153739929199218750e+00) (18, 4.35449145734310150146e-02) (10, -1.71095657348632812500e+01) (11, 8.26603126525878906250e+00) (12, 8.66871654987335205078e-01) (13, 8.22104752063751220703e-01) (14, 3.73143100738525390625e+00) (15, 7.22683572769165039062e+00) (16, 1.81765949726104736328e+00) (17, 3.75046753883361816406e+00) (18, 9.59842056035995483398e-02) (10, 3.51030731201171875000e+00) (11, -1.90256178379058837891e+00) (12, -3.23375415802001953125e+00) (13, -3.21439146995544433594e+00) (14, -1.15633225440979003906e+00) (15, -5.19383955001831054688e+00) (16, -1.91900444030761718750e+00) (17, -3.58770537376403808594e+00) (18, 3.19316267967224121094e+00) (19, 2.66592323780059814453e-01) (20, 3.08409601449966430664e-01) (21, 2.88218945264816284180e-01) (22, -5.35028171539306640625e+00) (23, 1.93161979317665100098e-01) 
