FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.25832748413085937500e+01) (1, 5.40432989597320556641e-01) (2, 2.35300374031066894531e+00) (3, -2.38855391740798950195e-01) (4, 7.60679006576538085938e-01) (5, -2.84856617450714111328e-01) (6, 7.85064935684204101562e-01) (7, 6.97659444808959960938e+00) (8, 1.86795568466186523438e+00) (9, 1.71652305871248245239e-02) (0, 3.63799095153808593750e-01) (1, 2.49180388450622558594e+00) (2, -3.15734744071960449219e+00) (3, -8.64822685718536376953e-01) (4, 3.87001842260360717773e-01) (5, -4.62033629417419433594e-01) (6, -2.10607096552848815918e-01) (7, 6.09249286353588104248e-02) (8, -1.16167449951171875000e+00) (9, 2.85167980194091796875e+00) (0, -1.06913125514984130859e+00) (1, 4.54930841922760009766e-01) (2, 6.57335221767425537109e-01) (3, -1.06062579154968261719e+00) (4, -8.55815529823303222656e-01) (5, -9.90355789661407470703e-01) (6, -4.55108582973480224609e-01) (7, 5.08620083332061767578e-01) (8, -1.75171315670013427734e+00) (9, 3.22218942642211914062e+00) (0, 6.47070825099945068359e-01) (1, 1.53052949905395507812e+00) (2, 1.13886184692382812500e+01) (3, -1.08720588684082031250e+00) (4, -2.03404188156127929688e-01) (5, -8.05660724639892578125e-01) (6, -3.66109132766723632812e-01) (7, 8.74345183372497558594e-01) (8, -3.87943534851074218750e+01) (9, 5.63254117965698242188e-01) (0, -1.12332093715667724609e+00) (1, 4.31819856166839599609e-01) (2, 1.57108235359191894531e+00) (3, -9.27865564823150634766e-01) (4, -3.98437917232513427734e-01) (5, -9.76404726505279541016e-01) (6, -7.95900821685791015625e-02) (7, 9.84341442584991455078e-01) (8, -2.27083683013916015625e+00) (9, 2.62061738967895507812e+00) (0, -3.24673414230346679688e-01) (1, 4.74905967712402343750e-01) (2, 6.86735212802886962891e-01) (3, 1.67779397964477539062e+00) (4, -6.04780256748199462891e-01) (5, -7.88740217685699462891e-01) (6, 5.80411016941070556641e-01) (7, 2.97657155990600585938e+00) (8, -7.66485929489135742188e-01) (9, 2.32392525672912597656e+00) (0, 1.15570030212402343750e+01) (1, 5.52546405792236328125e+00) (2, 4.43645775318145751953e-01) (3, -1.96367704868316650391e+00) (4, 6.52999505400657653809e-02) (5, -1.16561424732208251953e+00) (6, -2.23949012756347656250e+01) (7, 7.16202318668365478516e-01) (8, -2.03328824043273925781e+00) (9, 3.74090820550918579102e-01) (0, -2.18507423400878906250e+01) (1, 7.49385654926300048828e-01) (2, 8.13370895385742187500e+00) (3, -5.71480154991149902344e-01) (4, 7.38258123397827148438e-01) (5, 5.03057432174682617188e+00) (6, 7.53425836563110351562e-01) (7, 3.91281962394714355469e+00) (8, -1.77541828155517578125e+00) (9, 1.89909979701042175293e-01) (10, -2.74201660156250000000e+01) (11, 1.14750337600708007812e+00) (12, 1.06730580329895019531e+00) (13, -5.14185142517089843750e+00) (14, 1.24678945541381835938e+00) (15, 1.12422490119934082031e+00) (16, 4.98368692398071289062e+00) (17, 2.80316276550292968750e+01) (18, 1.09434731304645538330e-01) (10, -6.22162294387817382812e+00) (11, 1.00341665744781494141e+00) (12, 2.30813074111938476562e+00) (13, 2.78583168983459472656e-01) (14, 9.22990918159484863281e-01) (15, 1.35364627838134765625e+00) (16, -4.67036294937133789062e+00) (17, 5.52866506576538085938e+00) (18, 1.69309511780738830566e-01) (10, -2.33405137062072753906e+00) (11, -2.59080618619918823242e-01) (12, -6.66626274585723876953e-01) (13, -2.91341328620910644531e+00) (14, -6.16157412528991699219e-01) (15, -3.07022482156753540039e-01) (16, -2.40014171600341796875e+00) (17, -1.33042585849761962891e+00) (18, 1.06966781616210937500e+00) (10, -3.11426925659179687500e+00) (11, 5.14776110649108886719e-01) (12, -7.24803864955902099609e-01) (13, -3.16647028923034667969e+00) (14, -6.73804283142089843750e-01) (15, -5.53429484367370605469e-01) (16, -2.50658726692199707031e+00) (17, -1.28187525272369384766e+00) (18, 1.01234436035156250000e+00) (19, 3.05692136287689208984e-01) (20, 3.30658018589019775391e-01) (21, -3.25412535667419433594e+00) (22, -3.19714689254760742188e+00) (23, 3.35572540760040283203e-01) 
