FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 9 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (10, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -6.89568221569061279297e-01) (1, -2.58982092142105102539e-01) (2, -7.04110503196716308594e-01) (3, 3.06180047988891601562e+00) (4, 3.48571956157684326172e-01) (5, -3.39431405067443847656e+00) (6, 2.81764936447143554688e+00) (7, 3.12079000473022460938e+00) (8, -7.76187705993652343750e+00) (9, 9.38028693199157714844e-01) (0, -1.27832460403442382812e+01) (1, 1.21919482946395874023e-01) (2, -6.39011012390255928040e-03) (3, 1.29421257972717285156e+00) (4, 8.87347340583801269531e-01) (5, 7.21227264404296875000e+00) (6, 2.44921970367431640625e+00) (7, -4.83251770019531250000e+02) (8, 2.25339555740356445312e+00) (9, 5.31571686267852783203e-01) (0, -1.42541837692260742188e+01) (1, -5.45811557769775390625e+00) (2, -1.00473995208740234375e+01) (3, 3.40663552284240722656e+00) (4, -1.17107868194580078125e+00) (5, 3.60953950881958007812e+00) (6, 7.76424503326416015625e+00) (7, 1.00923323631286621094e+00) (8, 5.12771034240722656250e+00) (9, 6.67943835258483886719e-01) (0, -2.13837261199951171875e+01) (1, -2.60088753700256347656e+00) (2, -6.67924356460571289062e+00) (3, 5.16388607025146484375e+00) (4, 4.93703424930572509766e-01) (5, -5.65775573253631591797e-01) (6, 5.40460824966430664062e+00) (7, 5.59261131286621093750e+01) (8, -1.20370397567749023438e+01) (9, 6.70630782842636108398e-02) (0, 4.25464820861816406250e+00) (1, -1.70916959643363952637e-01) (2, 3.65226536989212036133e-01) (3, 2.80546879768371582031e+00) (4, -5.44858753681182861328e-01) (5, -6.95917248725891113281e-01) (6, 2.18572187423706054688e+00) (7, -4.32851123809814453125e+00) (8, -5.96450233459472656250e+00) (9, 3.89700978994369506836e-01) (0, -1.45507879257202148438e+01) (1, -1.57046043872833251953e+00) (2, -5.22318506240844726562e+00) (3, 1.37802171707153320312e+00) (4, 1.26187745481729507446e-02) (5, -1.10526013374328613281e+00) (6, 4.72201156616210937500e+00) (7, 3.79329061508178710938e+00) (8, 4.29629755020141601562e+00) (9, 3.52327674627304077148e-01) (0, -1.38787002563476562500e+01) (1, -7.04243230819702148438e+00) (2, -7.57380676269531250000e+00) (3, 4.51782751083374023438e+00) (4, 1.28115847706794738770e-01) (5, 2.86520266532897949219e+00) (6, 7.42371320724487304688e+00) (7, 2.34390020370483398438e+00) (8, 5.23618602752685546875e+00) (9, 5.37789642810821533203e-01) (0, -1.59072971343994140625e+01) (1, -5.08730411529541015625e+00) (2, -5.93091888427734375000e+01) (3, 1.17288374900817871094e+00) (4, 1.42545318603515625000e+00) (5, 2.86304831504821777344e-01) (6, 3.49897503852844238281e+00) (7, -4.59089660644531250000e+00) (8, 2.68675827980041503906e+00) (9, 4.31345552206039428711e-01) (10, -9.39033889770507812500e+00) (11, -7.57878341674804687500e+01) (12, 8.34100532531738281250e+00) (13, -8.25196743011474609375e+00) (14, 2.23645114898681640625e+01) (15, 7.52790594100952148438e+00) (16, 4.27032947540283203125e+00) (17, -5.17844390869140625000e+00) (18, 1.76975417137145996094e+00) (10, 7.39783477783203125000e+00) (11, -3.37797660827636718750e+01) (12, 4.13022804260253906250e+00) (13, -7.50003290176391601562e+00) (14, 1.05411033630371093750e+01) (15, 4.26636695861816406250e+00) (16, 3.18206095695495605469e+00) (17, -2.87956380844116210938e+00) (18, -6.53593912720680236816e-02) (10, 2.99956188201904296875e+01) (11, -1.63141586303710937500e+02) (12, 1.27568902969360351562e+01) (13, -1.97466869354248046875e+01) (14, 1.78687248229980468750e+01) (15, 1.36590623855590820312e+00) (16, 9.77416706085205078125e+00) (17, -1.99725222587585449219e+00) (18, -3.82069897651672363281e+00) (10, 7.54891443252563476562e+00) (11, -1.26986076354980468750e+02) (12, 6.91239070892333984375e+00) (13, -8.68620681762695312500e+00) (14, 1.43521499633789062500e+01) (15, 2.98942399024963378906e+00) (16, 4.23291969299316406250e+00) (17, -2.43057775497436523438e+00) (18, -1.61899614334106445312e+00) (19, 2.88059085607528686523e-01) (20, 2.50000178813934326172e-01) (21, 3.67120534181594848633e-01) (22, 7.48106479644775390625e-01) (23, -7.79070854187011718750e-01) 
